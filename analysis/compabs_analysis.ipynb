{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib, io\n",
    "os.getcwd()\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../utils\")\n",
    "sys.path.append(\"../analysis/utils\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "import pymongo as pm\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "\n",
    "from PIL import Image, ImageOps, ImageDraw, ImageFont \n",
    "\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "import  matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "\n",
    "import drawing_utils as drawing\n",
    "import importlib\n",
    "import scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## directory & file hierarchy\n",
    "proj_dir = os.path.abspath('..')\n",
    "datavol_dir = os.path.join(proj_dir,'data')\n",
    "analysis_dir =  os.path.abspath('.')\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "json_dir = os.path.join(results_dir,'json')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'behavioral_experiments'))\n",
    "png_dir = os.path.abspath(os.path.join(datavol_dir,'png'))\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'stimuli') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'stimuli'))\n",
    "    \n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    \n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)   \n",
    "    \n",
    "if not os.path.exists(csv_dir):\n",
    "    os.makedirs(csv_dir)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set vars \n",
    "auth = pd.read_csv(os.path.join(analysis_dir,'auth.txt'), header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'cogtoolslab.org'\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "import pymongo as pm\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['compositional-abstractions']\n",
    "coll = db['two-towers']\n",
    "\n",
    "# which iteration name should we use?\n",
    "iterationName = 'livetest0'\n",
    "\n",
    "## look up number of trials\n",
    "trialNumDict = {'testing':13, 'livetest0':13}\n",
    "numTrials = trialNumDict[iterationName]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construct tidy dataframe with game data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### establish connection to mongo\n",
    "First thing you need to do is to establish an ssh tunnel (aka remote port forwarding) to the server, so that requests to the mongodb can be made \"as if\" the mongodb server is running on your local computer. Run this from the command line before you begin data analysis if you plan to fetch data from mongo:\n",
    "\n",
    "`ssh -fNL 27017:127.0.0.1:27017 USERNAME@cogtoolslab.org`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 total games.\n",
      "There are 1 complete games.\n"
     ]
    }
   ],
   "source": [
    "## get list of all gameIDs in database\n",
    "total_games = coll.find({'iterationName':iterationName}).distinct('gameid')\n",
    "print('There are {} total games.'.format(len(total_games)))\n",
    "\n",
    "## get list of complete gameIDs\n",
    "gameIDs = coll.find({'iterationName':iterationName}).distinct('gameid')\n",
    "complete_games = [g for g in gameIDs if len(coll.find({'gameid':g}).distinct('trialNum')) == numTrials]\n",
    "print('There are {} complete games.'.format(len(complete_games)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "broken_games = []\n",
    "complete_games = [g for g in complete_games if g not in broken_games]\n",
    "\n",
    "def construct_tidy_dataframe(eventType = 'chatMessage', \n",
    "                             complete_games = [],\n",
    "                             iterationName = 'pilot1',\n",
    "                             remove_workerID = True):\n",
    "    '''\n",
    "    input: list of complete games and name of event Type\n",
    "    '''\n",
    "    event2name = {'chatMessage':'chat', 'block':'block', 'endTrial':'trial', 'exitSurvey':'exit'}\n",
    "    L = pd.DataFrame()\n",
    "    for g, this_gameID in enumerate(complete_games):\n",
    "        print('Analyzing game {} | {} of {}'.format(this_gameID, g+1, len(complete_games)))\n",
    "        clear_output(wait=True) \n",
    "\n",
    "        ### extract records \n",
    "        #loop over iteration names??\n",
    "        X = coll.find({ '$and': [{'iterationName':iterationName}, \n",
    "#                                  {\"$or\":[{'iterationName':'Exp2Pilot3'},\n",
    "#                                  {'iterationName':'Exp2Pilot3_batch2'}]}\n",
    "                                 {'gameid': this_gameID}, {'eventType': eventType}]}).sort('time') \n",
    "        \n",
    "        li = list(X)        \n",
    "        _L = pd.DataFrame(li)  \n",
    "\n",
    "        ## concat with previous game's dataframe\n",
    "        if L.shape[0]==0:\n",
    "            L = _L\n",
    "        else: \n",
    "            L = pd.concat([L,_L], axis=0)     \n",
    "\n",
    "    ## postprocessing\n",
    "    if remove_workerID and 'workerId' in L.columns:\n",
    "        L = L.drop('workerId',axis=1)\n",
    "\n",
    "    ## save out group dataframe to csv dir\n",
    "    out_path = os.path.join(csv_dir,'compabs_{}_{}.csv'.format(event2name[eventType],iterationName))\n",
    "    print('Saving dataframe out to CSV dir at path: {}'.format(out_path))    \n",
    "    L.to_csv(out_path)             \n",
    "\n",
    "    return L\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dataframe out to CSV dir at path: /Users/choldawa/Documents/Projects/composition-abstractions/results/csv/compabs_exit_livetest0.csv\n"
     ]
    }
   ],
   "source": [
    "## construct dataframe for each datatype\n",
    "dataTypes = coll.distinct('eventType')\n",
    "for thisDataType in dataTypes:\n",
    "    X = construct_tidy_dataframe(eventType=thisDataType, complete_games=complete_games, iterationName=iterationName)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full DF from DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure one to one gameID and workerId \n",
    "# Should only happen if a repeat worker gets through\n",
    "\n",
    "# query = coll.find({\"$and\":[\n",
    "# #                         {'workerId':{'$exists':True}},\n",
    "# #                         {'condition':{'$ne':'practice'}},\n",
    "# #                         {'eventType':'trial_end'},\n",
    "#                         {\"$or\":[{'iterationName':'testing'}]}]\n",
    "#                      })\n",
    "\n",
    "#df_trial_end_full = pd.DataFrame(list(query.sort('timeAbsolute')))\n",
    "#df_trial_end_full[['workerId','gameID']]\n",
    "\n",
    "query = coll.find()\n",
    "\n",
    "df_trial_end_full = pd.DataFrame(list(query))\n",
    "\n",
    "#assert (np.mean(df_trial_end_full['workerId'].value_counts()) == np.mean(df_trial_end_full['gameID'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "824"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How many records?\n",
    "coll.estimated_document_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_trial_end_full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>iterationName</th>\n",
       "      <th>gameid</th>\n",
       "      <th>time</th>\n",
       "      <th>workerId</th>\n",
       "      <th>assignmentId</th>\n",
       "      <th>leftTarget</th>\n",
       "      <th>rightTarget</th>\n",
       "      <th>trialNum</th>\n",
       "      <th>turnNum</th>\n",
       "      <th>...</th>\n",
       "      <th>nativeEnglish</th>\n",
       "      <th>isHuman</th>\n",
       "      <th>confused</th>\n",
       "      <th>comments</th>\n",
       "      <th>strategy</th>\n",
       "      <th>role</th>\n",
       "      <th>totalLength</th>\n",
       "      <th>cumulativeScore</th>\n",
       "      <th>cumulativeBonus</th>\n",
       "      <th>trialScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>5ef64baeb3a18955919bb7ef</td>\n",
       "      <td>livetest1</td>\n",
       "      <td>1670-311187db-fb6e-4abe-8ef6-dfbaa2202dc6</td>\n",
       "      <td>1.593200e+12</td>\n",
       "      <td>A2S64AUN7JI7ZS</td>\n",
       "      <td>3QFUFYSY92FK3VPPUXU89EPQQ4J4FI</td>\n",
       "      <td>L</td>\n",
       "      <td>Pi</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>5ef64bd0b3a18955919bb7f3</td>\n",
       "      <td>livetest1</td>\n",
       "      <td>1670-311187db-fb6e-4abe-8ef6-dfbaa2202dc6</td>\n",
       "      <td>1.593200e+12</td>\n",
       "      <td>A2S64AUN7JI7ZS</td>\n",
       "      <td>3QFUFYSY92FK3VPPUXU89EPQQ4J4FI</td>\n",
       "      <td>L</td>\n",
       "      <td>Pi</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>5ef64bf1b3a18955919bb7f5</td>\n",
       "      <td>livetest1</td>\n",
       "      <td>1670-311187db-fb6e-4abe-8ef6-dfbaa2202dc6</td>\n",
       "      <td>1.593200e+12</td>\n",
       "      <td>A2S64AUN7JI7ZS</td>\n",
       "      <td>3QFUFYSY92FK3VPPUXU89EPQQ4J4FI</td>\n",
       "      <td>L</td>\n",
       "      <td>Pi</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          _id iterationName  \\\n",
       "816  5ef64baeb3a18955919bb7ef     livetest1   \n",
       "820  5ef64bd0b3a18955919bb7f3     livetest1   \n",
       "822  5ef64bf1b3a18955919bb7f5     livetest1   \n",
       "\n",
       "                                        gameid          time        workerId  \\\n",
       "816  1670-311187db-fb6e-4abe-8ef6-dfbaa2202dc6  1.593200e+12  A2S64AUN7JI7ZS   \n",
       "820  1670-311187db-fb6e-4abe-8ef6-dfbaa2202dc6  1.593200e+12  A2S64AUN7JI7ZS   \n",
       "822  1670-311187db-fb6e-4abe-8ef6-dfbaa2202dc6  1.593200e+12  A2S64AUN7JI7ZS   \n",
       "\n",
       "                       assignmentId leftTarget rightTarget trialNum  turnNum  \\\n",
       "816  3QFUFYSY92FK3VPPUXU89EPQQ4J4FI          L          Pi        4        8   \n",
       "820  3QFUFYSY92FK3VPPUXU89EPQQ4J4FI          L          Pi        4       10   \n",
       "822  3QFUFYSY92FK3VPPUXU89EPQQ4J4FI          L          Pi        4       12   \n",
       "\n",
       "     ... nativeEnglish isHuman confused comments strategy  role  totalLength  \\\n",
       "816  ...           NaN     NaN      NaN      NaN      NaN   NaN          NaN   \n",
       "820  ...           NaN     NaN      NaN      NaN      NaN   NaN          NaN   \n",
       "822  ...           NaN     NaN      NaN      NaN      NaN   NaN          NaN   \n",
       "\n",
       "     cumulativeScore  cumulativeBonus trialScore  \n",
       "816              NaN              NaN        NaN  \n",
       "820              NaN              NaN        NaN  \n",
       "822              NaN              NaN        NaN  \n",
       "\n",
       "[3 rows x 37 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trial = df_trial_end_full[(df_trial_end_full['iterationName'] == 'livetest1') &\n",
    "                            (df_trial_end_full['eventType'] == 'chatMessage')]\n",
    "df_trial.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### check outcome for specific workerID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workerIDS: ['A2XK59FYAFO9EX' 'A1U43WUOJQBK5T']\n",
      "Bonus: nan\n"
     ]
    }
   ],
   "source": [
    "#set worker ID\n",
    "workerID = 'A1U43WUOJQBK5T'\n",
    "\n",
    "#get GameID (not all info available at workerID level (e.g. bonus))\n",
    "gameID = df_trial_end_full[df_trial_end_full['workerId'] == workerID]['gameid'].unique()[0]\n",
    "\n",
    "#check iteration name\n",
    "df_game = df_trial_end_full[(df_trial_end_full['iterationName'] == 'livetest1') &\n",
    "                            (df_trial_end_full['gameid'] == gameID)]\n",
    "#get workerIds\n",
    "print('workerIDS:',df_game['workerId'].unique())\n",
    "#get bonus for gameID ([air of workerIDs])\n",
    "print(\"Bonus:\",max(df_game['cumulativeBonus']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial Level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming that if trial 23 saves, then 0-22 have also saved \n",
    "# # get ids of people with trial 23 data\n",
    "# query = coll.find({\"$and\":[\n",
    "#                         {'condition':{'$ne':'practice'}},\n",
    "#                         {'eventType':'trial_end'},\n",
    "#                         {\"$or\":[{'iterationName':'Exp2Pilot3'},\n",
    "#                                 {'iterationName':'Exp2Pilot3_batch2'}]},\n",
    "#                         #{'iterationName': iterationName}, #use this if one iteration name\n",
    "#                         {'trialNum': numTrials-1}]\n",
    "#                      })\n",
    "# complete_data_df = pd.DataFrame(query)\n",
    "# complete_data_ids = list(complete_data_df['workerId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter for full datasets\n",
    "# query = coll.find({\"$and\":[\n",
    "#                         {'condition':{'$ne':'practice'}},\n",
    "#                         {'eventType':'trial_end'},\n",
    "#                         #{'iterationName': iterationName}, #use this if one iteration name\n",
    "#                         {\"$or\":[{'iterationName':'Exp2Pilot3'},\n",
    "#                                 {'iterationName':'Exp2Pilot3_batch2'}]}]\n",
    "#                      })\n",
    "\n",
    "# df_trial_end_full = pd.DataFrame(list(query.sort('timeAbsolute')))\n",
    "\n",
    "\n",
    "# # filter dataframe for complete datasets\n",
    "# df_trial_end_full_filtered = df_trial_end_full[df_trial_end_full.workerId.isin(complete_data_ids)]\n",
    "\n",
    "# # reduce to crucial information\n",
    "# df_trial_end_reduced_filtered = df_trial_end_full_filtered[[\n",
    "#     'gameID','trialNum','phase','condition','eventType','targetName','repetition','targetID', #trial identifiers\n",
    "#     'nullScore','F1Score','normedScore','rawScoreDiscrete','nullScoreDiscrete','normedScoreDiscrete','scoreGapDiscrete', #scoring\n",
    "#     'numBlocks','nPracticeAttempts','blockColor','blockColorID','blockFell','doNothingRepeats',#misc. trial info\n",
    "#     'score','currBonus','timeBonus', #bonusing\n",
    "#     'timeAbsolute','timeRelative','buildTime','buildStartTime','buildFinishTime','timeToBuild', #timing \n",
    "#     'discreteWorld','allVertices', #world reconstruction\n",
    "#     'browser','browserVersion','os','devMode', #developer info\n",
    "#     #below here should be the same for every trial in a dataset\n",
    "#     'iterationName',\n",
    "#     'numTargets', 'prePostSetSize','numRepetitions', #pre-post info\n",
    "#     'bonusThresholdLow','bonusThresholdMid','bonusThresholdHigh','timeThresholdYellow','timeThresholdRed', #bonus info\n",
    "#     ]]\n",
    "\n",
    "# #Fix error in data-saving- normedScoreDiscrete saved as rawScoreDiscrete\n",
    "# df_trial_end_reduced_filtered['normedScoreDiscrete'] = df_trial_end_reduced_filtered['rawScoreDiscrete']\n",
    "# df_trial_end_reduced_filtered.drop(['rawScoreDiscrete'], axis=1)\n",
    "\n",
    "\n",
    "# df = df_trial_end_reduced_filtered.sort_values(by=['gameID', 'timeAbsolute'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DF for each event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in dataframes from each eventType\n",
    "df_block = pd.read_csv('../results/csv/compabs_block_livetest0.csv')\n",
    "df_chat = pd.read_csv('../results/csv/compabs_chat_livetest0.csv')\n",
    "df_exit = pd.read_csv('../results/csv/compabs_exit_livetest0.csv')\n",
    "df_trial = pd.read_csv('../results/csv/compabs_trial_livetest0.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect some raw data: language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chat.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create columns for char and word counts\n",
    "df_chat['word_count'] = df_chat['content'].str.split(' ').str.len()\n",
    "df_chat['char_count'] = df_chat['content'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chat.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect some raw data: display block towers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(drawing)\n",
    "df_block['w'] = df_block['width']\n",
    "df_block['h'] = df_block['height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "drawing.draw_from_actions_subplot(df_block[df_block.trialNum=='0'], \n",
    "                                  ax, \n",
    "                                  world_size = [12,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make basic visualizations and calculate descriptives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architect: mean number of words across trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coerce trialNum to numeric -- will remove \"practice\". Thoughts?\n",
    "df_chat['trialNum'] = pd.to_numeric(df_chat['trialNum'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get sum of words for each trial, group by game then average across games\n",
    "print(df_chat.groupby(['gameid','trialNum'])['word_count'].sum().groupby(['trialNum']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## line plots\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "df_chat.groupby(['gameid','trialNum'])['word_count'].sum().groupby(['trialNum']).mean().plot(ax = ax)\n",
    "plt.ylabel('Word Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## print summary stat to console?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Architect: mean number of characters across trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "df_chat.groupby(['gameid','trialNum'])['char_count'].sum().groupby(['trialNum']).mean().plot(ax = ax)\n",
    "plt.ylabel('Char Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architect: mean number of messages (across turns within a trial) across trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "df_chat.groupby(['gameid','trialNum'])['_id'].count().groupby(['trialNum']).mean().plot(ax = ax)\n",
    "plt.ylabel('Messages per trial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architect: Total typing time (across turns within at trial) across trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check time elapsed\n",
    "df_chat[\"timeElapsedInTurn\"] = pd.to_numeric(df_chat['timeElapsedInTurn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## line plots\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "df_chat.groupby(['gameid','trialNum'])['timeElapsedInTurn'].sum().groupby(['trialNum']).mean().plot(ax = ax)\n",
    "plt.ylabel('Average Time elapsed, Architect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chat.groupby(['gameid','trialNum'])['timeElapsedInTurn'].sum().groupby(['trialNum']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Builder: Reconstruction accuracy (intersection over union, IOU) across trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coerce trialNum to numeric -- will remove \"practice\". Thoughts?\n",
    "df_trial['trialNum'] = pd.to_numeric(df_trial['trialNum'], errors = 'coerce')\n",
    "#Coerce trialNum to numeric -- will remove \"practice\". Thoughts?\n",
    "df_block['trialNum'] = pd.to_numeric(df_block['trialNum'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "df_trial.groupby(['gameid','trialNum'])['score'].sum().groupby(['trialNum']).mean().plot(ax = ax)\n",
    "plt.ylabel('Trial Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Builder: Mean number of block placements per utterance across trials\n",
    "\n",
    "is this just 8/#utterances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TBD\n",
    "#merge chat history (for number of messages) with block placement (for blocks placed)\n",
    "print(df_chat.groupby(['gameid','trialNum'])['_id'].count())\n",
    "print(df_block.groupby(['gameid','trialNum', 'turnNum'])['_id'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Builder: Total reconstruction time (summed build time across turns, within each trial) across trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check time elapsed\n",
    "df_block[\"timeElapsedInTurn\"] = pd.to_numeric(df_block['timeElapsedInTurn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## line plots\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "df_block.groupby(['gameid','trialNum'])['timeElapsedInTurn'].sum().groupby(['trialNum']).mean().plot(ax = ax)\n",
    "plt.ylabel('Average Time elapsed, Builder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's look at the DVs above, w.r.t. repetition of scenes, IGNORING which side a tower appears on... so across four repetitions (where [A,B] is equivalent to [B,A])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def convert(list): \n",
    "    return tuple(i for i in list)\n",
    "df_chat['targetSet'] = convert(df_chat[['leftTarget', 'rightTarget']].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chat.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_chat.groupby(['gameid','trialNum','targetSet'])['word_count'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "df_chat.groupby(['gameid','targetSet'])['word_count'].sum().groupby(['targetSet']).mean().plot.bar(ax = ax)\n",
    "plt.ylabel('Words Per figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
