{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib, io\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "import pymongo as pm\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "\n",
    "from PIL import Image, ImageOps, ImageDraw, ImageFont \n",
    "\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "import  matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## directory & file hierarchy\n",
    "proj_dir = os.path.abspath('..')\n",
    "datavol_dir = os.path.join(proj_dir,'data')\n",
    "analysis_dir =  os.path.abspath('.')\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "json_dir = os.path.join(results_dir,'json')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'behavioral_experiments'))\n",
    "png_dir = os.path.abspath(os.path.join(datavol_dir,'png'))\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'stimuli') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'stimuli'))\n",
    "    \n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    \n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)   \n",
    "    \n",
    "if not os.path.exists(csv_dir):\n",
    "    os.makedirs(csv_dir)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set vars \n",
    "auth = pd.read_csv(os.path.join(analysis_dir,'auth.txt'), header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'cogtoolslab.org'\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "import pymongo as pm\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['compositional-abstractions']\n",
    "coll = db['two-towers']\n",
    "\n",
    "# which iteration name should we use?\n",
    "iterationName = 'livetest0'\n",
    "\n",
    "## look up number of trials\n",
    "trialNumDict = {'testing':13, 'livetest0':13}\n",
    "numTrials = trialNumDict[iterationName]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construct tidy dataframe with game data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### establish connection to mongo\n",
    "First thing you need to do is to establish an ssh tunnel (aka remote port forwarding) to the server, so that requests to the mongodb can be made \"as if\" the mongodb server is running on your local computer. Run this from the command line before you begin data analysis if you plan to fetch data from mongo:\n",
    "\n",
    "`ssh -fNL 27017:127.0.0.1:27017 USERNAME@cogtoolslab.org`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 complete games.\n"
     ]
    }
   ],
   "source": [
    "## get list of incomplete gameIDs\n",
    "incomplete_games = coll.find({'iterationName':iterationName}).distinct('gameid')\n",
    "print('There are {} incomplete games.'.format(len(incomplete_games)))\n",
    "\n",
    "## get list of complete gameIDs\n",
    "gameIDs = coll.find({'iterationName':iterationName}).distinct('gameid')\n",
    "complete_games = [g for g in gameIDs if len(coll.find({'gameid':g}).distinct('trialNum')) == numTrials]\n",
    "print('There are {} complete games.'.format(len(complete_games)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter out scribble games\n",
    "broken_games = []\n",
    "complete_games = [g for g in complete_games if g not in broken_games]\n",
    "\n",
    "def construct_tidy_dataframe(eventType = 'chatMessage', \n",
    "                             complete_games = [],\n",
    "                             iterationName = 'pilot1',\n",
    "                             remove_workerID = True):\n",
    "    '''\n",
    "    input: list of complete games and name of event Type\n",
    "    '''\n",
    "    event2name = {'chatMessage':'chat', 'block':'block', 'endTrial':'trial', 'exitSurvey':'exit'}\n",
    "    L = pd.DataFrame()\n",
    "    for g, this_gameID in enumerate(complete_games):\n",
    "        print('Analyzing game {} | {} of {}'.format(this_gameID, g+1, len(complete_games)))\n",
    "        clear_output(wait=True) \n",
    "\n",
    "        ### extract records \n",
    "        X = coll.find({ '$and': [{'iterationName':iterationName}, {'gameid': this_gameID}, {'eventType': eventType}]}).sort('time') \n",
    "        li = list(X)        \n",
    "        _L = pd.DataFrame(li)  \n",
    "\n",
    "        ## concat with previous game's dataframe\n",
    "        if L.shape[0]==0:\n",
    "            L = _L\n",
    "        else: \n",
    "            L = pd.concat([L,_L], axis=0)     \n",
    "\n",
    "    ## postprocessing\n",
    "    if remove_workerID and 'workerId' in L.columns:\n",
    "        L = L.drop('workerId',axis=1)\n",
    "\n",
    "    ## save out group dataframe to csv dir\n",
    "    out_path = os.path.join(csv_dir,'compabs_{}_{}.csv'.format(event2name[eventType],iterationName))\n",
    "    print('Saving dataframe out to CSV dir at path: {}'.format(out_path))    \n",
    "    L.to_csv(out_path)             \n",
    "\n",
    "    return L\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dataframe out to CSV dir at path: /Users/judithfan/compositional-abstractions/results/csv/compabs_exit_testing.csv\n"
     ]
    }
   ],
   "source": [
    "## construct dataframe for each datatype\n",
    "dataTypes = coll.distinct('eventType')\n",
    "for thisDataType in dataTypes:\n",
    "    X = construct_tidy_dataframe(eventType=thisDataType, complete_games=complete_games, iterationName=iterationName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure one to one gameID and workerId \n",
    "# Should only happen if a repeat worker gets through\n",
    "\n",
    "# query = coll.find({\"$and\":[\n",
    "# #                         {'workerId':{'$exists':True}},\n",
    "# #                         {'condition':{'$ne':'practice'}},\n",
    "# #                         {'eventType':'trial_end'},\n",
    "#                         {\"$or\":[{'iterationName':'testing'}]}]\n",
    "#                      })\n",
    "\n",
    "#df_trial_end_full = pd.DataFrame(list(query.sort('timeAbsolute')))\n",
    "#df_trial_end_full[['workerId','gameID']]\n",
    "\n",
    "query = coll.find()\n",
    "\n",
    "df_trial_end_full = pd.DataFrame(list(query))\n",
    "\n",
    "#assert (np.mean(df_trial_end_full['workerId'].value_counts()) == np.mean(df_trial_end_full['gameID'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How many records?\n",
    "coll.estimated_document_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0541-f9e6ef08-9c16-419b-86ca-7ab446764fed',\n",
       " '5541-746b2d7c-6092-4c1e-8fb5-9295525a2a0d']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll.distinct('gameid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial_end_full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial_end_full[['_id', 'iterationName', 'gameid', 'time', 'workerId', 'assignmentId',\\\n",
    "       'leftTarget', 'rightTarget', 'trialNum', 'turnNum', 'repNum', 'content',\\\n",
    "       'eventType', 'blockNum','x', 'y', 'width', 'height', 'color','discreteWorld']].tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial Level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that if trial 23 saves, then 0-22 have also saved \n",
    "# get ids of people with trial 23 data\n",
    "query = coll.find({\"$and\":[\n",
    "                        {'condition':{'$ne':'practice'}},\n",
    "                        {'eventType':'trial_end'},\n",
    "                        {\"$or\":[{'iterationName':'Exp2Pilot3'},\n",
    "                                {'iterationName':'Exp2Pilot3_batch2'}]},\n",
    "                        #{'iterationName': iterationName}, #use this if one iteration name\n",
    "                        {'trialNum': numTrials-1}]\n",
    "                     })\n",
    "complete_data_df = pd.DataFrame(query)\n",
    "complete_data_ids = list(complete_data_df['workerId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for full datasets\n",
    "query = coll.find({\"$and\":[\n",
    "                        {'condition':{'$ne':'practice'}},\n",
    "                        {'eventType':'trial_end'},\n",
    "                        #{'iterationName': iterationName}, #use this if one iteration name\n",
    "                        {\"$or\":[{'iterationName':'Exp2Pilot3'},\n",
    "                                {'iterationName':'Exp2Pilot3_batch2'}]}]\n",
    "                     })\n",
    "\n",
    "df_trial_end_full = pd.DataFrame(list(query.sort('timeAbsolute')))\n",
    "\n",
    "\n",
    "# filter dataframe for complete datasets\n",
    "df_trial_end_full_filtered = df_trial_end_full[df_trial_end_full.workerId.isin(complete_data_ids)]\n",
    "\n",
    "# reduce to crucial information\n",
    "df_trial_end_reduced_filtered = df_trial_end_full_filtered[[\n",
    "    'gameID','trialNum','phase','condition','eventType','targetName','repetition','targetID', #trial identifiers\n",
    "    'nullScore','F1Score','normedScore','rawScoreDiscrete','nullScoreDiscrete','normedScoreDiscrete','scoreGapDiscrete', #scoring\n",
    "    'numBlocks','nPracticeAttempts','blockColor','blockColorID','blockFell','doNothingRepeats',#misc. trial info\n",
    "    'score','currBonus','timeBonus', #bonusing\n",
    "    'timeAbsolute','timeRelative','buildTime','buildStartTime','buildFinishTime','timeToBuild', #timing \n",
    "    'discreteWorld','allVertices', #world reconstruction\n",
    "    'browser','browserVersion','os','devMode', #developer info\n",
    "    #below here should be the same for every trial in a dataset\n",
    "    'iterationName',\n",
    "    'numTargets', 'prePostSetSize','numRepetitions', #pre-post info\n",
    "    'bonusThresholdLow','bonusThresholdMid','bonusThresholdHigh','timeThresholdYellow','timeThresholdRed', #bonus info\n",
    "    ]]\n",
    "\n",
    "#Fix error in data-saving- normedScoreDiscrete saved as rawScoreDiscrete\n",
    "df_trial_end_reduced_filtered['normedScoreDiscrete'] = df_trial_end_reduced_filtered['rawScoreDiscrete']\n",
    "df_trial_end_reduced_filtered.drop(['rawScoreDiscrete'], axis=1)\n",
    "\n",
    "\n",
    "df = df_trial_end_reduced_filtered.sort_values(by=['gameID', 'timeAbsolute'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect some raw data: language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect some raw data: display block towers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make basic visualizations and calculate descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architect: mean number of words across trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## line plots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## print summary stat to console?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Architect: mean number of characters across trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architect: mean number of messages (across turns within a trial) across trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architect: Total typing time (across turns within at trial) across trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Builder: Reconstruction accuracy (intersection over union, IOU) across trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Builder: Mean number of block placements per utterance across trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Builder: Total reconstruction time (summed build time across turns, within each trial) across trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's look at the DVs above, w.r.t. repetition of scenes, IGNORING which side a tower appears on... so across four repetitions (where [A,B] is equivalent to [B,A])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
