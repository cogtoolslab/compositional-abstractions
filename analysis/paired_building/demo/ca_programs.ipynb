{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "964735df",
   "metadata": {},
   "source": [
    "# Linguistic Analyses for Compositional Abstractions (COSMOS)\n",
    "## Notebook 2: Learning part concepts with program abstraction\n",
    "\n",
    "In the previous section, we saw that *Architects* used increasingly concise language to describe the scenes they were viewing. In particular, we saw that they started to use words that referred to increasingly complex entities, moving from instructions about individual blocks to entire towers.\n",
    "\n",
    "Here we try to explain this trend through the lens of *abstraction*. We hypothesize that, as people are exposed to scenes that have elements in common, they acquire a vocabulary of part concepts that they can use represent and talk about each scene more concisely. To formalize this notion, we use *programmatic representations* of scenes, which support and amodal notion of abstraction, in the form of *program fragments*. In this notebook we explore a mechanism for learning program fragments as a model for the acquisition of part concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b9d4ef",
   "metadata": {},
   "source": [
    "*Note: this notebook serves as the instructor version and should be altered to the student version before being presented*\n",
    "\n",
    "This section is divided into three sections.  \n",
    "**Section 1** explains the programmatic representations we will work with.  \n",
    "**Section 2** covers the aquisition of part concepts over trials.  \n",
    "**Section 3** covers the refactoring of scene programs into more concise programs involving these part concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0935bba5",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c330338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib, io\n",
    "os.getcwd()\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "import pymongo as pm\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from PIL import Image, ImageOps, ImageDraw, ImageFont \n",
    "\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17eabe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"./model/lib_learning/\")\n",
    "\n",
    "from program import *\n",
    "import utilities\n",
    "import render\n",
    "from parse import *\n",
    "\n",
    "from towerPrimitives import primitives\n",
    "from makeTowerTasks import *\n",
    "from grammar import *\n",
    "from fragmentGrammar import *\n",
    "from gen_seq import *\n",
    "from enumeration import *\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c05f3a",
   "metadata": {},
   "source": [
    "## Part 1: Representing block towers as programs\n",
    "\n",
    "In this project we want to explore how people build on top of existing knowledge over a short interaction. We therefore assume a basic level of understanding of block building concepts, encapsulated in a *domain specific language* (DSL).\n",
    "\n",
    "Our *base DSL* (adapted from the [Dreamcoder building task](https://arxiv.org/abs/2006.08381)), contains the following primitives:\n",
    "- **h**: horizontal domino\n",
    "- **v**: vertical domino\n",
    "- **l_x**: move left x places,  where x in {1,2,3,4,5,6,7,8,9,10,11,12}\n",
    "- **r_x**: move right x places, where x in {1,2,3,4,5,6,7,8,9,10,11,12}\n",
    "\n",
    "We manually define a unique program for each scene. For example, the scene with the C-tower on the left and L-tower on the right is represented as:  \n",
    "    `h l_1 v v r_1 h r_12 h l_4 h l_1 v v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca3e4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_tower_programs = {\"CL\" :\"h l_1 v v r_1 h r_12 h l_4 h l_1 v v\",\n",
    "                         \"CPi\": \"h l_1 v v r_1 h r_6 v r_6 v l_5 h r_4 h\",\n",
    "                         \"PiC\": \"v r_6 v l_5 h r_4 h r_7 h l_1 v v r_1 h\",\n",
    "                         \"LPi\": \"h l_4 h l_1 v v r_9 v r_6 v l_5 h r_4 h\",\n",
    "                         \"LC\": \"h l_4 h l_1 v v r_12 h l_1 v v r_1 h\",\n",
    "                         \"PiL\": \"v r_6 v l_5 h r_4 h r_9 h l_4 h l_1 v v\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da586b6d",
   "metadata": {},
   "source": [
    "### <span style=\"color: orange\"> Possible exercise: follow through the program for a specific scene [include image] to make sure you know how the dsl is implemented </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a212c56",
   "metadata": {},
   "source": [
    "## Part 2: Library learning\n",
    "\n",
    "In this section we formalize abstraction learning as the discovery of *program fragments*. Fragments express part of a program with a single token. By augmenting the base DSL with these additional program fragments, we create a new DSL that can be used to express scenes more efficiently (i.e. with fewer tokens). This benefit comes at the cost of storing the new abstractions in memory.\n",
    "\n",
    "This trade-off is captured by the abstraction learning algorithm, [Dreamcoder](https://arxiv.org/abs/2006.08381). Dreamcoder proposes program fragments more or less readily, depending on a weighting parameter, *w*. To keep things simple, here we consider a small range of *w*s that produce a reasonable range of learning rates.\n",
    "\n",
    "This is important, as we use Dreamcoder to capture the *change in DSLs* across trials. As the model is exposed to more scenes (programs), program fragments are added to the DSL, and scenes are able to be expressed with shorter programs. This is meant to capture the ability of participants to reason about structures larger than individual blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036f4d63",
   "metadata": {},
   "source": [
    "### Running dreamcoder\n",
    "\n",
    "To save time, we have run the library learning phase of Dreamcoder for you on a range of weights. \n",
    "\n",
    "The output of Dreamcoder, for each participant, for each weight, is a series of DSLs-- one for each trial.\n",
    "\n",
    "These DSLs are saved in `./data/model/dsls/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02eb7f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = [1.5, 3.2, 3.3, 9.6] # values of w for which dreamcoder was run\n",
    "w_index = {w: i for i, w in enumerate(ws)} # positional index of w\n",
    "trials = range(1,13)\n",
    "ppts = range(1,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eff49665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the DSLs learned by dreamcoder\n",
    "\n",
    "data_path = './data/model/dsls/'\n",
    "\n",
    "dsls = {}\n",
    "trial_seqs = {}\n",
    "\n",
    "for ppt in range(1,50):\n",
    "    \n",
    "    dsls[ppt] = {}\n",
    "    \n",
    "    # read participants' trial sequence\n",
    "    with open(data_path+f\"{ppt}/configs.p\", \"rb\") as config_file:\n",
    "            trial_seqs[ppt] = pickle.load(config_file)\n",
    "    \n",
    "    # read inferred DSLs\n",
    "    for trial in range(1, 13):\n",
    "        with open(data_path+f\"{ppt}/{trial}.p\", \"rb\") as input_file:\n",
    "            dsls[ppt][trial] = pickle.load(input_file)\n",
    "\n",
    "def check_values(value, valid_values, parameter_type):\n",
    "    if value not in valid_values:\n",
    "        raise ValueError(f'{parameter_type} must be one of the following values: {valid_values}.')\n",
    "            \n",
    "def read_library(ppt, trial, w = 3.2, base_dsl_only=True):\n",
    "    '''\n",
    "    Returns dsl learned by dreamcoder\n",
    "    '''\n",
    "    check_values(ppt, range(1, 50), 'ppt')\n",
    "    check_values(trial, range(1, 13), 'trial')\n",
    "    check_values(w, ws, 'w')\n",
    "    \n",
    "    lib = [parse(str(fragment), base_dsl_only=base_dsl_only) for fragment in dsls[ppt][trial][w_index[w]]]\n",
    "        \n",
    "    \n",
    "    return lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c254584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h l_1 v v']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_library(ppt = 49, \n",
    "             trial = 3,\n",
    "             w = 3.2,\n",
    "             base_dsl_only=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a639414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v r_6 v l_5 h r_4 h', 'h l_1 v v', 'h l_4 h l_1 v v', 'h l_1 v v r_1 h']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect libraries learned for a particular participant, trial, and w\n",
    "\n",
    "read_library(ppt = 1, \n",
    "             trial = 12,\n",
    "             w = 3.2,\n",
    "             base_dsl_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae7c507",
   "metadata": {},
   "source": [
    "We're currently displaying each fragment as a program in the base DSL, but the whole point of learning fragments is that you can express them as a single token.\n",
    "\n",
    "If we were fully automating this process, we might use an ID to label each learned fragment. In this example, only a handful of fragments are learned. This makes it possible to give each fragment a more helpful, human-readable name. If we change `base_dsl_only` to `False` then we can give these learned fragments helpful names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0094237a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chunk_Pi', 'chunk_8', 'chunk_L', 'chunk_C', 'chunk_CPi', 'chunk_PiC']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_library(ppt = 49, \n",
    "             trial = 12,\n",
    "             w = 1.5,\n",
    "             base_dsl_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b01a543",
   "metadata": {},
   "source": [
    "We refer to all these learned abstractions as \"chunks\". \n",
    "\n",
    "- `chunk_8`, `chunk_8b`, `chunk_9` are subtower expressions (capturing several block placements)\n",
    "- `chunk_Pi`, `chunk_C` and `chunk_L`, are distinct block towers. \n",
    "- `chunk_CPi` (and other chunks with two of C, L, and Pi) are single abstractions that capture the entire scene.\n",
    "\n",
    "There are also a few unnamed chunks (mostly rarely occuring, small chunks consisting of e.g. a block and move). You might come across some of these as `chunk_un`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5ee887",
   "metadata": {},
   "source": [
    "### <span style=\"color: orange\"> Exercise: explore libraries</span>\n",
    "\n",
    "Now we'd like to know how libraries change across trials, as well as what this looks like for different values of w.\n",
    "\n",
    "First try printing an entire sequence of libraries for one participant.  \n",
    "Then, try to calculate some basic summary statistics across participants. One thing that might differ is the size of the library. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "416faa5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " ['chunk_8b'],\n",
       " ['chunk_8b', 'chunk_Pi'],\n",
       " ['chunk_8', 'chunk_Pi', 'chunk_L', 'chunk_C'],\n",
       " ['chunk_Pi', 'chunk_8', 'chunk_L', 'chunk_C'],\n",
       " ['chunk_8', 'chunk_Pi', 'chunk_L', 'chunk_C'],\n",
       " ['chunk_8', 'chunk_Pi', 'chunk_L', 'chunk_C'],\n",
       " ['chunk_Pi', 'chunk_8', 'chunk_L', 'chunk_C'],\n",
       " ['chunk_8', 'chunk_Pi', 'chunk_L', 'chunk_C'],\n",
       " ['chunk_Pi', 'chunk_8', 'chunk_L', 'chunk_C'],\n",
       " ['chunk_Pi', 'chunk_8', 'chunk_L', 'chunk_C']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the series of libraries for a specific weight and participant\n",
    "\n",
    "[read_library(ppt = 1, \n",
    "             trial = trial,\n",
    "             w = 3.2,\n",
    "             base_dsl_only=False) for trial in range(1,13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da184ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the series of libraries for a specific weight and participant\n",
    "\n",
    "libs = [[read_library(ppt = ppt, \n",
    "             trial = trial,\n",
    "             w = 1.5,\n",
    "             base_dsl_only=False) for trial in range(1,13)] for ppt in range(1,50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4859794b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chunk_Pi     510\n",
       "chunk_C      490\n",
       "chunk_L      487\n",
       "chunk_8      428\n",
       "chunk_CPi    248\n",
       "chunk_LPi    145\n",
       "chunk_8b     105\n",
       "chunk_PiC    105\n",
       "chunk_un      41\n",
       "chunk_PiL     20\n",
       "chunk_CL      18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([y for ys in [x for xs in libs for x in xs] for y in ys]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0608a064",
   "metadata": {},
   "source": [
    "1. Library size\n",
    "2. Library content\n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6d6aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize the breakdown of expressions learned in each run of dreamcoder (with different ws).\n",
    "# # move to file\n",
    "\n",
    "# import pickle\n",
    "# from makeTowerTasks import *\n",
    "# from render import *\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as mpatches\n",
    "# import re\n",
    "# sns.set()\n",
    "\n",
    "# sys.path.append('..')\n",
    "\n",
    "# def sorted_alphanumeric(data):\n",
    "#     convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "#     alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
    "#     return sorted(data, key=alphanum_key)\n",
    "\n",
    "# def get_freq(chunk):\n",
    "#     pair = 0\n",
    "#     tower = 0\n",
    "#     frag = 0\n",
    "#     for item in chunk:\n",
    "#         if str(item.body) in lookup.keys():\n",
    "#             item = lookup[str(item.body)]\n",
    "#             for t in item:\n",
    "#                 if t.name == 'C': \n",
    "#                     tower += 1.\n",
    "#                 elif t.name == 'L': \n",
    "#                     tower += 1.\n",
    "#                 elif t.name == 'Pi': \n",
    "#                     tower += 1.\n",
    "#                 elif t.name == 'CL': \n",
    "#                     pair += 1.\n",
    "#                 elif t.name == 'CPi': \n",
    "#                     pair += 1.\n",
    "#                 elif t.name == 'LC': \n",
    "#                     pair += 1.\n",
    "#                 elif t.name == 'LPi': \n",
    "#                     pair += 1.\n",
    "#                 elif t.name == 'PiC': \n",
    "#                     pair += 1.\n",
    "#                 elif t.name == 'PiL': \n",
    "#                     pair += 1.\n",
    "#                 elif t.name == '8': \n",
    "#                     frag += 1.\n",
    "#                 elif t.name == '8b': \n",
    "#                     frag += 1.\n",
    "#                 elif t.name == '7': \n",
    "#                     frag += 1.\n",
    "#                 elif t.name == '6': \n",
    "#                     frag += 1.\n",
    "#                 elif t.name == '5': \n",
    "#                     frag += 1.\n",
    "#                 elif t.name == '4': \n",
    "#                     frag += 1.\n",
    "#                 elif t.name == '3': \n",
    "#                     frag += 1.\n",
    "#                 elif t.name == '2': \n",
    "#                     frag += 1.\n",
    "#                 elif t.name == '1': \n",
    "#                     frag += 1.\n",
    "\n",
    "#     return frag, tower, pair\n",
    "\n",
    "# path = './data/model/dsls/'\n",
    "\n",
    "# ffrags_low_mean = []\n",
    "# ffrags_med_mean = []\n",
    "# ffrags_high_mean = []\n",
    "# ttowers_low_mean = []\n",
    "# ttowers_med_mean = []\n",
    "# ttowers_high_mean = []\n",
    "# ppairs_low_mean = []\n",
    "# ppairs_med_mean = []\n",
    "# ppairs_high_mean = []\n",
    "\n",
    "# lst = sorted_alphanumeric(os.listdir(path))\n",
    "# for dirname in lst:\n",
    "#     ffrags_low = []\n",
    "#     ffrags_med = []\n",
    "#     ffrags_high = []\n",
    "#     ttowers_low = []\n",
    "#     ttowers_med = []\n",
    "#     ttowers_high = []\n",
    "#     ppairs_low = []\n",
    "#     ppairs_med = []\n",
    "#     ppairs_high = []\n",
    "\n",
    "#     data_path = path + dirname + '/'\n",
    "#     # print(data_path)\n",
    "#     for name in range(1, 13):\n",
    "#         with open(data_path+f\"{name}.p\", \"rb\") as input_file:\n",
    "#             e = pickle.load(input_file)\n",
    "\n",
    "#         for i, w in enumerate(range(len(e))):\n",
    "#             if i == 0:\n",
    "#                 frag, tower, pair = get_freq(e[w])\n",
    "#                 ffrags_low.append(frag)\n",
    "#                 ttowers_low.append(tower)\n",
    "#                 ppairs_low.append(pair)\n",
    "#             elif i == 1:\n",
    "#                 frag, tower, pair = get_freq(e[w])\n",
    "#                 ffrags_med.append(frag)\n",
    "#                 ttowers_med.append(tower)\n",
    "#                 ppairs_med.append(pair)\n",
    "#             elif i == 3:\n",
    "#                 frag, tower, pair = get_freq(e[w])\n",
    "#                 ffrags_high.append(frag)\n",
    "#                 ttowers_high.append(tower)\n",
    "#                 ppairs_high.append(pair)\n",
    "#     ffrags_low_mean.append(ffrags_low)\n",
    "#     ffrags_med_mean.append(ffrags_med)\n",
    "#     ffrags_high_mean.append(ffrags_high)\n",
    "#     ttowers_low_mean.append(ttowers_low)\n",
    "#     ttowers_med_mean.append(ttowers_med)\n",
    "#     ttowers_high_mean.append(ttowers_high)\n",
    "#     ppairs_low_mean.append(ppairs_low)\n",
    "#     ppairs_med_mean.append(ppairs_med)\n",
    "#     ppairs_high_mean.append(ppairs_high)\n",
    "\n",
    "# ffrags_low_mean = np.array(ffrags_low_mean)\n",
    "# ffrags_med_mean = np.array(ffrags_med_mean)\n",
    "# ffrags_high_mean = np.array(ffrags_high_mean)\n",
    "# ttowers_low_mean = np.array(ttowers_low_mean)\n",
    "# ttowers_med_mean = np.array(ttowers_med_mean)\n",
    "# ttowers_high_mean = np.array(ttowers_high_mean)\n",
    "# ppairs_low_mean = np.array(ppairs_low_mean)\n",
    "# ppairs_med_mean = np.array(ppairs_med_mean)\n",
    "# ppairs_high_mean = np.array(ppairs_high_mean)\n",
    "\n",
    "# ffrags_low_sum = ffrags_low_mean.sum(axis=0)\n",
    "# ffrags_med_sum = ffrags_med_mean.sum(axis=0)\n",
    "# ffrags_high_sum = ffrags_high_mean.sum(axis=0)\n",
    "# ttowers_low_sum = ttowers_low_mean.sum(axis=0)\n",
    "# ttowers_med_sum = ttowers_med_mean.sum(axis=0)\n",
    "# ttowers_high_sum = ttowers_high_mean.sum(axis=0)\n",
    "# ppairs_low_sum = ppairs_low_mean.sum(axis=0)\n",
    "# ppairs_med_sum = ppairs_med_mean.sum(axis=0)\n",
    "# ppairs_high_sum = ppairs_high_mean.sum(axis=0)\n",
    "\n",
    "# low = np.vstack([ffrags_low_sum, ttowers_low_sum, ppairs_low_sum])\n",
    "# med = np.vstack([ffrags_med_sum, ttowers_med_sum, ppairs_med_sum])\n",
    "# high = np.vstack([ffrags_high_sum, ttowers_high_sum, ppairs_high_sum])\n",
    "\n",
    "# low = low.sum(axis=0)\n",
    "# med = med.sum(axis=0)\n",
    "# high = high.sum(axis=0)\n",
    "\n",
    "# ffrags_low = ffrags_low_sum/low\n",
    "# ffrags_med = ffrags_med_sum/med\n",
    "# ffrags_high = ffrags_high_sum/high\n",
    "# ttowers_low = ttowers_low_sum/low\n",
    "# ttowers_med = ttowers_med_sum/med\n",
    "# ttowers_high = ttowers_high_sum/high\n",
    "# ppairs_low = ppairs_low_sum/low\n",
    "# ppairs_med = ppairs_med_sum/med\n",
    "# ppairs_high = ppairs_high_sum/high\n",
    "\n",
    "# where_are_NaNs = np.isnan(ffrags_low)\n",
    "# ffrags_low[where_are_NaNs] = 0\n",
    "# where_are_NaNs = np.isnan(ffrags_med)\n",
    "# ffrags_med[where_are_NaNs] = 0\n",
    "# where_are_NaNs = np.isnan(ffrags_high)\n",
    "# ffrags_high[where_are_NaNs] = 0\n",
    "# where_are_NaNs = np.isnan(ttowers_low)\n",
    "# ttowers_low[where_are_NaNs] = 0\n",
    "# where_are_NaNs = np.isnan(ttowers_med)\n",
    "# ttowers_med[where_are_NaNs] = 0\n",
    "# where_are_NaNs = np.isnan(ttowers_high)\n",
    "# ttowers_high[where_are_NaNs] = 0\n",
    "# where_are_NaNs = np.isnan(ppairs_low)\n",
    "# ppairs_low[where_are_NaNs] = 0\n",
    "# where_are_NaNs = np.isnan(ppairs_med)\n",
    "# ppairs_med[where_are_NaNs] = 0\n",
    "# where_are_NaNs = np.isnan(ppairs_high)\n",
    "# ppairs_high[where_are_NaNs] = 0\n",
    "\n",
    "# df_const = np.array([ffrags_high, ffrags_med, ffrags_low])\n",
    "# df_one = np.array([ttowers_high, ttowers_med, ttowers_low])\n",
    "# df_two = np.array([ppairs_high, ppairs_med, ppairs_low])\n",
    "\n",
    "# xticks = ['high', 'med', 'low']\n",
    "# with sns.axes_style(\"white\"):\n",
    "#     sns.set_style(\"ticks\")\n",
    "#     sns.set_context(\"talk\")        \n",
    "\n",
    "#     # plot details\n",
    "#     bar_width = 0.25\n",
    "#     two_bar_positions = np.arange(3)\n",
    "#     one_bar_positions = two_bar_positions + bar_width\n",
    "#     const_bar_positions = one_bar_positions + bar_width\n",
    "\n",
    "#     rgba_colors_const = np.zeros((3,4))\n",
    "#     rgba_colors_const[:,0] = 1.0\n",
    "#     rgba_colors_one = np.zeros((3,4))\n",
    "#     rgba_colors_one[:,1] = 0.5019607843137255\n",
    "#     rgba_colors_two = np.zeros((3,4))\n",
    "#     rgba_colors_two[:,2] = 1.0\n",
    "\n",
    "#     for i in range(12):\n",
    "#         rgba_colors_const[:, 3] = df_const[:,i]\n",
    "#         rgba_colors_one[:, 3] = df_one[:,i]\n",
    "#         rgba_colors_two[:, 3] = df_two[:,i]\n",
    "#         const_labels = [str(x) for x in rgba_colors_const]\n",
    "#         one_labels = [str(x) for x in rgba_colors_one]\n",
    "#         two_labels = [str(x) for x in rgba_colors_two]\n",
    "\n",
    "#         const_bar = plt.barh(const_bar_positions, [1, 1, 1], bar_width,\n",
    "#                                 color=rgba_colors_const,\n",
    "#                                 left=i*1,\n",
    "#                                 tick_label=const_labels)\n",
    "#         for j, p in enumerate(const_bar.patches):\n",
    "#             if rgba_colors_const[j][3]>=0.6:\n",
    "#                 clr = 'white'\n",
    "#             else:\n",
    "#                 clr = 'black'\n",
    "#             plt.text(p.get_x()+0.5*p.get_width(),p.get_y()+0.5*p.get_height(),str(round(rgba_colors_const[j][3],2)),color=clr,ha='center', va='center', fontsize=12.5)\n",
    "#         one_bar = plt.barh(one_bar_positions, [1, 1, 1], bar_width,\n",
    "#                                 color=rgba_colors_one,\n",
    "#                                 left=i*1,\n",
    "#                                 tick_label=one_labels)\n",
    "#         for j, p in enumerate(one_bar.patches):\n",
    "#             if rgba_colors_one[j][3]>=0.6:\n",
    "#                 clr = 'white'\n",
    "#             else:\n",
    "#                 clr = 'black'\n",
    "#             plt.text(p.get_x()+0.5*p.get_width(),p.get_y()+0.5*p.get_height(),str(round(rgba_colors_one[j][3],2)),color=clr,ha='center', va='center', fontsize=12.5)\n",
    "#         two_bar = plt.barh(two_bar_positions, [1, 1, 1], bar_width,\n",
    "#                                 color=rgba_colors_two,\n",
    "#                                 left=i*1,\n",
    "#                                 tick_label=two_labels)\n",
    "#         for j, p in enumerate(two_bar.patches):\n",
    "#             if rgba_colors_two[j][3]>=0.6:\n",
    "#                 clr = 'white'\n",
    "#             else:\n",
    "#                 clr = 'black'\n",
    "#             plt.text(p.get_x()+0.5*p.get_width(),p.get_y()+0.5*p.get_height(),str(round(rgba_colors_two[j][3],2)),color=clr,ha='center', va='center', fontsize=12.5)\n",
    "#     plt.yticks(one_bar_positions, xticks)\n",
    "#     plt.xticks(np.arange(0.5, 12, step=1), [x for x in np.arange(1, 13, step=1)])\n",
    "#     plt.xlabel('trial num')\n",
    "#     plt.ylabel('cost of learning')\n",
    "#     const_patch = mpatches.Patch(color='red', label='const')\n",
    "#     one_patch = mpatches.Patch(color='green', label='one')\n",
    "#     two_patch = mpatches.Patch(color='blue', label='two')\n",
    "#     # plt.legend(handles=[const_patch, two_patch, one_patch], bbox_to_anchor=(.91, .55))\n",
    "#     sns.despine()  \n",
    "#     plt.show()\n",
    "# #     plt.savefig('/Users/cogtoolslab/Desktop/fig.pdf')\n",
    "# #     plt.savefig('~/compositional-abstractions/figures/cogsci21_fragments_all_sequences.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41a2746",
   "metadata": {},
   "source": [
    "## Part 3: Representing scenes more concisely with refactored programs\n",
    "\n",
    "Now we have inferred the libraries of part concepts available to each participant in each trial. These part concepts, or program fragments, allow each scene program to be expressed more efficiently. In the next notebook, the model makes a decision about whether to use the most efficient program available to it, or play it safe and use lower-level language (about individual blocks). Before we get there, we first need to find these efficient programs.\n",
    "\n",
    "How to search for programs given a DSL is an interesting research question in itself. Here, however, our focus is on how people choose between more or less efficient ways of expressing a concept, given uncertainty about what their partner will understand. For our purposes, we just need to select the single most efficient program that represents each scene. Fortunately for us, Dreamcoder libraries uniquely determine this most efficient programs. Programs involving larger abstractions can easily be found through enumeration. For less compressed programs, enumeration takes too long, however, we can simply swap in the learned abstractions from our DSLs through string-matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc09493e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 3.3\n",
    "w_position = w_index[w]\n",
    "\n",
    "# ground-truth programs fed into library learning\n",
    "tower_strings = {\"CL\" :\"(h (l 1) v v (r 1) h (r 12) h (l 4) h (l 1) v v)\",\n",
    "                \"CPi\": \"(h (l 1) v v (r 1) h (r 6) v (r 6) v (l 5) h (r 4) h)\",\n",
    "                \"LPi\": \"(h (l 4) h (l 1) v v (r 9) v (r 6) v (l 5) h (r 4) h)\",\n",
    "                \"LC\": \"(h (l 4) h (l 1) v v (r 12) h (l 1) v v (r 1) h)\",\n",
    "                \"PiC\": \"(v (r 6) v (l 5) h (r 4) h (r 7) h (l 1) v v (r 1) h)\",\n",
    "                \"PiL\": \"(v (r 6) v (l 5) h (r 4) h (r 9) h (l 4) h (l 1) v v)\"}\n",
    "\n",
    "\n",
    "# base dsl for webppl-readable strings\n",
    "base_dsl = ['h', \n",
    " 'v', \n",
    " 'l_0',\n",
    " 'l_1',\n",
    " 'l_2',\n",
    " 'l_3',\n",
    " 'l_4',\n",
    " 'l_5',\n",
    " 'l_6',\n",
    " 'l_7',\n",
    " 'l_8',\n",
    " 'l_9',\n",
    " 'l_10',\n",
    " 'l_11',\n",
    " 'l_12',\n",
    " 'r_0',\n",
    " 'r_1',\n",
    " 'r_2',\n",
    " 'r_3',\n",
    " 'r_4',\n",
    " 'r_5',\n",
    " 'r_6',\n",
    " 'r_7',\n",
    " 'r_8',\n",
    " 'r_9',\n",
    " 'r_10',\n",
    " 'r_11',\n",
    " 'r_12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1fc951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partially_chunked_programs(trial_datum):\n",
    "    '''\n",
    "    This helper function converts minimum length programs into longer versions that replace each chunk with its base-DSL equivalent.\n",
    "    '''\n",
    "    \n",
    "    chunk_lambdas = trial_datum['dsl_lambda'][16:]\n",
    "    chunk_names = trial_datum['chunks']\n",
    "\n",
    "    progs = [trial_datum['min_program']]\n",
    "\n",
    "    for prog in progs:\n",
    "        for i, chunk_name in enumerate(chunk_names):\n",
    "            new_prog = prog.replace(chunk_name, parse(chunk_lambdas[i], base_dsl_only=True))\n",
    "            if not(new_prog in progs):\n",
    "                progs.append(new_prog)\n",
    "    \n",
    "    progs_with_length = {p: len(p.split(' ')) for p in progs}\n",
    "    return progs_with_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4097c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CL': 'h l_1 v v r_1 h r_12 h l_4 h l_1 v v',\n",
       " 'CPi': 'h l_1 v v r_1 h r_6 v r_6 v l_5 h r_4 h',\n",
       " 'PiC': 'v r_6 v l_5 h r_4 h r_7 h l_1 v v r_1 h',\n",
       " 'LPi': 'h l_4 h l_1 v v r_9 v r_6 v l_5 h r_4 h',\n",
       " 'LC': 'h l_4 h l_1 v v r_12 h l_1 v v r_1 h',\n",
       " 'PiL': 'v r_6 v l_5 h r_4 h r_9 h l_4 h l_1 v v'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_tower_programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ff405cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all participants\n",
    "\n",
    "verbose = False\n",
    "\n",
    "for ppt in range(1,50):\n",
    "    \n",
    "    trial_data = []\n",
    "\n",
    "    # towerpairs plus trial numbers\n",
    "    trial_tasks = [SupervisedTower(tower_pair + str(i+1), tower_strings[tower_pair]) for i, tower_pair in enumerate(trial_seqs[ppt])]\n",
    "\n",
    "    # get dsls for all trials\n",
    "    trial_grammars = {trial_tasks[i]: Grammar.uniform(primitives + dsls[ppt][i][w_position]) for i in range (1,12)}\n",
    "    trial_grammars[trial_tasks[0]] = Grammar.uniform(primitives)\n",
    "    \n",
    "    for trial_num in range(1,13):\n",
    "        \n",
    "        scene = trial_seqs[ppt][trial_num-1] # get trial scene\n",
    "        if verbose: print(scene)\n",
    "        chunks = list(map(lambda x: parse(str(x)), trial_grammars[trial_tasks[trial_num-1]].primitives[16:]))\n",
    "        manual_program = manual_tower_programs[scene]\n",
    "        min_program = manual_program\n",
    "\n",
    "        if len(dsls[ppt][trial_num][w_position]) == 0: # if no chunks learned, take input program\n",
    "            \n",
    "            if verbose: print(min_program)\n",
    "\n",
    "        else: # if some chunks learned, swap in chunks into input program\n",
    "\n",
    "            # find translation between dsl substring and chunk\n",
    "            chunk_tranlations_trimmed = list(map(lambda x: parse(str(x), base_dsl_only=True), dsls[ppt][trial_num-1][w_position]))\n",
    "\n",
    "            # order chunks from largest to smallest\n",
    "            chunk_dict = {chunks[i]: chunk_tranlations_trimmed[i] for i in range(0, len(chunks))}\n",
    "            sorted_chunk_dict = sorted(chunk_dict.items(), key=lambda item: len(item[1].split()), reverse=True)\n",
    "            if verbose: print(sorted_chunk_dict)\n",
    "\n",
    "            # start with base dsl program\n",
    "            chunked_program = manual_program\n",
    "                \n",
    "            # swap chunks in from largest to smallest\n",
    "            for key, value in sorted_chunk_dict:\n",
    "                chunked_program = chunked_program.replace(value, key)\n",
    "            \n",
    "            if verbose:\n",
    "                print('manual:', manual_program)\n",
    "                print('chunked:', chunked_program)\n",
    "            \n",
    "            min_program = chunked_program\n",
    "\n",
    "\n",
    "        trial_data.append(\n",
    "            {\n",
    "            'ppt' : ppt, # just added\n",
    "            'trial_num': trial_num,\n",
    "            'towers': scene,\n",
    "            'dsl_lambda': [str(p) for p in trial_grammars[trial_tasks[trial_num-1]].primitives],\n",
    "            'chunks': chunks,\n",
    "            'dsl': base_dsl + list(map(lambda s: parse(str(s)), trial_grammars[trial_tasks[trial_num-1]].primitives[16:])),\n",
    "            #         'trial_programs': trial_programs_sorted,\n",
    "            'min_program': min_program\n",
    "            })\n",
    "    \n",
    "    # find programs with abstractions replaced with base dsl only\n",
    "    for i, trial_datum in enumerate(trial_data):\n",
    "        trial_datum['programs_with_length'] = get_partially_chunked_programs(trial_datum)\n",
    "\n",
    "#     # # This will save results within lib-learning directory. \n",
    "    with open(\"../demo/data/model/programs/programs_ppt_\" + str(ppt) + \".json\", \"w\") as write_file:\n",
    "         json.dump(trial_data, write_file)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f348f86d",
   "metadata": {},
   "source": [
    "### <span style=\"color: orange\"> Exercise: explore programs</span>\n",
    "\n",
    "Inspect the programs learned across trials.  \n",
    "Across \"participants\", how does the length of these programs change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2294f91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppt = 4\n",
    "\n",
    "with open(\"../demo/data/model/programs/programs_ppt_\" + str(ppt) + \".json\", \"r\") as read_file:\n",
    "    trial_data = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "802190d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h l_1 v v r_1 h r_6 v r_6 v l_5 h r_4 h',\n",
       " 'h l_4 h l_1 v v r_12 h l_1 v v r_1 h',\n",
       " 'h l_4 h l_1 v v r_9 v r_6 v l_5 h r_4 h',\n",
       " 'chunk_8b r_1 h r_12 h l_4 chunk_8b',\n",
       " 'v r_6 v l_5 h r_4 h r_9 h l_4 chunk_8',\n",
       " 'chunk_Pi r_4 h r_7 chunk_C',\n",
       " 'chunk_L r_9 chunk_Pi',\n",
       " 'chunk_C r_6 chunk_Pi',\n",
       " 'chunk_L r_12 chunk_C',\n",
       " 'chunk_Pi r_7 chunk_C',\n",
       " 'chunk_C r_12 chunk_L',\n",
       " 'chunk_Pi r_9 chunk_L']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[trial['min_program'] for trial in trial_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4fce13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ppt': 4,\n",
       "  'trial_num': 1,\n",
       "  'towers': 'CPi',\n",
       "  'dsl_lambda': ['2x1',\n",
       "   '1x2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '6',\n",
       "   '7',\n",
       "   '8',\n",
       "   '9',\n",
       "   '10',\n",
       "   '11',\n",
       "   '12',\n",
       "   'left',\n",
       "   'right'],\n",
       "  'chunks': [],\n",
       "  'dsl': ['h',\n",
       "   'v',\n",
       "   'l_0',\n",
       "   'l_1',\n",
       "   'l_2',\n",
       "   'l_3',\n",
       "   'l_4',\n",
       "   'l_5',\n",
       "   'l_6',\n",
       "   'l_7',\n",
       "   'l_8',\n",
       "   'l_9',\n",
       "   'l_10',\n",
       "   'l_11',\n",
       "   'l_12',\n",
       "   'r_0',\n",
       "   'r_1',\n",
       "   'r_2',\n",
       "   'r_3',\n",
       "   'r_4',\n",
       "   'r_5',\n",
       "   'r_6',\n",
       "   'r_7',\n",
       "   'r_8',\n",
       "   'r_9',\n",
       "   'r_10',\n",
       "   'r_11',\n",
       "   'r_12'],\n",
       "  'min_program': 'h l_1 v v r_1 h r_6 v r_6 v l_5 h r_4 h',\n",
       "  'programs_with_length': {'h l_1 v v r_1 h r_6 v r_6 v l_5 h r_4 h': 14}},\n",
       " {'ppt': 4,\n",
       "  'trial_num': 2,\n",
       "  'towers': 'LC',\n",
       "  'dsl_lambda': ['2x1',\n",
       "   '1x2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '6',\n",
       "   '7',\n",
       "   '8',\n",
       "   '9',\n",
       "   '10',\n",
       "   '11',\n",
       "   '12',\n",
       "   'left',\n",
       "   'right'],\n",
       "  'chunks': [],\n",
       "  'dsl': ['h',\n",
       "   'v',\n",
       "   'l_0',\n",
       "   'l_1',\n",
       "   'l_2',\n",
       "   'l_3',\n",
       "   'l_4',\n",
       "   'l_5',\n",
       "   'l_6',\n",
       "   'l_7',\n",
       "   'l_8',\n",
       "   'l_9',\n",
       "   'l_10',\n",
       "   'l_11',\n",
       "   'l_12',\n",
       "   'r_0',\n",
       "   'r_1',\n",
       "   'r_2',\n",
       "   'r_3',\n",
       "   'r_4',\n",
       "   'r_5',\n",
       "   'r_6',\n",
       "   'r_7',\n",
       "   'r_8',\n",
       "   'r_9',\n",
       "   'r_10',\n",
       "   'r_11',\n",
       "   'r_12'],\n",
       "  'min_program': 'h l_4 h l_1 v v r_12 h l_1 v v r_1 h',\n",
       "  'programs_with_length': {'h l_4 h l_1 v v r_12 h l_1 v v r_1 h': 13}},\n",
       " {'ppt': 4,\n",
       "  'trial_num': 3,\n",
       "  'towers': 'LPi',\n",
       "  'dsl_lambda': ['2x1',\n",
       "   '1x2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '6',\n",
       "   '7',\n",
       "   '8',\n",
       "   '9',\n",
       "   '10',\n",
       "   '11',\n",
       "   '12',\n",
       "   'left',\n",
       "   'right'],\n",
       "  'chunks': [],\n",
       "  'dsl': ['h',\n",
       "   'v',\n",
       "   'l_0',\n",
       "   'l_1',\n",
       "   'l_2',\n",
       "   'l_3',\n",
       "   'l_4',\n",
       "   'l_5',\n",
       "   'l_6',\n",
       "   'l_7',\n",
       "   'l_8',\n",
       "   'l_9',\n",
       "   'l_10',\n",
       "   'l_11',\n",
       "   'l_12',\n",
       "   'r_0',\n",
       "   'r_1',\n",
       "   'r_2',\n",
       "   'r_3',\n",
       "   'r_4',\n",
       "   'r_5',\n",
       "   'r_6',\n",
       "   'r_7',\n",
       "   'r_8',\n",
       "   'r_9',\n",
       "   'r_10',\n",
       "   'r_11',\n",
       "   'r_12'],\n",
       "  'min_program': 'h l_4 h l_1 v v r_9 v r_6 v l_5 h r_4 h',\n",
       "  'programs_with_length': {'h l_4 h l_1 v v r_9 v r_6 v l_5 h r_4 h': 14}},\n",
       " {'ppt': 4,\n",
       "  'trial_num': 4,\n",
       "  'towers': 'CL',\n",
       "  'dsl_lambda': ['2x1',\n",
       "   '1x2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '6',\n",
       "   '7',\n",
       "   '8',\n",
       "   '9',\n",
       "   '10',\n",
       "   '11',\n",
       "   '12',\n",
       "   'left',\n",
       "   'right',\n",
       "   '#(lambda (lambda (2x1 (left 1 (1x2 (1x2 (right $0 $1)))))))'],\n",
       "  'chunks': ['chunk_8b'],\n",
       "  'dsl': ['h',\n",
       "   'v',\n",
       "   'l_0',\n",
       "   'l_1',\n",
       "   'l_2',\n",
       "   'l_3',\n",
       "   'l_4',\n",
       "   'l_5',\n",
       "   'l_6',\n",
       "   'l_7',\n",
       "   'l_8',\n",
       "   'l_9',\n",
       "   'l_10',\n",
       "   'l_11',\n",
       "   'l_12',\n",
       "   'r_0',\n",
       "   'r_1',\n",
       "   'r_2',\n",
       "   'r_3',\n",
       "   'r_4',\n",
       "   'r_5',\n",
       "   'r_6',\n",
       "   'r_7',\n",
       "   'r_8',\n",
       "   'r_9',\n",
       "   'r_10',\n",
       "   'r_11',\n",
       "   'r_12',\n",
       "   'chunk_8b'],\n",
       "  'min_program': 'chunk_8b r_1 h r_12 h l_4 chunk_8b',\n",
       "  'programs_with_length': {'chunk_8b r_1 h r_12 h l_4 chunk_8b': 7,\n",
       "   'h l_1 v v r_1 h r_12 h l_4 h l_1 v v': 13}},\n",
       " {'ppt': 4,\n",
       "  'trial_num': 5,\n",
       "  'towers': 'PiL',\n",
       "  'dsl_lambda': ['2x1',\n",
       "   '1x2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '6',\n",
       "   '7',\n",
       "   '8',\n",
       "   '9',\n",
       "   '10',\n",
       "   '11',\n",
       "   '12',\n",
       "   'left',\n",
       "   'right',\n",
       "   '#(lambda (2x1 (left 1 (1x2 (1x2 $0)))))'],\n",
       "  'chunks': ['chunk_8'],\n",
       "  'dsl': ['h',\n",
       "   'v',\n",
       "   'l_0',\n",
       "   'l_1',\n",
       "   'l_2',\n",
       "   'l_3',\n",
       "   'l_4',\n",
       "   'l_5',\n",
       "   'l_6',\n",
       "   'l_7',\n",
       "   'l_8',\n",
       "   'l_9',\n",
       "   'l_10',\n",
       "   'l_11',\n",
       "   'l_12',\n",
       "   'r_0',\n",
       "   'r_1',\n",
       "   'r_2',\n",
       "   'r_3',\n",
       "   'r_4',\n",
       "   'r_5',\n",
       "   'r_6',\n",
       "   'r_7',\n",
       "   'r_8',\n",
       "   'r_9',\n",
       "   'r_10',\n",
       "   'r_11',\n",
       "   'r_12',\n",
       "   'chunk_8'],\n",
       "  'min_program': 'v r_6 v l_5 h r_4 h r_9 h l_4 chunk_8',\n",
       "  'programs_with_length': {'v r_6 v l_5 h r_4 h r_9 h l_4 chunk_8': 11,\n",
       "   'v r_6 v l_5 h r_4 h r_9 h l_4 h l_1 v v': 14}},\n",
       " {'ppt': 4,\n",
       "  'trial_num': 6,\n",
       "  'towers': 'PiC',\n",
       "  'dsl_lambda': ['2x1',\n",
       "   '1x2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '6',\n",
       "   '7',\n",
       "   '8',\n",
       "   '9',\n",
       "   '10',\n",
       "   '11',\n",
       "   '12',\n",
       "   'left',\n",
       "   'right',\n",
       "   '#(lambda (2x1 (left 1 (1x2 (1x2 $0)))))',\n",
       "   '#(lambda (lambda (1x2 (right 6 (1x2 (left 5 (2x1 (right $0 (2x1 $1)))))))))',\n",
       "   '#(lambda (2x1 (left 4 (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) $0))))',\n",
       "   '#(lambda (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) (right 1 (2x1 $0))))'],\n",
       "  'chunks': ['chunk_8', 'chunk_Pi', 'chunk_L', 'chunk_C'],\n",
       "  'dsl': ['h',\n",
       "   'v',\n",
       "   'l_0',\n",
       "   'l_1',\n",
       "   'l_2',\n",
       "   'l_3',\n",
       "   'l_4',\n",
       "   'l_5',\n",
       "   'l_6',\n",
       "   'l_7',\n",
       "   'l_8',\n",
       "   'l_9',\n",
       "   'l_10',\n",
       "   'l_11',\n",
       "   'l_12',\n",
       "   'r_0',\n",
       "   'r_1',\n",
       "   'r_2',\n",
       "   'r_3',\n",
       "   'r_4',\n",
       "   'r_5',\n",
       "   'r_6',\n",
       "   'r_7',\n",
       "   'r_8',\n",
       "   'r_9',\n",
       "   'r_10',\n",
       "   'r_11',\n",
       "   'r_12',\n",
       "   'chunk_8',\n",
       "   'chunk_Pi',\n",
       "   'chunk_L',\n",
       "   'chunk_C'],\n",
       "  'min_program': 'chunk_Pi r_4 h r_7 chunk_C',\n",
       "  'programs_with_length': {'chunk_Pi r_4 h r_7 chunk_C': 5,\n",
       "   'v r_6 v l_5 h r_4 h r_7 chunk_C': 9,\n",
       "   'chunk_Pi r_4 h r_7 h l_1 v v r_1 h': 10,\n",
       "   'v r_6 v l_5 h r_4 h r_7 h l_1 v v r_1 h': 14}},\n",
       " {'ppt': 4,\n",
       "  'trial_num': 7,\n",
       "  'towers': 'LPi',\n",
       "  'dsl_lambda': ['2x1',\n",
       "   '1x2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '6',\n",
       "   '7',\n",
       "   '8',\n",
       "   '9',\n",
       "   '10',\n",
       "   '11',\n",
       "   '12',\n",
       "   'left',\n",
       "   'right',\n",
       "   '#(lambda (2x1 (left 1 (1x2 (1x2 $0)))))',\n",
       "   '#(lambda (1x2 (right 6 (1x2 (left 5 (2x1 (right 4 (2x1 $0))))))))',\n",
       "   '#(lambda (2x1 (left 4 (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) $0))))',\n",
       "   '#(lambda (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) (right 1 (2x1 $0))))'],\n",
       "  'chunks': ['chunk_8', 'chunk_Pi', 'chunk_L', 'chunk_C'],\n",
       "  'dsl': ['h',\n",
       "   'v',\n",
       "   'l_0',\n",
       "   'l_1',\n",
       "   'l_2',\n",
       "   'l_3',\n",
       "   'l_4',\n",
       "   'l_5',\n",
       "   'l_6',\n",
       "   'l_7',\n",
       "   'l_8',\n",
       "   'l_9',\n",
       "   'l_10',\n",
       "   'l_11',\n",
       "   'l_12',\n",
       "   'r_0',\n",
       "   'r_1',\n",
       "   'r_2',\n",
       "   'r_3',\n",
       "   'r_4',\n",
       "   'r_5',\n",
       "   'r_6',\n",
       "   'r_7',\n",
       "   'r_8',\n",
       "   'r_9',\n",
       "   'r_10',\n",
       "   'r_11',\n",
       "   'r_12',\n",
       "   'chunk_8',\n",
       "   'chunk_Pi',\n",
       "   'chunk_L',\n",
       "   'chunk_C'],\n",
       "  'min_program': 'chunk_L r_9 chunk_Pi',\n",
       "  'programs_with_length': {'chunk_L r_9 chunk_Pi': 3,\n",
       "   'chunk_L r_9 v r_6 v l_5 h r_4 h': 9,\n",
       "   'h l_4 h l_1 v v r_9 chunk_Pi': 8,\n",
       "   'h l_4 h l_1 v v r_9 v r_6 v l_5 h r_4 h': 14}},\n",
       " {'ppt': 4,\n",
       "  'trial_num': 8,\n",
       "  'towers': 'CPi',\n",
       "  'dsl_lambda': ['2x1',\n",
       "   '1x2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '6',\n",
       "   '7',\n",
       "   '8',\n",
       "   '9',\n",
       "   '10',\n",
       "   '11',\n",
       "   '12',\n",
       "   'left',\n",
       "   'right',\n",
       "   '#(lambda (1x2 (right 6 (1x2 (left 5 (2x1 (right 4 (2x1 $0))))))))',\n",
       "   '#(lambda (2x1 (left 1 (1x2 (1x2 $0)))))',\n",
       "   '#(lambda (2x1 (left 4 (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) $0))))',\n",
       "   '#(lambda (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) (right 1 (2x1 $0))))'],\n",
       "  'chunks': ['chunk_Pi', 'chunk_8', 'chunk_L', 'chunk_C'],\n",
       "  'dsl': ['h',\n",
       "   'v',\n",
       "   'l_0',\n",
       "   'l_1',\n",
       "   'l_2',\n",
       "   'l_3',\n",
       "   'l_4',\n",
       "   'l_5',\n",
       "   'l_6',\n",
       "   'l_7',\n",
       "   'l_8',\n",
       "   'l_9',\n",
       "   'l_10',\n",
       "   'l_11',\n",
       "   'l_12',\n",
       "   'r_0',\n",
       "   'r_1',\n",
       "   'r_2',\n",
       "   'r_3',\n",
       "   'r_4',\n",
       "   'r_5',\n",
       "   'r_6',\n",
       "   'r_7',\n",
       "   'r_8',\n",
       "   'r_9',\n",
       "   'r_10',\n",
       "   'r_11',\n",
       "   'r_12',\n",
       "   'chunk_Pi',\n",
       "   'chunk_8',\n",
       "   'chunk_L',\n",
       "   'chunk_C'],\n",
       "  'min_program': 'chunk_C r_6 chunk_Pi',\n",
       "  'programs_with_length': {'chunk_C r_6 chunk_Pi': 3,\n",
       "   'chunk_C r_6 v r_6 v l_5 h r_4 h': 9,\n",
       "   'h l_1 v v r_1 h r_6 chunk_Pi': 8,\n",
       "   'h l_1 v v r_1 h r_6 v r_6 v l_5 h r_4 h': 14}},\n",
       " {'ppt': 4,\n",
       "  'trial_num': 9,\n",
       "  'towers': 'LC',\n",
       "  'dsl_lambda': ['2x1',\n",
       "   '1x2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '6',\n",
       "   '7',\n",
       "   '8',\n",
       "   '9',\n",
       "   '10',\n",
       "   '11',\n",
       "   '12',\n",
       "   'left',\n",
       "   'right',\n",
       "   '#(lambda (1x2 (right 6 (1x2 (left 5 (2x1 (right 4 (2x1 $0))))))))',\n",
       "   '#(lambda (2x1 (left 1 (1x2 (1x2 $0)))))',\n",
       "   '#(lambda (2x1 (left 4 (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) $0))))',\n",
       "   '#(lambda (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) (right 1 (2x1 $0))))'],\n",
       "  'chunks': ['chunk_Pi', 'chunk_8', 'chunk_L', 'chunk_C'],\n",
       "  'dsl': ['h',\n",
       "   'v',\n",
       "   'l_0',\n",
       "   'l_1',\n",
       "   'l_2',\n",
       "   'l_3',\n",
       "   'l_4',\n",
       "   'l_5',\n",
       "   'l_6',\n",
       "   'l_7',\n",
       "   'l_8',\n",
       "   'l_9',\n",
       "   'l_10',\n",
       "   'l_11',\n",
       "   'l_12',\n",
       "   'r_0',\n",
       "   'r_1',\n",
       "   'r_2',\n",
       "   'r_3',\n",
       "   'r_4',\n",
       "   'r_5',\n",
       "   'r_6',\n",
       "   'r_7',\n",
       "   'r_8',\n",
       "   'r_9',\n",
       "   'r_10',\n",
       "   'r_11',\n",
       "   'r_12',\n",
       "   'chunk_Pi',\n",
       "   'chunk_8',\n",
       "   'chunk_L',\n",
       "   'chunk_C'],\n",
       "  'min_program': 'chunk_L r_12 chunk_C',\n",
       "  'programs_with_length': {'chunk_L r_12 chunk_C': 3,\n",
       "   'h l_4 h l_1 v v r_12 chunk_C': 8,\n",
       "   'chunk_L r_12 h l_1 v v r_1 h': 8,\n",
       "   'h l_4 h l_1 v v r_12 h l_1 v v r_1 h': 13}},\n",
       " {'ppt': 4,\n",
       "  'trial_num': 10,\n",
       "  'towers': 'PiC',\n",
       "  'dsl_lambda': ['2x1',\n",
       "   '1x2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '6',\n",
       "   '7',\n",
       "   '8',\n",
       "   '9',\n",
       "   '10',\n",
       "   '11',\n",
       "   '12',\n",
       "   'left',\n",
       "   'right',\n",
       "   '#(lambda (1x2 (right 6 (1x2 (left 5 (2x1 (right 4 (2x1 $0))))))))',\n",
       "   '#(lambda (2x1 (left 1 (1x2 (1x2 $0)))))',\n",
       "   '#(lambda (2x1 (left 4 (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) $0))))',\n",
       "   '#(lambda (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) (right 1 (2x1 $0))))'],\n",
       "  'chunks': ['chunk_Pi', 'chunk_8', 'chunk_L', 'chunk_C'],\n",
       "  'dsl': ['h',\n",
       "   'v',\n",
       "   'l_0',\n",
       "   'l_1',\n",
       "   'l_2',\n",
       "   'l_3',\n",
       "   'l_4',\n",
       "   'l_5',\n",
       "   'l_6',\n",
       "   'l_7',\n",
       "   'l_8',\n",
       "   'l_9',\n",
       "   'l_10',\n",
       "   'l_11',\n",
       "   'l_12',\n",
       "   'r_0',\n",
       "   'r_1',\n",
       "   'r_2',\n",
       "   'r_3',\n",
       "   'r_4',\n",
       "   'r_5',\n",
       "   'r_6',\n",
       "   'r_7',\n",
       "   'r_8',\n",
       "   'r_9',\n",
       "   'r_10',\n",
       "   'r_11',\n",
       "   'r_12',\n",
       "   'chunk_Pi',\n",
       "   'chunk_8',\n",
       "   'chunk_L',\n",
       "   'chunk_C'],\n",
       "  'min_program': 'chunk_Pi r_7 chunk_C',\n",
       "  'programs_with_length': {'chunk_Pi r_7 chunk_C': 3,\n",
       "   'v r_6 v l_5 h r_4 h r_7 chunk_C': 9,\n",
       "   'chunk_Pi r_7 h l_1 v v r_1 h': 8,\n",
       "   'v r_6 v l_5 h r_4 h r_7 h l_1 v v r_1 h': 14}},\n",
       " {'ppt': 4,\n",
       "  'trial_num': 11,\n",
       "  'towers': 'CL',\n",
       "  'dsl_lambda': ['2x1',\n",
       "   '1x2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '6',\n",
       "   '7',\n",
       "   '8',\n",
       "   '9',\n",
       "   '10',\n",
       "   '11',\n",
       "   '12',\n",
       "   'left',\n",
       "   'right',\n",
       "   '#(lambda (1x2 (right 6 (1x2 (left 5 (2x1 (right 4 (2x1 $0))))))))',\n",
       "   '#(lambda (2x1 (left 1 (1x2 (1x2 $0)))))',\n",
       "   '#(lambda (2x1 (left 4 (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) $0))))',\n",
       "   '#(lambda (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) (right 1 (2x1 $0))))'],\n",
       "  'chunks': ['chunk_Pi', 'chunk_8', 'chunk_L', 'chunk_C'],\n",
       "  'dsl': ['h',\n",
       "   'v',\n",
       "   'l_0',\n",
       "   'l_1',\n",
       "   'l_2',\n",
       "   'l_3',\n",
       "   'l_4',\n",
       "   'l_5',\n",
       "   'l_6',\n",
       "   'l_7',\n",
       "   'l_8',\n",
       "   'l_9',\n",
       "   'l_10',\n",
       "   'l_11',\n",
       "   'l_12',\n",
       "   'r_0',\n",
       "   'r_1',\n",
       "   'r_2',\n",
       "   'r_3',\n",
       "   'r_4',\n",
       "   'r_5',\n",
       "   'r_6',\n",
       "   'r_7',\n",
       "   'r_8',\n",
       "   'r_9',\n",
       "   'r_10',\n",
       "   'r_11',\n",
       "   'r_12',\n",
       "   'chunk_Pi',\n",
       "   'chunk_8',\n",
       "   'chunk_L',\n",
       "   'chunk_C'],\n",
       "  'min_program': 'chunk_C r_12 chunk_L',\n",
       "  'programs_with_length': {'chunk_C r_12 chunk_L': 3,\n",
       "   'chunk_C r_12 h l_4 h l_1 v v': 8,\n",
       "   'h l_1 v v r_1 h r_12 chunk_L': 8,\n",
       "   'h l_1 v v r_1 h r_12 h l_4 h l_1 v v': 13}},\n",
       " {'ppt': 4,\n",
       "  'trial_num': 12,\n",
       "  'towers': 'PiL',\n",
       "  'dsl_lambda': ['2x1',\n",
       "   '1x2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '6',\n",
       "   '7',\n",
       "   '8',\n",
       "   '9',\n",
       "   '10',\n",
       "   '11',\n",
       "   '12',\n",
       "   'left',\n",
       "   'right',\n",
       "   '#(lambda (1x2 (right 6 (1x2 (left 5 (2x1 (right 4 (2x1 $0))))))))',\n",
       "   '#(lambda (2x1 (left 1 (1x2 (1x2 $0)))))',\n",
       "   '#(lambda (2x1 (left 4 (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) $0))))',\n",
       "   '#(lambda (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) (right 1 (2x1 $0))))'],\n",
       "  'chunks': ['chunk_Pi', 'chunk_8', 'chunk_L', 'chunk_C'],\n",
       "  'dsl': ['h',\n",
       "   'v',\n",
       "   'l_0',\n",
       "   'l_1',\n",
       "   'l_2',\n",
       "   'l_3',\n",
       "   'l_4',\n",
       "   'l_5',\n",
       "   'l_6',\n",
       "   'l_7',\n",
       "   'l_8',\n",
       "   'l_9',\n",
       "   'l_10',\n",
       "   'l_11',\n",
       "   'l_12',\n",
       "   'r_0',\n",
       "   'r_1',\n",
       "   'r_2',\n",
       "   'r_3',\n",
       "   'r_4',\n",
       "   'r_5',\n",
       "   'r_6',\n",
       "   'r_7',\n",
       "   'r_8',\n",
       "   'r_9',\n",
       "   'r_10',\n",
       "   'r_11',\n",
       "   'r_12',\n",
       "   'chunk_Pi',\n",
       "   'chunk_8',\n",
       "   'chunk_L',\n",
       "   'chunk_C'],\n",
       "  'min_program': 'chunk_Pi r_9 chunk_L',\n",
       "  'programs_with_length': {'chunk_Pi r_9 chunk_L': 3,\n",
       "   'v r_6 v l_5 h r_4 h r_9 chunk_L': 9,\n",
       "   'chunk_Pi r_9 h l_4 h l_1 v v': 8,\n",
       "   'v r_6 v l_5 h r_4 h r_9 h l_4 h l_1 v v': 14}}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8d09b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
