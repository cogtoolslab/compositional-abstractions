{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57cf1df7-e955-4a46-8be7-bd72d30c652f",
   "metadata": {},
   "source": [
    "# Import empirical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5f3fa8c9-e4bb-4963-a6d4-96fa3aeec6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h',\n",
       " 'v',\n",
       " 'l_0',\n",
       " 'l_1',\n",
       " 'l_2',\n",
       " 'l_3',\n",
       " 'l_4',\n",
       " 'l_5',\n",
       " 'l_6',\n",
       " 'l_7',\n",
       " 'l_8',\n",
       " 'l_9',\n",
       " 'l_10',\n",
       " 'l_11',\n",
       " 'l_12',\n",
       " 'r_0',\n",
       " 'r_1',\n",
       " 'r_2',\n",
       " 'r_3',\n",
       " 'r_4',\n",
       " 'r_5',\n",
       " 'r_6',\n",
       " 'r_7',\n",
       " 'r_8',\n",
       " 'r_9',\n",
       " 'r_10',\n",
       " 'r_11',\n",
       " 'r_12']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools\n",
    "import itertools\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from collections.abc import Mapping\n",
    "\n",
    "\n",
    "d = pd.read_json('../../../model/lib_learning_output/synthesis_output_cogsci_revised/ca_synthesis_cogsci_21_ppt_1.json')\n",
    "d['dsl'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e8da56-7f7c-494e-8b0a-fe9ca33a7d65",
   "metadata": {},
   "source": [
    "## Constructing the lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e0bdc1d5-91fb-4124-a614-9c8a697fb49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we assume all agents start with a basic mapping \n",
    "# between 'h'/'v' in the DSL and 'horizontal'/'vertical' in language\n",
    "class BlockLexicon(dict) :\n",
    "    def __init__(self, primitives, lexemes):\n",
    "        \"\"\"\n",
    "        initialize dictionary subclass\n",
    "        \"\"\"\n",
    "        dict.__init__(self)\n",
    "        self.__dict__ = self\n",
    "        unassigned_lexemes = lexemes.copy()\n",
    "        \n",
    "        for primitive in primitives :\n",
    "            if primitive in ['v', 'h'] :\n",
    "                adjective = 'horizontal' if primitive == 'h' else 'vertical'\n",
    "                self.update({primitive : f'place a {adjective} block.'})\n",
    "            elif primitive[0] in ['l', 'r'] :\n",
    "                distance = primitive.split('_')[1]\n",
    "                direction = 'right' if primitive[0] == 'r' else 'left'\n",
    "                self.update({primitive : f'move to the {direction} by {distance}'})\n",
    "            else :\n",
    "                self.update({primitive: f'place a {unassigned_lexemes.pop()}.'})\n",
    "    def __hash__(self):\n",
    "        return hash(json.dumps(self, sort_keys=True))\n",
    "\n",
    "    def invert(self):\n",
    "        \"\"\"\n",
    "        invert keys and values of a dictionary d\n",
    "        \"\"\"\n",
    "        return {v: k for k, v in self.items()}\n",
    "    \n",
    "    def dsl_to_language(self, e) :\n",
    "        # parse expression e written in DSL into language\n",
    "        return self.get(e)\n",
    "    \n",
    "    def language_to_dsl(self, e) :\n",
    "        # parse expression e written in DSL into language\n",
    "        return self.invert().get(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a79ebcb-bc50-449a-93c3-c9411d658af3",
   "metadata": {},
   "source": [
    "Let's take this class out for a drive. \n",
    "\n",
    "We initialize it with the primitives of the agent's DSL on a given trial and an (ordered) list of available lexemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7eb79b25-0cb4-42fd-bac1-067bc15ea9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h -> place a horizontal block.\n",
      "l_8 -> move to the left by 8\n",
      "chunk_C -> place a blah.\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.04\n",
    "lexemes = ['blah', 'blab', 'bloop', 'bleep']\n",
    "dsl = d['dsl'][10]\n",
    "l = BlockLexicon(dsl, lexemes)\n",
    "print(dsl[0], '->', l.dsl_to_language(dsl[0]))\n",
    "print(dsl[10], '->', l.dsl_to_language(dsl[10]))\n",
    "print(dsl[-1], '->', l.dsl_to_language(dsl[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079c86e7-880f-4736-8029-1d32d9247fc0",
   "metadata": {},
   "source": [
    "and we can also go in the other direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "de665913-c211-4c9d-b001-09f2394c5683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "place a horizontal block. -> h\n",
      "move to the left by 8 -> l_8\n",
      "place a blah. -> chunk_C\n"
     ]
    }
   ],
   "source": [
    "print('place a horizontal block. ->', l.language_to_dsl('place a horizontal block.'))\n",
    "print('move to the left by 8 ->', l.language_to_dsl('move to the left by 8'))\n",
    "print('place a blah. ->', l.language_to_dsl('place a blah.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4af5810-abbb-430e-aa96-62edd23e0b9b",
   "metadata": {},
   "source": [
    "## Adding probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcb9e2c-070d-46f2-bece-f967ffdbcea3",
   "metadata": {},
   "source": [
    "If we were using a probabilistic programming language like WebPPL, we would be able to automatically construct probability distributions over lexicons. But to do this simple example in base python, we're going to manually construct a distribution as another dictionary. The keys will be possible lexicons and the values will be their probabilities. \n",
    "\n",
    "Because the only thing that varies across different lexicons in our example is the word to use for a given chunk, the support of the distribution only needs to be defined over the list of possible mappings (everything else is fixed across lexicons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1b5c583a-9a99-44d7-93c8-d826de1c39b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distribution(dict) :\n",
    "    def __init__(self, support, probabilities):\n",
    "        super().__init__(self)\n",
    "        self.__dict__ = self\n",
    "        for element, probability in zip(support, probabilities) :\n",
    "            self.update({element: probability})\n",
    "\n",
    "    def update(self, element):\n",
    "        for k, prob in element.items():\n",
    "            if k in self :\n",
    "                # if it already exists in the distribution, aggregate probabilities\n",
    "                self[k] += prob\n",
    "            else : \n",
    "               # otherwise add as a new element of the distribution\n",
    "                self[k] = prob\n",
    "\n",
    "class UniformDistribution(Distribution) :\n",
    "    def __init__(self, support):\n",
    "        uniform_probabilities = [ 1/len(support) ] * len(support)\n",
    "        super().__init__(support, uniform_probabilities)\n",
    "        \n",
    "class MarginalDistribution(Distribution) :\n",
    "    def __init__(self, support):\n",
    "        uniform_probabilities = [ float(0) ] * len(support)\n",
    "        super().__init__(support, uniform_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e08889a-8c4d-4e7f-9764-290418abd69f",
   "metadata": {},
   "source": [
    "We can now define a prior over lexicons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "9355dc77-4b9f-478c-a41d-b55db4e16682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'h': 'place a horizontal block.',\n",
       "   'v': 'place a vertical block.',\n",
       "   'l_0': 'move to the left by 0',\n",
       "   'l_1': 'move to the left by 1',\n",
       "   'l_2': 'move to the left by 2',\n",
       "   'l_3': 'move to the left by 3',\n",
       "   'l_4': 'move to the left by 4',\n",
       "   'l_5': 'move to the left by 5',\n",
       "   'l_6': 'move to the left by 6',\n",
       "   'l_7': 'move to the left by 7',\n",
       "   'l_8': 'move to the left by 8',\n",
       "   'l_9': 'move to the left by 9',\n",
       "   'l_10': 'move to the left by 10',\n",
       "   'l_11': 'move to the left by 11',\n",
       "   'l_12': 'move to the left by 12',\n",
       "   'r_0': 'move to the right by 0',\n",
       "   'r_1': 'move to the right by 1',\n",
       "   'r_2': 'move to the right by 2',\n",
       "   'r_3': 'move to the right by 3',\n",
       "   'r_4': 'move to the right by 4',\n",
       "   'r_5': 'move to the right by 5',\n",
       "   'r_6': 'move to the right by 6',\n",
       "   'r_7': 'move to the right by 7',\n",
       "   'r_8': 'move to the right by 8',\n",
       "   'r_9': 'move to the right by 9',\n",
       "   'r_10': 'move to the right by 10',\n",
       "   'r_11': 'move to the right by 11',\n",
       "   'r_12': 'move to the right by 12',\n",
       "   'chunk_8': 'place a bleep.',\n",
       "   'chunk_Pi': 'place a bloop.',\n",
       "   'chunk_L': 'place a blab.',\n",
       "   'chunk_C': 'place a blah.'},\n",
       "  0.041666666666666664)]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_lexicons = [BlockLexicon(dsl, list(mapping)) for mapping in itertools.permutations(lexemes)]\n",
    "prior = UniformDistribution(possible_lexicons)\n",
    "list(prior.items())[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0009db83-2988-415b-84db-284895003536",
   "metadata": {},
   "source": [
    "# Create agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848199ef-ce1e-4ab2-ab8b-7feb07141cbf",
   "metadata": {},
   "source": [
    "Now we're ready to define our Architect and Builder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "59a39bce-9691-437e-99d0-e53c453c2e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as random\n",
    "\n",
    "class Agent() :\n",
    "    def __init__(self, role, trial) :\n",
    "        self.role = role\n",
    "        self.dsl = trial['dsl']\n",
    "        self.beliefs = LexiconDistribution(self.dsl, possible_mappings, uniform_probabilities)\n",
    "        self.utterances = [*[*self.beliefs.keys()][0].values()]\n",
    "\n",
    "    \n",
    "    def build(self, utt) :\n",
    "        ''' \n",
    "        get distribution over dsl actions\n",
    "        marginalizing over different possible meanings\n",
    "        '''\n",
    "        action_dist = MarginalDistribution(self.dsl)\n",
    "        for lexicon, prob in self.beliefs.items() :\n",
    "            action_dist.update({lexicon.language_to_dsl(utt) : prob})\n",
    "        return random.choice(a = [*action_dist.keys()], \n",
    "                             p = [*action_dist.values()])\n",
    "        \n",
    "    def speak(self, target) :\n",
    "        '''\n",
    "        construct distribution over utterances\n",
    "        marginalizing over different possible meanings\n",
    "        '''\n",
    "        utt_dist = MarginalDistribution(self.utterances)\n",
    "        for lexicon, prob in self.beliefs.items() :\n",
    "            utt_dist.update({lexicon.dsl_to_language(target) : prob})\n",
    "        return random.choice(a = [*utt_dist.keys()], \n",
    "                             p = [*utt_dist.values()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e777d9b9-1e58-4cd9-9dbf-90be88d60d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architect choice:  place a horizontal block.\n",
      "builder choice:  h\n"
     ]
    }
   ],
   "source": [
    "architect = Agent('architect', d.loc[0].to_dict())\n",
    "print('architect choice: ', architect.speak('h'))\n",
    "\n",
    "builder = Agent('builder', d.loc[0].to_dict())\n",
    "print('builder choice: ', builder.build('place a horizontal block.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9020e990-db06-4ed1-ac7a-5f153c0c91b1",
   "metadata": {},
   "source": [
    "# Run simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023b0db7-b394-4b59-ba16-c3177bc42ced",
   "metadata": {},
   "source": [
    "Now we have our agents, we just have to run them forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "3d5cafdc-5a6f-451f-a557-ea63c80dd4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h l_4 h l_1 v v r_9 v r_6 v l_5 h r_4 h']\n",
      "['h l_4 h l_1 v v r_12 h l_1 v v r_1 h']\n",
      "['h l_1 v v r_1 h r_6 v r_6 v l_5 h r_4 h']\n",
      "['v r_6 v l_5 h r_4 h r_7 chunk_8b r_1 h', 'v r_6 v l_5 h r_4 h r_7 h l_1 v v r_1 h']\n",
      "['chunk_8b r_1 h r_12 h l_4 chunk_8b', 'h l_1 v v r_1 h r_12 h l_4 h l_1 v v']\n",
      "['chunk_Pi r_9 chunk_L', 'v r_6 v l_5 h r_4 h r_9 chunk_L', 'chunk_Pi r_9 h l_4 h l_1 v v', 'v r_6 v l_5 h r_4 h r_9 h l_4 h l_1 v v']\n",
      "['chunk_Pi r_9 chunk_L', 'v r_6 v l_5 h r_4 h r_9 chunk_L', 'chunk_Pi r_9 h l_4 h l_1 v v', 'v r_6 v l_5 h r_4 h r_9 h l_4 h l_1 v v']\n",
      "['chunk_Pi r_9 chunk_L', 'v r_6 v l_5 h r_4 h r_9 chunk_L', 'chunk_Pi r_9 h l_4 h l_1 v v', 'v r_6 v l_5 h r_4 h r_9 h l_4 h l_1 v v']\n",
      "['chunk_Pi r_9 chunk_L', 'v r_6 v l_5 h r_4 h r_9 chunk_L', 'chunk_Pi r_9 h l_4 h l_1 v v', 'v r_6 v l_5 h r_4 h r_9 h l_4 h l_1 v v']\n",
      "['chunk_Pi r_9 chunk_L', 'v r_6 v l_5 h r_4 h r_9 chunk_L', 'chunk_Pi r_9 h l_4 h l_1 v v', 'v r_6 v l_5 h r_4 h r_9 h l_4 h l_1 v v']\n",
      "['chunk_Pi r_9 chunk_L', 'v r_6 v l_5 h r_4 h r_9 chunk_L', 'chunk_Pi r_9 h l_4 h l_1 v v', 'v r_6 v l_5 h r_4 h r_9 h l_4 h l_1 v v']\n",
      "['chunk_Pi r_9 chunk_L', 'v r_6 v l_5 h r_4 h r_9 chunk_L', 'chunk_Pi r_9 h l_4 h l_1 v v', 'v r_6 v l_5 h r_4 h r_9 h l_4 h l_1 v v']\n"
     ]
    }
   ],
   "source": [
    "for i, trial in d.iterrows() :\n",
    "  # need to sample target program based on program length. Use currTrial.\n",
    "    possiblePrograms = list(trial['programs_with_length'].keys())\n",
    "    print(possiblePrograms)\n",
    "    lengths = np.array(trial['programs_with_length'].values()) \n",
    "    utilities = np.exp(-alpha * lengths)\n",
    "#   var target = sample(Categorical({vs: possiblePrograms, ps: lengths}));\n",
    "#   var numInstructions = currTrial.programs_with_length[target];\n",
    "#   var newData = reduce(function(targetInstruction, acc) {\n",
    "#     var speakerDist = Architect(targetInstruction, currTrial, prevData);\n",
    "#     var utt = sample(speakerDist);\n",
    "#     var listenerDist = Builder(utt, currTrial, prevData);\n",
    "#     var response = sample(listenerDist);\n",
    "#     return {utt: acc.utt.concat(utt),\n",
    "#             response: acc.response.concat(response),\n",
    "#             targetInstruction: acc.targetInstruction.concat(targetInstruction),\n",
    "#             numCorrect: acc.numCorrect + (response == targetInstruction)};\n",
    "#   }, {\n",
    "#     utt: [], response: [], targetInstruction: [], numCorrect: 0\n",
    "#   }, target.split(' '));\n",
    "#   return step(rest(remainingTrials),\n",
    "#               prevData.concat(extend(newData, {numInstructions})));\n",
    "# };"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40a1633-1498-4329-8b68-91ae8bc4d5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
