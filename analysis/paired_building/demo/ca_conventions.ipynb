{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57cf1df7-e955-4a46-8be7-bd72d30c652f",
   "metadata": {},
   "source": [
    "# Import empirical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5f3fa8c9-e4bb-4963-a6d4-96fa3aeec6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h',\n",
       " 'v',\n",
       " 'l_0',\n",
       " 'l_1',\n",
       " 'l_2',\n",
       " 'l_3',\n",
       " 'l_4',\n",
       " 'l_5',\n",
       " 'l_6',\n",
       " 'l_7',\n",
       " 'l_8',\n",
       " 'l_9',\n",
       " 'l_10',\n",
       " 'l_11',\n",
       " 'l_12',\n",
       " 'r_0',\n",
       " 'r_1',\n",
       " 'r_2',\n",
       " 'r_3',\n",
       " 'r_4',\n",
       " 'r_5',\n",
       " 'r_6',\n",
       " 'r_7',\n",
       " 'r_8',\n",
       " 'r_9',\n",
       " 'r_10',\n",
       " 'r_11',\n",
       " 'r_12']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools\n",
    "import itertools\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from collections.abc import Mapping\n",
    "\n",
    "\n",
    "d = pd.read_json('../../../model/lib_learning_output/synthesis_output_cogsci_revised/ca_synthesis_cogsci_21_ppt_1.json')\n",
    "d['dsl'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e8da56-7f7c-494e-8b0a-fe9ca33a7d65",
   "metadata": {},
   "source": [
    "## Constructing the lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e0bdc1d5-91fb-4124-a614-9c8a697fb49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we assume all agents start with a basic mapping \n",
    "# between 'h'/'v' in the DSL and 'horizontal'/'vertical' in language\n",
    "class BlockLexicon(dict) :\n",
    "    def __init__(self, primitives, lexemes):\n",
    "        \"\"\"\n",
    "        initialize dictionary subclass\n",
    "        \"\"\"\n",
    "        dict.__init__(self)\n",
    "        self.__dict__ = self\n",
    "        unassigned_lexemes = lexemes.copy()\n",
    "        \n",
    "        for primitive in primitives :\n",
    "            if primitive in ['v', 'h'] :\n",
    "                adjective = 'horizontal' if primitive == 'h' else 'vertical'\n",
    "                self.update({primitive : f'place a {adjective} block.'})\n",
    "            elif primitive[0] in ['l', 'r'] :\n",
    "                distance = primitive.split('_')[1]\n",
    "                direction = 'right' if primitive[0] == 'r' else 'left'\n",
    "                self.update({primitive : f'move to the {direction} by {distance}'})\n",
    "            else :\n",
    "                self.update({primitive: f'place a {unassigned_lexemes.pop()}.'})\n",
    "    def __hash__(self):\n",
    "        return hash(json.dumps(self, sort_keys=True))\n",
    "\n",
    "    def invert(self):\n",
    "        \"\"\"\n",
    "        invert keys and values of a dictionary d\n",
    "        \"\"\"\n",
    "        return {v: k for k, v in self.items()}\n",
    "    \n",
    "    def dsl_to_language(self, e) :\n",
    "        # parse expression e written in DSL into language\n",
    "        return self.get(e)\n",
    "    \n",
    "    def language_to_dsl(self, e) :\n",
    "        # parse expression e written in DSL into language\n",
    "        return self.invert().get(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a79ebcb-bc50-449a-93c3-c9411d658af3",
   "metadata": {},
   "source": [
    "Let's take this class out for a drive. \n",
    "\n",
    "We initialize it with the primitives of the agent's DSL on a given trial and an (ordered) list of available lexemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7eb79b25-0cb4-42fd-bac1-067bc15ea9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h -> place a horizontal block.\n",
      "l_8 -> move to the left by 8\n",
      "chunk_C -> place a blah.\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.04\n",
    "lexemes = ['blah', 'blab', 'bloop', 'bleep']\n",
    "dsl = d['dsl'][10]\n",
    "l = BlockLexicon(dsl, lexemes)\n",
    "print(dsl[0], '->', l.dsl_to_language(dsl[0]))\n",
    "print(dsl[10], '->', l.dsl_to_language(dsl[10]))\n",
    "print(dsl[-1], '->', l.dsl_to_language(dsl[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079c86e7-880f-4736-8029-1d32d9247fc0",
   "metadata": {},
   "source": [
    "and we can also go in the other direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "de665913-c211-4c9d-b001-09f2394c5683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "place a horizontal block. -> h\n",
      "move to the left by 8 -> l_8\n",
      "place a blah. -> chunk_C\n"
     ]
    }
   ],
   "source": [
    "print('place a horizontal block. ->', l.language_to_dsl('place a horizontal block.'))\n",
    "print('move to the left by 8 ->', l.language_to_dsl('move to the left by 8'))\n",
    "print('place a blah. ->', l.language_to_dsl('place a blah.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4af5810-abbb-430e-aa96-62edd23e0b9b",
   "metadata": {},
   "source": [
    "## Adding probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcb9e2c-070d-46f2-bece-f967ffdbcea3",
   "metadata": {},
   "source": [
    "If we were using a probabilistic programming language like WebPPL, we would be able to automatically construct probability distributions over lexicons. But to do this simple example in base python, we're going to manually construct a distribution as another dictionary. The keys will be possible lexicons and the values will be their probabilities. \n",
    "\n",
    "Because the only thing that varies across different lexicons in our example is the word to use for a given chunk, the support of the distribution only needs to be defined over the list of possible mappings (everything else is fixed across lexicons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1b5c583a-9a99-44d7-93c8-d826de1c39b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distribution(dict) :\n",
    "    def __init__(self, support, probabilities):\n",
    "        super().__init__(self)\n",
    "        self.__dict__ = self\n",
    "        for element, probability in zip(support, probabilities) :\n",
    "            self.update({element: probability})\n",
    "\n",
    "    def update(self, element):\n",
    "        for k, prob in element.items():\n",
    "            if k in self :\n",
    "                # if it already exists in the distribution, aggregate probabilities\n",
    "                self[k] += prob\n",
    "            else : \n",
    "               # otherwise add as a new element of the distribution\n",
    "                self[k] = prob\n",
    "\n",
    "class UniformDistribution(Distribution) :\n",
    "    def __init__(self, support):\n",
    "        uniform_probabilities = [ 1/len(support) ] * len(support)\n",
    "        super().__init__(support, uniform_probabilities)\n",
    "        \n",
    "class MarginalDistribution(Distribution) :\n",
    "    def __init__(self, support):\n",
    "        uniform_probabilities = [ float(0) ] * len(support)\n",
    "        super().__init__(support, uniform_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e08889a-8c4d-4e7f-9764-290418abd69f",
   "metadata": {},
   "source": [
    "We can now define a prior over lexicons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "9355dc77-4b9f-478c-a41d-b55db4e16682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'h': 'place a horizontal block.',\n",
       "   'v': 'place a vertical block.',\n",
       "   'l_0': 'move to the left by 0',\n",
       "   'l_1': 'move to the left by 1',\n",
       "   'l_2': 'move to the left by 2',\n",
       "   'l_3': 'move to the left by 3',\n",
       "   'l_4': 'move to the left by 4',\n",
       "   'l_5': 'move to the left by 5',\n",
       "   'l_6': 'move to the left by 6',\n",
       "   'l_7': 'move to the left by 7',\n",
       "   'l_8': 'move to the left by 8',\n",
       "   'l_9': 'move to the left by 9',\n",
       "   'l_10': 'move to the left by 10',\n",
       "   'l_11': 'move to the left by 11',\n",
       "   'l_12': 'move to the left by 12',\n",
       "   'r_0': 'move to the right by 0',\n",
       "   'r_1': 'move to the right by 1',\n",
       "   'r_2': 'move to the right by 2',\n",
       "   'r_3': 'move to the right by 3',\n",
       "   'r_4': 'move to the right by 4',\n",
       "   'r_5': 'move to the right by 5',\n",
       "   'r_6': 'move to the right by 6',\n",
       "   'r_7': 'move to the right by 7',\n",
       "   'r_8': 'move to the right by 8',\n",
       "   'r_9': 'move to the right by 9',\n",
       "   'r_10': 'move to the right by 10',\n",
       "   'r_11': 'move to the right by 11',\n",
       "   'r_12': 'move to the right by 12',\n",
       "   'chunk_8': 'place a bleep.',\n",
       "   'chunk_Pi': 'place a bloop.',\n",
       "   'chunk_L': 'place a blab.',\n",
       "   'chunk_C': 'place a blah.'},\n",
       "  0.041666666666666664)]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_lexicons = [BlockLexicon(dsl, list(mapping)) for mapping in itertools.permutations(lexemes)]\n",
    "prior = UniformDistribution(possible_lexicons)\n",
    "list(prior.items())[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0009db83-2988-415b-84db-284895003536",
   "metadata": {},
   "source": [
    "# Create agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848199ef-ce1e-4ab2-ab8b-7feb07141cbf",
   "metadata": {},
   "source": [
    "Now we're ready to define our Architect and Builder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "59a39bce-9691-437e-99d0-e53c453c2e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as random\n",
    "\n",
    "class FixedAgent() :\n",
    "    def __init__(self, role, trial) :\n",
    "        self.role = role\n",
    "        self.dsl = trial['dsl']\n",
    "\n",
    "        # initialize beliefs to uniform prior over lexicons\n",
    "        self.beliefs = UniformDistribution(\n",
    "            [BlockLexicon(dsl, list(mapping)) for mapping in itertools.permutations(lexemes)]\n",
    "        )\n",
    "        self.utterances = [*[*self.beliefs.keys()][0].values()]\n",
    "    \n",
    "    def builder_dist(self, utt) :\n",
    "        ''' \n",
    "        get distribution over dsl actions\n",
    "        marginalizing over different possible meanings\n",
    "        '''\n",
    "        builder_dist = MarginalDistribution(self.dsl)\n",
    "        for lexicon, prob in self.beliefs.items() :\n",
    "            builder_dist.update({lexicon.language_to_dsl(utt) : prob})\n",
    "        return builder_dist\n",
    "        \n",
    "    def architect_dist(self, target) :\n",
    "        '''\n",
    "        construct distribution over utterances\n",
    "        marginalizing over different possible meanings\n",
    "        '''\n",
    "        architect_dist = MarginalDistribution(self.utterances)\n",
    "        for lexicon, prob in self.beliefs.items() :\n",
    "            architect_dist.update({lexicon.dsl_to_language(target) : prob})\n",
    "        return architect_dist\n",
    "\n",
    "    def act(self, observation) :\n",
    "        if self.role == 'architect' :\n",
    "            utt_dist = self.architect_dist(observation)\n",
    "            return random.choice(a = [*utt_dist.keys()], p = [*utt_dist.values()])\n",
    "        elif self.role == 'builder' :\n",
    "            action_dist = self.builder_dist(observation)\n",
    "            return random.choice(a = [*action_dist.keys()], p = [*action_dist.values()])\n",
    "        else :\n",
    "            print(f'oops, no policy for {self.role} role')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "e777d9b9-1e58-4cd9-9dbf-90be88d60d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architect choice:  place a horizontal block.\n",
      "builder choice:  h\n"
     ]
    }
   ],
   "source": [
    "architect = FixedAgent('architect', d.loc[0].to_dict())\n",
    "print('architect choice: ', architect.act('h'))\n",
    "\n",
    "builder = FixedAgent('builder', d.loc[0].to_dict())\n",
    "print('builder choice: ', builder.act('place a horizontal block.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9020e990-db06-4ed1-ac7a-5f153c0c91b1",
   "metadata": {},
   "source": [
    "# Run simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023b0db7-b394-4b59-ba16-c3177bc42ced",
   "metadata": {},
   "source": [
    "Now we have our agents, we just have to run them forward!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "3d5cafdc-5a6f-451f-a557-ea63c80dd4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "output = pd.DataFrame({\"utts\": [], \"responses\": [], \"target_program\": [], \"target_length\" : [], \"accs\": []})\n",
    "for i, trial in d.iterrows() :\n",
    "    architect = FixedAgent('architect', trial)\n",
    "    builder = FixedAgent('builder', trial)\n",
    "\n",
    "    # architect selects which program representation to comunicate proportional to length\n",
    "    possiblePrograms = list(trial['programs_with_length'].keys())\n",
    "    possibleLengths = np.array(list(trial['programs_with_length'].values()))\n",
    "    utilities = np.exp(-alpha * possibleLengths) / sum(np.exp(-alpha * possibleLengths))\n",
    "    target_program = random.choice(a = possiblePrograms, p = utilities)\n",
    "\n",
    "    # loop through steps of target program one at a time\n",
    "    utts, responses, accs = [], [], []\n",
    "    for step in target_program.split(' ') :\n",
    "        utt = architect.act(step)\n",
    "        response = builder.act(utt)\n",
    "        utts.append(utt)\n",
    "        responses.append(response)\n",
    "        accs.append(1.0 * (response == step))\n",
    "        \n",
    "    output = pd.concat([output, pd.DataFrame({\n",
    "        \"utts\": utts,\n",
    "        \"responses\": responses,\n",
    "        \"accs\": accs,\n",
    "        \"target_program\": target_program,\n",
    "        \"target_length\" : trial['programs_with_length'][target_program],\n",
    "    })])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858a12ad-eac1-4c94-a115-2f10c42505f7",
   "metadata": {},
   "source": [
    "Wait, why is the accuracy so bad? Well, our agents aren't actually *learning* -- they're continuing to use their initial uniform priors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e771ae8-e64c-409d-8670-bfca342c043b",
   "metadata": {},
   "source": [
    "# Update beliefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe82f26-4c60-451a-a2d5-4ab4f6fb9118",
   "metadata": {},
   "source": [
    "To have our agents learn, we need to extend the agent class to do Bayesian inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfb28cf-8efd-4852-9110-998011ba7312",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningAgent() :\n",
    "    def __init__(self, role, trial) :\n",
    "        self.role = role\n",
    "        self.dsl = trial['dsl']\n",
    "        self.utterances = [*[*self.beliefs.keys()][0].values()]\n",
    "\n",
    "        # initialize to uniform \n",
    "        self.beliefs = UniformDistribution(\n",
    "            [BlockLexicon(dsl, list(mapping)) for mapping in itertools.permutations(lexemes)]\n",
    "        )\n",
    "    \n",
    "    def update_beliefs(data) :\n",
    "        # Initialize posterior to prior values\n",
    "        prior = self.beliefs.copy()\n",
    "        posterior = prior.copy()\n",
    "        \n",
    "        # for each data point, calculate the likelihood of each lexicon\n",
    "        for datum in data : \n",
    "            for lexicon, prob in self.beliefs.items() :\n",
    "                likelihoods.append(lexicon.dsl_to_language(target) \n",
    "\n",
    "        \n",
    "    def build(self, utt) :\n",
    "        ''' \n",
    "        get distribution over dsl actions\n",
    "        marginalizing over different possible meanings\n",
    "        '''\n",
    "        action_dist = MarginalDistribution(self.dsl)\n",
    "        for lexicon, prob in self.beliefs.items() :\n",
    "            action_dist.update({lexicon.language_to_dsl(utt) : prob})\n",
    "        return random.choice(a = [*action_dist.keys()], \n",
    "                             p = [*action_dist.values()])\n",
    "        \n",
    "    def speak(self, target) :\n",
    "        '''\n",
    "        construct distribution over utterances\n",
    "        marginalizing over different possible meanings\n",
    "        '''\n",
    "        utt_dist = MarginalDistribution(self.utterances)\n",
    "        for lexicon, prob in self.beliefs.items() :\n",
    "            utt_dist.update({lexicon.dsl_to_language(target) : prob})\n",
    "        return random.choice(a = [*utt_dist.keys()], \n",
    "                             p = [*utt_dist.values()])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
