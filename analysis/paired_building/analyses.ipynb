{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccf372fd",
   "metadata": {},
   "source": [
    "# Learning to communicate about shared procedural abstractions\n",
    "# Analysis\n",
    "\n",
    "The majority of our plots and all of our statistical analyses can be found in `./stats.Rmd`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fc3e196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.getcwd()\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "\n",
    "import  matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d03748a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## directory & file hierarchy\n",
    "proj_dir = os.path.abspath('../..')\n",
    "datavol_dir = os.path.join(proj_dir,'data')\n",
    "analysis_dir =  os.path.abspath('.')\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "json_dir = os.path.join(results_dir,'json')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'behavioral_experiments'))\n",
    "png_dir = os.path.abspath(os.path.join(datavol_dir,'png'))\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'stimuli') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'stimuli'))\n",
    "    \n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    \n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)   \n",
    "    \n",
    "if not os.path.exists(csv_dir):\n",
    "    os.makedirs(csv_dir)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dd62a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/will/compositional-abstractions/results'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48fff9c",
   "metadata": {},
   "source": [
    "## Read dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17d57bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dataframes from each eventType)\n",
    "df_block = pd.read_csv(os.path.join(csv_dir,'df_block.csv'))\n",
    "df_chat = pd.read_csv(os.path.join(csv_dir,'df_chat.csv'))\n",
    "df_exit = pd.read_csv(os.path.join(csv_dir,'df_exit.csv'))\n",
    "df_trial = pd.read_csv(os.path.join(csv_dir,'df_trial.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bc22018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 73\n"
     ]
    }
   ],
   "source": [
    "print('n:', df_block.gameid.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de2b11d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pilot0', 'pilot1', 'pilot2', 'pilot3', 'pilot4', 'pilot4b']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iterationNames\n",
    "list(df_trial.iterationName.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f92afed",
   "metadata": {},
   "source": [
    "## Exclusion criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47bd3996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dyads achieving 75% Accuracy on 75% of trials: 49\n"
     ]
    }
   ],
   "source": [
    "# 75% Accuracy on 75% of trials\n",
    "df75 = pd.DataFrame(df_trial.groupby(['gameid', 'trialNum'])['trialScore'].sum()>75).groupby(['gameid']).sum()\n",
    "df75['trials'] = df75['trialScore']\n",
    "\n",
    "df75 = df75[df75['trials']>=9]\n",
    "includedGames = list(df75.reset_index().gameid)\n",
    "\n",
    "print(\"Total dyads achieving 75% Accuracy on 75% of trials:\",len(df75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8efe2670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude from analysis\n",
    "df_block = df_block[df_block.gameid.isin(includedGames)]\n",
    "df_chat = df_chat[df_chat.gameid.isin(includedGames)]\n",
    "df_exit = df_exit[df_exit.gameid.isin(includedGames)]\n",
    "df_trial = df_trial[df_trial.gameid.isin(includedGames)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78554c13",
   "metadata": {},
   "source": [
    "# Referring Expressions Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eaebf1",
   "metadata": {},
   "source": [
    "## Create annotations dataframe\n",
    "\n",
    "Here we load and merge data from two rounds of annotations.\n",
    "1. We originally asked two annotators to identify the referring expressions in the chat data.\n",
    "2. To make these annotations more robust, we later asked an additional two annotators, this time using a custom-built interface. The task can be found in `tasks/annotation`, and basic wrangling of that data can be found in `analysis/annotation`.\n",
    "\n",
    "Here we wrangle data from both rouhns into a common format, and export for other analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849d182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first set of annotations (cogsci 2021)\n",
    "df_jj = pd.read_csv('{}/csv/JJ_content.csv'.format(results_dir))\n",
    "\n",
    "# second set of annotations (2023)\n",
    "df_zc = pd.read_csv('{}/csv/ref_exp_annotations_2023.csv'.format(results_dir))\n",
    "\n",
    "df_chat = pd.read_csv('{}/csv/df_chat_ids_cogsci21.csv'.format(results_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcdf399",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chat.loc[:,'dyad_gameid'] = df_chat.gameid\n",
    "df_chat.loc[:,'turn_num'] = df_chat.turnNum\n",
    "df_chat.loc[:,'trial_num'] = df_chat.trialNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31de9c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jj.loc[:,'message_num'] = (df_jj.turnNum/2).astype(int)\n",
    "\n",
    "df_jj_small = df_jj[['gameid','trialNum', 'message_num','turnNum','message','block_justin', 'toer_justin',\n",
    "       'scene_justin', 'Flagged', 'phrases_justin', 'block_julia',\n",
    "       'tower_juli', 'scene_juli', 'phrases_julia']].copy()\n",
    "\n",
    "df_jj_small.rename(\n",
    "            columns={\n",
    "            'gameid': 'dyad_gameid',\n",
    "            'trialNum': 'trial_num',\n",
    "            'turnNum': 'turn_num',\n",
    "            'toer_justin': 'tower_justin',\n",
    "            'tower_juli': 'tower_julia',\n",
    "            'scene_juli': 'scene_julia'\n",
    "            # add more column names as needed\n",
    "        }, inplace=True)\n",
    "\n",
    "df_jj_small = df_jj_small.merge(df_chat[['dyad_gameid','trial_num','turn_num','message_id']], on = ['dyad_gameid','trial_num','turn_num'], how = 'left')\n",
    "\n",
    "df_jj_small = df_jj_small.sort_values(['dyad_gameid','trial_num','message_num']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dc2654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt and pivot\n",
    "\n",
    "suffix_columns = [col for col in df_jj_small.columns if col.endswith('_justin') or col.endswith('_julia')]\n",
    "\n",
    "suffix_df = df_jj_small[['dyad_gameid','trial_num','turn_num','message_id'] + suffix_columns]\n",
    "\n",
    "# Then, melt the DataFrame with the new index as the identifier variable\n",
    "melted_df = pd.melt(suffix_df, id_vars=['dyad_gameid','trial_num','turn_num','message_id'], var_name='Type', value_name='Value')\n",
    "\n",
    "# melted_df\n",
    "\n",
    "# # Now, split the 'Type' column to separate the suffix and create a new column\n",
    "melted_df[['Category', 'Suffix']] = melted_df['Type'].str.split('_', expand=True)\n",
    "\n",
    "# # Drop the 'Type' column as it's no longer needed\n",
    "melted_df.drop(columns=['Type'], inplace=True)\n",
    "melted_df\n",
    "# # Finally, pivot the table to the desired format\n",
    "pivoted_df = melted_df.pivot(index=['dyad_gameid','trial_num','turn_num','message_id','Suffix'], \n",
    "                             columns='Category', values='Value').reset_index()\n",
    "\n",
    "pivoted_df = pivoted_df.rename(columns={'Suffix':'workerID'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb88208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust a bad annotation\n",
    "pivoted_df.loc[pivoted_df['tower'] == 'L','tower'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5a266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to ints\n",
    "pivoted_df.loc[:,'block'] = pivoted_df['block'].fillna(0).astype(int)\n",
    "pivoted_df.loc[:,'tower'] = pivoted_df['tower'].fillna(0).astype(int)\n",
    "pivoted_df.loc[:,'scene'] = pivoted_df['scene'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df80349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge in metadata\n",
    "pivoted_df_merged = pivoted_df.merge(df_jj_small[['dyad_gameid','message_id','message_num','message']], \n",
    "                 on=['message_id','dyad_gameid'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7c577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_df_merged['content'] = pivoted_df_merged['phrases'].str.lower()\n",
    "pivoted_df_merged['content'] = pivoted_df_merged['content'].str.replace(r'~', '')\n",
    "pivoted_df_merged['content'] = pivoted_df_merged['content'].str.replace(r'\\(', '')\n",
    "pivoted_df_merged['content'] = pivoted_df_merged['content'].str.replace(r'\\)', '')\n",
    "pivoted_df_merged['content'] = pivoted_df_merged['content'].str.replace(r'\\,', '')\n",
    "pivoted_df_merged['content'] = pivoted_df_merged['content'].str.replace(r\"\\'\", '')\n",
    "pivoted_df_merged['content'] = pivoted_df_merged['content'].str.replace(r\"\\:\", '')\n",
    "pivoted_df_merged['content'] = pivoted_df_merged['content'].str.replace(r\"\\;\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36f8a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zc_small = df_zc[['workerID','message_id','dyad_gameid','msgNum','message','block','tower','refExps']].copy()\n",
    "\n",
    "df_zc_small = df_zc_small.merge(df_chat[['message_id','trialNum']], \n",
    "                               how ='left',\n",
    "                               on = 'message_id')\n",
    "\n",
    "df_zc_small.rename(\n",
    "            columns={\n",
    "            'trialNum': 'trial_num',\n",
    "            'msgNum': 'message_num'\n",
    "        }, inplace=True)\n",
    "\n",
    "\n",
    "df_zc_small.loc[:,'turn_num'] = (df_zc_small.message_num*2).astype(int)\n",
    "\n",
    "df_zc_small = df_zc_small.sort_values(['workerID','dyad_gameid','trial_num','message_num']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253e4d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zc_small['content'] = df_zc_small['refExps'].str.lower()\n",
    "df_zc_small['content'] = df_zc_small['content'].str.replace(r'~', '')\n",
    "df_zc_small['content'] = df_zc_small['content'].str.replace(r'\\(', '')\n",
    "df_zc_small['content'] = df_zc_small['content'].str.replace(r'\\)', '')\n",
    "df_zc_small['content'] = df_zc_small['content'].str.replace(r'\\,', '')\n",
    "df_zc_small['content'] = df_zc_small['content'].str.replace(r\"\\'\", '')\n",
    "df_zc_small['content'] = df_zc_small['content'].str.replace(r\"\\:\", '')\n",
    "df_zc_small['content'] = df_zc_small['content'].str.replace(r\"\\;\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdbd792",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref_exps = pd.concat([pivoted_df_merged, df_zc_small], ignore_index=True)\n",
    "\n",
    "df_ref_exps = df_ref_exps.merge(df_chat[['message_id','leftTarget','rightTarget']], how ='left', on='message_id')\n",
    "df_ref_exps.loc[:,'tower_pair'] = df_ref_exps.leftTarget + '_' + df_ref_exps.rightTarget\n",
    "df_ref_exps.loc[:,'rep'] = ((df_ref_exps.trial_num)/ 3).astype(int) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3f1ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref_exps.loc[:,'content'] = df_ref_exps.loc[:,'content'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099da3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ref_exps.to_csv('{}/results/csv/df_ref_exps.csv'.format(analysis_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0913f904",
   "metadata": {},
   "source": [
    "## Inter-rater reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31761719",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ref_exps_melt = df_ref_exps.melt(id_vars=['workerID','dyad_gameid','message_id','message_num','trial_num','tower_pair','rep'], value_vars=['block','tower'], value_name='n_refs')\n",
    "df_ref_exps_melt = df_ref_exps_melt.rename(columns={'variable': 'exp_type'})\n",
    "df_ref_exps_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ef6123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ref_exps_melt.to_csv('{}/results/csv/df_ref_exps_melt.csv'.format(results_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbd2755",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_ref_exps_table = df_ref_exps.pivot(index='message_id', columns='workerID', values=['block','tower'])\n",
    "df_ref_exps_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275f47f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_all_agree_block = np.mean(\n",
    "    (df_ref_exps_table['block','charles'] == df_ref_exps_table['block','julia']) &\\\n",
    "    (df_ref_exps_table['block','julia'] == df_ref_exps_table['block','justin']) &\\\n",
    "    (df_ref_exps_table['block','justin'] == df_ref_exps_table['block','zoe']))\n",
    "\n",
    "print('%.1f' % (prop_all_agree_block*100) + '% total agreement on blocks') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ac3ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_all_agree_tower = np.mean(\n",
    "    (df_ref_exps_table['tower','charles'] == df_ref_exps_table['tower','julia']) &\\\n",
    "    (df_ref_exps_table['tower','julia'] == df_ref_exps_table['tower','justin']) &\\\n",
    "    (df_ref_exps_table['tower','justin'] == df_ref_exps_table['tower','zoe']))\n",
    "\n",
    "print('%.1f' % (prop_all_agree_tower*100) + '% total agreement on towers') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b07679",
   "metadata": {},
   "source": [
    "## calculate inter rater reliability with ICC\n",
    "https://en.wikipedia.org/wiki/Intraclass_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8c7355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg\n",
    "# https://www.statology.org/intraclass-correlation-coefficient-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc4fa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref_exps_melt.n_refs = pd.to_numeric(df_ref_exps_melt.n_refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2858a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.intraclass_corr(data = df_ref_exps_melt, targets=\"message_id\", raters=\"workerID\", ratings=\"n_refs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38757a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.intraclass_corr(data = df_ref_exps_melt.query('exp_type==\"block\"'), \n",
    "                   targets=\"message_id\", raters=\"workerID\", ratings=\"n_refs\")                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b950da07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.intraclass_corr(data = df_ref_exps_melt.query('exp_type==\"tower\"'), \n",
    "                   targets=\"message_id\", raters=\"workerID\", ratings=\"n_refs\")                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0f75d7",
   "metadata": {},
   "source": [
    "## Comparing to baseline distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e460efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c75d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "\n",
    "def shuffle_counts(df, within_exp_type=True, coupled=False):\n",
    "    '''\n",
    "    Shuffles counts of block and tower referring expressions.\n",
    "    This decouples block and tower counts from each trial.\n",
    "    '''\n",
    "\n",
    "    df_shuffled = df.copy()\n",
    "\n",
    "    for workerID in df.workerID.unique():\n",
    "        \n",
    "        if within_exp_type:\n",
    "            \n",
    "            if coupled:\n",
    "                \n",
    "                indicies = list(range(0, len(df.loc[(df.workerID == workerID) &\n",
    "                                            (df.exp_type == df.exp_type.nunique())])))\n",
    "                random.shuffle(indicies)\n",
    "                \n",
    "                for exp_type in df.exp_type.unique():\n",
    "                \n",
    "                    counts = df.loc[(df.workerID == workerID) &\n",
    "                                                (df.exp_type == exp_type), 'n_refs'].reset_index()\n",
    "                    \n",
    "                    df_shuffled.loc[(df.workerID == workerID) &\n",
    "                                              (df.exp_type == exp_type), 'n_refs'] = counts[indicies]\n",
    "                \n",
    "        \n",
    "            for exp_type in df.exp_type.unique():\n",
    "                \n",
    "                counts = list(df.loc[(df.workerID == workerID) &\n",
    "                                            (df.exp_type == exp_type), 'n_refs'])\n",
    "\n",
    "                random.shuffle(counts)\n",
    "\n",
    "                df_shuffled.loc[(df.workerID == workerID) &\n",
    "                                              (df.exp_type == exp_type), 'n_refs'] = counts\n",
    "\n",
    "                    \n",
    "                \n",
    "        else:\n",
    "            if not(coupled):\n",
    "                counts = list(df.loc[(df.workerID == workerID), 'n_refs'])\n",
    "\n",
    "                random.shuffle(counts)\n",
    "\n",
    "                df_shuffled.loc[(df.workerID == workerID), 'n_refs'] = counts\n",
    "            else:\n",
    "                print('does not make sense to ask for coupled block and tower responses across expression type')\n",
    "\n",
    "    \n",
    "    df_shuffled['n_refs'] = df_shuffled['n_refs'].astype(int)\n",
    "    \n",
    "    return df_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f876b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref_exps_melt_shuffled = shuffle_counts(df_ref_exps_melt, within_exp_type=True, coupled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b112cfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref_exps_melt_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b476b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref_exps_shuffled_table = df_ref_exps_melt_shuffled.pivot(index='message_id', columns=['exp_type', 'workerID'], values=['n_refs'])['n_refs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31892a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prop_agreement(df_table, level = 'block'):\n",
    "    prop = np.mean(\n",
    "    (df_table[level,'charles'] == df_table[level,'julia']) &\\\n",
    "    (df_table[level,'julia'] == df_table[level,'justin']) &\\\n",
    "    (df_table[level,'justin'] == df_table[level,'zoe']))\n",
    "    \n",
    "    return prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116aea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_agreement(df_ref_exps_shuffled_table, 'block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed33d437",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_agreement(df_ref_exps_shuffled_table, 'tower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775beae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "\n",
    "agreement_baseline = {}\n",
    "agreement_baseline['block'] = []\n",
    "agreement_baseline['tower'] = []\n",
    "icc_baseline = []\n",
    "# icc_baseline['block'] = []\n",
    "# icc_baseline['tower'] = []\n",
    "\n",
    "for i in range(0,50):\n",
    "    \n",
    "    df_ref_exps_melt_shuffled = shuffle_counts(df_ref_exps_melt, within_exp_type=True, coupled=True)\n",
    "    \n",
    "    df_ref_exps_shuffled_table = df_ref_exps_melt_shuffled.pivot(index='message_id', columns=['exp_type', 'workerID'], values=['n_refs'])['n_refs']\n",
    "    \n",
    "    agreement_baseline['block'].append(prop_agreement(df_ref_exps_shuffled_table, 'block'))\n",
    "    agreement_baseline['tower'].append(prop_agreement(df_ref_exps_shuffled_table, 'tower'))\n",
    "    \n",
    "    icc_baseline.append(\\\n",
    "            pg.intraclass_corr(data = df_ref_exps_melt_shuffled, \n",
    "                               targets=\"message_id\", \n",
    "                               raters=\"workerID\", \n",
    "                               ratings=\"n_refs\").loc[0,\"ICC\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd8bbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_icc = pg.intraclass_corr(data = df_ref_exps_melt, targets=\"message_id\", raters=\"workerID\", ratings=\"n_refs\").loc[0,\"ICC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd36f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10,4))\n",
    "sns.displot(icc_baseline, height=5, aspect=2)\n",
    "plt.axvline(overall_icc, color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e32612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10,4))\n",
    "sns.displot(agreement_baseline['block'], height=5, aspect=2)\n",
    "plt.axvline(prop_all_agree_block, color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f1d76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(agreement_baseline['tower'], height=5, aspect=2)\n",
    "plt.axvline(prop_all_agree_tower, color='r', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f722809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07c9d6ba",
   "metadata": {},
   "source": [
    "# Change in referring expression across repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc912347",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ref_exps = pd.read_csv(os.path.join(csv_dir,'df_ref_exps.csv'))\n",
    "df_ref_exps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496b4453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "df_ref_exps.loc[:,'content'] = df_ref_exps.loc[:,'content'].astype(str)\n",
    "df_ref_exps['content'] = df_ref_exps['content'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "df_ref_exps['content'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05ad298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert number words\n",
    "\n",
    "def num_2_words(sentence):\n",
    "    out = \"\"\n",
    "    for word in sentence.split():\n",
    "        try:\n",
    "            o = num2words(word)\n",
    "        except:\n",
    "            o = word\n",
    "        out = out+\" \"+ o\n",
    "    return out\n",
    "\n",
    "df_ref_exps['content'] = df_ref_exps['content'].apply(lambda x: num_2_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c080a275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatize\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in tokenizer.tokenize(text)]\n",
    "\n",
    "df_ref_exps['BOW_lemmatized'] = df_ref_exps['content'].apply(lemmatize_text)\n",
    "df_ref_exps['BOW_lemmatized'] = df_ref_exps['BOW_lemmatized'].apply(lambda x: [i.upper() for i in x])\n",
    "\n",
    "df_ref_exps[['message','content','BOW_lemmatized']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafa3c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get work frequencies\n",
    "df_ref_exps['word_freq'] = df_ref_exps['BOW_lemmatized'].apply(lambda x: Counter(x))\n",
    "df_ref_exps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee319c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## concatenate lemmatized tokens, separated by spaces\n",
    "df_ref_exps['BOW_concat'] = df_ref_exps['BOW_lemmatized'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adfea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently, the word counts represent the counts from all 4 of our naive raters. \n",
    "# So that we can examine how frequently different words were used, we need to convert these values into proportions.\n",
    "split_words = df_ref_exps['BOW_concat'].apply(lambda x: x.split())\n",
    "all_words = list(pd.Series([st for row in split_words for st in row]).unique())\n",
    "support = {}\n",
    "for word in all_words:\n",
    "    support[word] = 0.000000001\n",
    "    \n",
    "def get_pdist(row):\n",
    "    num_words = np.sum(list(row['word_freq'].values()))\n",
    "    pdist = support.copy()\n",
    "    for i, (word, count) in enumerate(row['word_freq'].items()):\n",
    "        pdist[word] = count/num_words\n",
    "    return pdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fa2f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref_exps['word_pdist'] = df_ref_exps.apply(get_pdist, axis = 1)\n",
    "df_ref_exps['word_pdist_numeric'] = df_ref_exps['word_pdist'].apply(lambda dist: list(dist.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21c8b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_words = df_ref_exps[['dyad_gameid', 'rep', 'BOW_concat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bff8afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in all_words:\n",
    "    df_all_words.loc[:,w] = df_all_words['BOW_concat'].apply(lambda row: int(w in row.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f9a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_words_reps = df_all_words.groupby('rep').agg(sum)\n",
    "df_all_words_reps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac87a0a",
   "metadata": {},
   "source": [
    "### figure 3A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e222d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the change in word frequencies between trials.\n",
    "# prep data\n",
    "df_ref_exps_rep = df_ref_exps.groupby('rep')['BOW_concat'].apply(lambda group:' '.join(group)).reset_index()\n",
    "df_ref_exps_rep['word_freq'] = df_ref_exps_rep['BOW_concat'].apply(lambda x: Counter(x.split()))\n",
    "df_ref_exps_rep['word_pdist'] = df_ref_exps_rep.apply(get_pdist, axis=1)\n",
    "df_ref_exps_rep['word_pdist_numeric'] = df_ref_exps_rep['word_pdist'].apply(lambda dist: list(dist.values()))\n",
    "df_ref_exps_rep.index=df_ref_exps_rep['rep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7b4c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate difference in proportion between reps (currently hardcoded to be 1 and 4)\n",
    "rep_a = 1 \n",
    "rep_b = 4\n",
    "\n",
    "rep_diff = {}\n",
    "\n",
    "for _, (k, rep_a_v) in enumerate(df_ref_exps_rep.loc[rep_a,'word_pdist'].items()):\n",
    "    rep_diff[k] = df_ref_exps_rep.loc[rep_b,'word_pdist'][k] - rep_a_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d409a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find largest n increase/ decrease in proportion across reps\n",
    "n = 6\n",
    "\n",
    "# find the largest increase in proportion between reps\n",
    "top_n = dict(sorted(rep_diff.items(), key=lambda item: item[1], reverse=True)[:n])\n",
    "\n",
    "# find the largest decrease in proportion between reps\n",
    "bottom_n = dict(sorted(rep_diff.items(), key=lambda item: item[1], reverse=False)[:n])\n",
    "\n",
    "df_grouped = df_ref_exps.groupby('rep').agg({'BOW_lemmatized': 'sum'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e12fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "font = {'fontname':'Helvetica'}\n",
    "sns.set_theme(style='white')\n",
    "\n",
    "x_limit = 6\n",
    "\n",
    "labels, values = zip(*rep_diff.items())\n",
    "\n",
    "# sort your values in descending order\n",
    "indSort_high = np.argsort(values)[::-1]\n",
    "indSort_low = np.argsort(values)\n",
    "\n",
    "# rearrange your data\n",
    "#labels = np.array(labels)[indSort_high][:x_limit][::-1]\n",
    "labels = np.concatenate([np.array(labels)[indSort_low][:x_limit],np.array(labels)[indSort_high][:x_limit][::-1]])\n",
    "#values = np.array(values)[indSort_high][:x_limit][::-1]\n",
    "values = np.concatenate([np.array(values)[indSort_low][:x_limit], np.array(values)[indSort_high][:x_limit][::-1]])\n",
    "\n",
    "indexes = np.arange(len(labels))\n",
    "\n",
    "bar_width = 0.35\n",
    "\n",
    "fig = plt.figure(num=None, figsize=(7, 11), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = fig.add_subplot(111)\n",
    "ax.bar(indexes, values, color = \"#7D7D7D\")\n",
    "ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "# add labels\n",
    "plt.yticks(fontsize=16, **font)\n",
    "plt.xticks(indexes + bar_width, labels,  rotation='vertical', fontsize=16, **font)\n",
    "plt.ylabel(\"change in proportion\", size = 24, **font)\n",
    "plt.yticks(np.arange(-.13,.06, .02))\n",
    "ax.axes.get_xaxis().set_visible(True)\n",
    "#plt.title(\"highest delta words\", size = 24, **font)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d012e2",
   "metadata": {},
   "source": [
    "## Change in referring expression visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ad80e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude a couple of participants that have very different data (which make all other participants appear closer together)\n",
    "\n",
    "exclude_ids = ['4338-9f5cbb3a-a351-45e4-9b99-dc2737fd4658', #\"xxoooxxxo\"-type responses\n",
    "               '9387-db1af5ad-b089-48ad-a730-baee40f08177'  # lots of empty messages\n",
    "              ]\n",
    "\n",
    "df_ref_exps = df_ref_exps[~df_ref_exps.dyad_gameid.isin(exclude_ids)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae373606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word count (across all four raters)\n",
    "df_ref_exps_trial = df_ref_exps.groupby(['dyad_gameid','rep','trial_num'])['BOW_concat'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "df_ref_exps_trial['word_freq'] = df_ref_exps_trial['BOW_concat'].apply(lambda x: Counter(x.split()))\n",
    "df_ref_exps_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61787a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find which words were used by each participant in every trial\n",
    "\n",
    "df_all_words_trial = df_ref_exps_trial[['dyad_gameid', 'rep', 'trial_num' ,'BOW_concat']]\n",
    "\n",
    "for w in all_words:\n",
    "    df_all_words_trial[w] = df_all_words_trial['BOW_concat'].apply(lambda row: int(w in row.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be84804c",
   "metadata": {},
   "source": [
    "## visualize change across repetition, with TSNE (figure 2B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde823a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify some demonstrative examples\n",
    "ps = [29, 38, 71]\n",
    "\n",
    "# 29\n",
    "# ['BLOCK', 'BLUE', 'RED']\n",
    "# ['BLUE', 'RED']\n",
    "\n",
    "# 38\n",
    "# ['BLOCK', 'BLUE', 'L', 'RED', 'TWO']\n",
    "# ['L', 'U', 'UPSIDE']\n",
    "\n",
    "# 71\n",
    "# ['1', 'HORIZONTAL', 'ONE', 'TWO', 'VERTICAL']\n",
    "# ['L', 'LOWERCASE', 'N', 'SHAPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa11d962",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualizations using tsne, colored by rep\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "both_reps = pd.concat([df_all_words_trial[(df_all_words_trial.rep == 1)].loc[:,'TWO':'TWR'], df_all_words_trial[(df_all_words_trial.rep == 4)].loc[:,'TWO':'TWR']], axis=0)\n",
    "rep_labels = list(pd.concat([df_all_words_trial[(df_all_words_trial.rep == 1)].rep, df_all_words_trial[(df_all_words_trial.rep == 4)].rep]))\n",
    "\n",
    "pca = PCA(n_components=21)\n",
    "pca_result = pca.fit_transform(both_reps)\n",
    "\n",
    "tsne = TSNE(perplexity=15)\n",
    "X_embedded = tsne.fit_transform(pca_result)\n",
    "n = int(len(X_embedded[:,0])/2)\n",
    "\n",
    "sns.set_style('white')\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "# palette = list(np.array(sns.color_palette(\"bright\", 2)))\n",
    "palette = ['#99CCCC']\n",
    "\n",
    "for i, x in enumerate(X_embedded[:n,0]):\n",
    "    if not i in ps:\n",
    "        plt.arrow(x, \n",
    "                  X_embedded[i, 1],\n",
    "                  X_embedded[i+n, 0]-x, \n",
    "                  X_embedded[i+n, 1]-X_embedded[i, 1], \n",
    "                  shape='full', \n",
    "                  lw=0.2, \n",
    "                  length_includes_head=True, \n",
    "                  overhang=0,\n",
    "                  color='#21606B', \n",
    "                  head_width=0.7,\n",
    "                  head_length=0.8,\n",
    "                  alpha=0.8)\n",
    "\n",
    "for i, x in enumerate(X_embedded[:n,0]):\n",
    "    if i in ps:\n",
    "        plt.arrow(x, \n",
    "                  X_embedded[i, 1],\n",
    "                  X_embedded[i+n, 0]-x, \n",
    "                  X_embedded[i+n, 1]-X_embedded[i, 1], \n",
    "                  shape='full', \n",
    "                  lw=2, \n",
    "                  length_includes_head=True, \n",
    "                  overhang=0,\n",
    "                  color='#FF0000', \n",
    "                  head_width=0.6,\n",
    "                  head_length=0.7,\n",
    "                  alpha=0.8)\n",
    "\n",
    "\n",
    "\n",
    "sns.scatterplot(x = X_embedded[:n,0], \n",
    "                y = X_embedded[:n,1], \n",
    "                hue=rep_labels[:n], \n",
    "                legend=False, \n",
    "                palette=palette, \n",
    "                alpha=0.7, \n",
    "                s=50, \n",
    "                linewidth=0.5)\n",
    "\n",
    "# plt.legend()\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0)\n",
    "plt.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    left=False,         # ticks along the top edge are off\n",
    "    labelbottom=False,\n",
    "    labelleft=False) # labels along the bottom edge are off\n",
    "\n",
    "# plt.savefig('../results/plots/rep1_clusters.pdf')\n",
    "\n",
    "plt.savefig('../../results/plots/rep4_clusters.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22b7550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb510c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cfbd57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
