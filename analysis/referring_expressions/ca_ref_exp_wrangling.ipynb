{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02231cf3",
   "metadata": {},
   "source": [
    "# Analyzing annotations of linguistic data from paired building experiment\n",
    "\n",
    "We ran two separate annotations studies, each with two naive participants from the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a14da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib, io\n",
    "os.getcwd()\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../../utils\")\n",
    "sys.path.append(\"../../analysis/utils\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import pymongo as pm\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "\n",
    "from PIL import Image, ImageOps, ImageDraw, ImageFont \n",
    "\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "import  matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "\n",
    "# import drawing_utils as drawing\n",
    "import importlib\n",
    "import scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2425099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1193d694",
   "metadata": {},
   "outputs": [],
   "source": [
    "## directory & file hierarchy\n",
    "proj_dir = os.path.abspath('../..')\n",
    "datavol_dir = os.path.join(proj_dir,'data')\n",
    "analysis_dir =  os.path.abspath('../')\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "json_dir = os.path.join(results_dir,'json')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'behavioral_experiments'))\n",
    "png_dir = os.path.abspath(os.path.join(datavol_dir,'png'))\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'stimuli') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'stimuli'))\n",
    "    \n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    \n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)   \n",
    "    \n",
    "if not os.path.exists(csv_dir):\n",
    "    os.makedirs(csv_dir)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eaebf1",
   "metadata": {},
   "source": [
    "### load annotations and wrangle to match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849d182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first set of annotations (cogsci 2021)\n",
    "df_jj = pd.read_csv('{}/csv/JJ_content.csv'.format(results_dir))\n",
    "\n",
    "# second set of annotations (2023)\n",
    "df_zc = pd.read_csv('{}/csv/ref_exp_annotations_2023.csv'.format(results_dir))\n",
    "\n",
    "df_chat = pd.read_csv('{}/csv/df_chat_ids_cogsci21.csv'.format(results_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcdf399",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chat.loc[:,'dyad_gameid'] = df_chat.gameid\n",
    "df_chat.loc[:,'turn_num'] = df_chat.turnNum\n",
    "df_chat.loc[:,'trial_num'] = df_chat.trialNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31de9c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jj.loc[:,'message_num'] = (df_jj.turnNum/2).astype(int)\n",
    "\n",
    "df_jj_small = df_jj[['gameid','trialNum', 'message_num','turnNum','message','block_justin', 'toer_justin',\n",
    "       'scene_justin', 'Flagged', 'phrases_justin', 'block_julia',\n",
    "       'tower_juli', 'scene_juli', 'phrases_julia']].copy()\n",
    "\n",
    "df_jj_small.rename(\n",
    "            columns={\n",
    "            'gameid': 'dyad_gameid',\n",
    "            'trialNum': 'trial_num',\n",
    "            'turnNum': 'turn_num',\n",
    "            'toer_justin': 'tower_justin',\n",
    "            'tower_juli': 'tower_julia',\n",
    "            'scene_juli': 'scene_julia'\n",
    "            # add more column names as needed\n",
    "        }, inplace=True)\n",
    "\n",
    "df_jj_small = df_jj_small.merge(df_chat[['dyad_gameid','trial_num','turn_num','message_id']], on = ['dyad_gameid','trial_num','turn_num'], how = 'left')\n",
    "\n",
    "df_jj_small = df_jj_small.sort_values(['dyad_gameid','trial_num','message_num']).reset_index(drop=True)\n",
    "\n",
    "df_jj_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dc2654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt and pivot\n",
    "\n",
    "suffix_columns = [col for col in df_jj_small.columns if col.endswith('_justin') or col.endswith('_julia')]\n",
    "\n",
    "suffix_df = df_jj_small[['dyad_gameid','trial_num','turn_num','message_id'] + suffix_columns]\n",
    "\n",
    "# Then, melt the DataFrame with the new index as the identifier variable\n",
    "melted_df = pd.melt(suffix_df, id_vars=['dyad_gameid','trial_num','turn_num','message_id'], var_name='Type', value_name='Value')\n",
    "\n",
    "# melted_df\n",
    "\n",
    "# # Now, split the 'Type' column to separate the suffix and create a new column\n",
    "melted_df[['Category', 'Suffix']] = melted_df['Type'].str.split('_', expand=True)\n",
    "\n",
    "# # Drop the 'Type' column as it's no longer needed\n",
    "melted_df.drop(columns=['Type'], inplace=True)\n",
    "melted_df\n",
    "# # Finally, pivot the table to the desired format\n",
    "pivoted_df = melted_df.pivot(index=['dyad_gameid','trial_num','turn_num','message_id','Suffix'], \n",
    "                             columns='Category', values='Value').reset_index()\n",
    "\n",
    "pivoted_df = pivoted_df.rename(columns={'Suffix':'workerID'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb88208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust a bad annotation\n",
    "pivoted_df.loc[pivoted_df['tower'] == 'L','tower'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5a266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to ints\n",
    "pivoted_df.loc[:,'block'] = pivoted_df['block'].fillna(0).astype(int)\n",
    "pivoted_df.loc[:,'tower'] = pivoted_df['tower'].fillna(0).astype(int)\n",
    "pivoted_df.loc[:,'scene'] = pivoted_df['scene'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b334315",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df80349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge in metadata\n",
    "pivoted_df_merged = pivoted_df.merge(df_jj_small[['dyad_gameid','message_id','message_num','message']], \n",
    "                 on=['message_id','dyad_gameid'], how='left')\n",
    "\n",
    "pivoted_df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7c577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_df_merged['content'] = pivoted_df_merged['phrases'].str.lower()\n",
    "pivoted_df_merged['content'] = pivoted_df_merged['content'].str.replace(r'~', '')\n",
    "pivoted_df_merged['content'] = pivoted_df_merged['content'].str.replace(r'\\(', '')\n",
    "pivoted_df_merged['content'] = pivoted_df_merged['content'].str.replace(r'\\)', '')\n",
    "pivoted_df_merged['content'] = pivoted_df_merged['content'].str.replace(r'\\,', '')\n",
    "pivoted_df_merged['content'] = pivoted_df_merged['content'].str.replace(r\"\\'\", '')\n",
    "pivoted_df_merged['content'] = pivoted_df_merged['content'].str.replace(r\"\\:\", '')\n",
    "pivoted_df_merged['content'] = pivoted_df_merged['content'].str.replace(r\"\\;\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36f8a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zc_small = df_zc[['workerID','message_id','dyad_gameid','msgNum','message','block','tower','refExps']].copy()\n",
    "\n",
    "df_zc_small = df_zc_small.merge(df_chat[['message_id','trialNum']], \n",
    "                               how ='left',\n",
    "                               on = 'message_id')\n",
    "\n",
    "df_zc_small.rename(\n",
    "            columns={\n",
    "            'trialNum': 'trial_num',\n",
    "            'msgNum': 'message_num'\n",
    "        }, inplace=True)\n",
    "\n",
    "\n",
    "df_zc_small.loc[:,'turn_num'] = (df_zc_small.message_num*2).astype(int)\n",
    "\n",
    "df_zc_small = df_zc_small.sort_values(['workerID','dyad_gameid','trial_num','message_num']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_zc_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253e4d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zc_small['content'] = df_zc_small['refExps'].str.lower()\n",
    "df_zc_small['content'] = df_zc_small['content'].str.replace(r'~', '')\n",
    "df_zc_small['content'] = df_zc_small['content'].str.replace(r'\\(', '')\n",
    "df_zc_small['content'] = df_zc_small['content'].str.replace(r'\\)', '')\n",
    "df_zc_small['content'] = df_zc_small['content'].str.replace(r'\\,', '')\n",
    "df_zc_small['content'] = df_zc_small['content'].str.replace(r\"\\'\", '')\n",
    "df_zc_small['content'] = df_zc_small['content'].str.replace(r\"\\:\", '')\n",
    "df_zc_small['content'] = df_zc_small['content'].str.replace(r\"\\;\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdbd792",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref_exps = pd.concat([pivoted_df_merged, df_zc_small], ignore_index=True)\n",
    "\n",
    "df_ref_exps = df_ref_exps.merge(df_chat[['message_id','leftTarget','rightTarget']], how ='left', on='message_id')\n",
    "df_ref_exps.loc[:,'tower_pair'] = df_ref_exps.leftTarget + '_' + df_ref_exps.rightTarget\n",
    "df_ref_exps.loc[:,'rep'] = ((df_ref_exps.trial_num)/ 3).astype(int) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3f1ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref_exps.loc[:,'content'] = df_ref_exps.loc[:,'content'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099da3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref_exps.to_csv('{}/results/csv/df_ref_exps.csv'.format(analysis_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0913f904",
   "metadata": {},
   "source": [
    "# Inter-rater Reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31761719",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ref_exps_melt = df_ref_exps.melt(id_vars=['workerID','dyad_gameid','message_id','message_num','trial_num','tower_pair','rep'], value_vars=['block','tower'], value_name='n_refs')\n",
    "df_ref_exps_melt = df_ref_exps_melt.rename(columns={'variable': 'exp_type'})\n",
    "df_ref_exps_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ef6123",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref_exps_melt.to_csv('{}/results/csv/df_ref_exps_melt.csv'.format(results_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbd2755",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_ref_exps_table = df_ref_exps.pivot(index='message_id', columns='workerID', values=['block','tower'])\n",
    "df_ref_exps_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275f47f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_all_agree_block = np.mean(\n",
    "    (df_ref_exps_table['block','charles'] == df_ref_exps_table['block','julia']) &\\\n",
    "    (df_ref_exps_table['block','julia'] == df_ref_exps_table['block','justin']) &\\\n",
    "    (df_ref_exps_table['block','justin'] == df_ref_exps_table['block','zoe']))\n",
    "\n",
    "print('%.1f' % (prop_all_agree_block*100) + '% total agreement on blocks') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ac3ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_all_agree_tower = np.mean(\n",
    "    (df_ref_exps_table['tower','charles'] == df_ref_exps_table['tower','julia']) &\\\n",
    "    (df_ref_exps_table['tower','julia'] == df_ref_exps_table['tower','justin']) &\\\n",
    "    (df_ref_exps_table['tower','justin'] == df_ref_exps_table['tower','zoe']))\n",
    "\n",
    "print('%.1f' % (prop_all_agree_tower*100) + '% total agreement on towers') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b07679",
   "metadata": {},
   "source": [
    "## calculate inter rater reliability with ICC\n",
    "https://en.wikipedia.org/wiki/Intraclass_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8c7355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg\n",
    "# https://www.statology.org/intraclass-correlation-coefficient-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2858a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.intraclass_corr(data = df_ref_exps_melt, targets=\"message_id\", raters=\"workerID\", ratings=\"n_refs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38757a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.intraclass_corr(data = df_ref_exps_melt.query('exp_type==\"block\"'), \n",
    "                   targets=\"message_id\", raters=\"workerID\", ratings=\"n_refs\")                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b950da07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.intraclass_corr(data = df_ref_exps_melt.query('exp_type==\"tower\"'), \n",
    "                   targets=\"message_id\", raters=\"workerID\", ratings=\"n_refs\")                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dacbba",
   "metadata": {},
   "source": [
    "### calculte ICC by hand- something wrong here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb41470",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_message = len(df_ref_exps_table)\n",
    "n_rater = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42678eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean for each rater\n",
    "block_rater_means = df_ref_exps_table['block'].mean()\n",
    "\n",
    "# mean for each message\n",
    "block_message_means = df_ref_exps_table['block'].mean(axis=1)\n",
    "\n",
    "# overall mean\n",
    "overall_mean = block_message_means.mean()\n",
    "\n",
    "# between messages sum of squares\n",
    "block_message_ss =  n_rater * ((block_message_means - overall_mean) ** 2).sum() \n",
    "\n",
    "# between raters sum of squares\n",
    "block_rater_ss =  n_message * ((block_rater_means - overall_mean) ** 2).sum()\n",
    "\n",
    "# Residual (SSE)\n",
    "SE = (df_ref_exps_table['block'].apply(lambda col: col - block_message_means)) ** 2\n",
    "SSE = SE.sum().sum()\n",
    "\n",
    "# mean squares for each source of variance\n",
    "\n",
    "# between messages\n",
    "MSM = block_message_ss / (n_message - 1)\n",
    "\n",
    "# between raters\n",
    "MSR = block_rater_ss / (n_rater - 1)\n",
    "\n",
    "# Residual (MSE)\n",
    "MSE = SSE / ((n_rater - 1) * (n_message - 1))\n",
    "\n",
    "# ICC\n",
    "ICC = (MSM - MSE) / (MSM + ((n_rater - 1) * MSR) + MSE)\n",
    "ICC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3575e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean for each rater\n",
    "tower_rater_means = df_ref_exps_table['tower'].mean()\n",
    "\n",
    "# mean for each message\n",
    "tower_message_means = df_ref_exps_table['tower'].mean(axis=1)\n",
    "\n",
    "# overall mean\n",
    "overall_mean = tower_message_means.mean()\n",
    "\n",
    "# between messages sum of squares\n",
    "tower_message_ss =  n_rater * ((tower_message_means - overall_mean) ** 2).sum() \n",
    "\n",
    "# between raters sum of squares\n",
    "tower_rater_ss =  n_message * ((tower_rater_means - overall_mean) ** 2).sum()\n",
    "\n",
    "# Residual (SSE)\n",
    "SE = (df_ref_exps_table['tower'].apply(lambda col: col - tower_message_means)) ** 2\n",
    "SSE = SE.sum().sum()\n",
    "\n",
    "# mean squares for each source of variance\n",
    "\n",
    "# between messages\n",
    "MSM = tower_message_ss / (n_message - 1)\n",
    "\n",
    "# between raters\n",
    "MSR = tower_rater_ss / (n_rater - 1)\n",
    "\n",
    "# Residual (MSE)\n",
    "MSE = SSE / ((n_rater - 1) * (n_message - 1))\n",
    "\n",
    "# ICC\n",
    "ICC = (MSM - MSE) / (MSM + ((n_rater - 1) * MSR) + MSE)\n",
    "ICC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0f75d7",
   "metadata": {},
   "source": [
    "## Comparing to baseline distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e460efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ca5857",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = list(df_ref_exps_melt.loc[(df_ref_exps_melt.workerID == workerID) &\n",
    "                                    (df_ref_exps_melt.exp_type == exp_type), 'n_refs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c75d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "\n",
    "def shuffle_counts(df, within_exp_type=True, coupled=False):\n",
    "    '''\n",
    "    Shuffles counts of block and tower referring expressions.\n",
    "    This decouples block and tower counts from each trial.\n",
    "    '''\n",
    "\n",
    "    df_shuffled = df.copy()\n",
    "\n",
    "    for workerID in df.workerID.unique():\n",
    "        \n",
    "        if within_exp_type:\n",
    "            \n",
    "            if coupled:\n",
    "                \n",
    "                indicies = list(range(0, len(df.loc[(df.workerID == workerID) &\n",
    "                                            (df.exp_type == df.exp_type.nunique())])))\n",
    "                random.shuffle(indicies)\n",
    "                \n",
    "                for exp_type in df.exp_type.unique():\n",
    "                \n",
    "                    counts = df.loc[(df.workerID == workerID) &\n",
    "                                                (df.exp_type == exp_type), 'n_refs'].reset_index()\n",
    "                    \n",
    "                    df_shuffled.loc[(df.workerID == workerID) &\n",
    "                                              (df.exp_type == exp_type), 'n_refs'] = counts[indicies]\n",
    "                \n",
    "        \n",
    "            for exp_type in df.exp_type.unique():\n",
    "                \n",
    "                counts = list(df.loc[(df.workerID == workerID) &\n",
    "                                            (df.exp_type == exp_type), 'n_refs'])\n",
    "\n",
    "                random.shuffle(counts)\n",
    "\n",
    "                df_shuffled.loc[(df.workerID == workerID) &\n",
    "                                              (df.exp_type == exp_type), 'n_refs'] = counts\n",
    "\n",
    "                    \n",
    "                \n",
    "        else:\n",
    "            if not(coupled):\n",
    "                counts = list(df.loc[(df.workerID == workerID), 'n_refs'])\n",
    "\n",
    "                random.shuffle(counts)\n",
    "\n",
    "                df_shuffled.loc[(df.workerID == workerID), 'n_refs'] = counts\n",
    "            else:\n",
    "                print('does not make sense to ask for coupled block and tower responses across expression type')\n",
    "\n",
    "    \n",
    "    df_shuffled['n_refs'] = df_shuffled['n_refs'].astype(int)\n",
    "    \n",
    "    return df_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f876b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref_exps_melt_shuffled = shuffle_counts(df_ref_exps_melt, within_exp_type=True, coupled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b112cfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref_exps_melt_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b476b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref_exps_shuffled_table = df_ref_exps_melt_shuffled.pivot(index='message_id', columns=['exp_type', 'workerID'], values=['n_refs'])['n_refs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31892a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prop_agreement(df_table, level = 'block'):\n",
    "    prop = np.mean(\n",
    "    (df_table[level,'charles'] == df_table[level,'julia']) &\\\n",
    "    (df_table[level,'julia'] == df_table[level,'justin']) &\\\n",
    "    (df_table[level,'justin'] == df_table[level,'zoe']))\n",
    "    \n",
    "    return prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116aea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_agreement(df_ref_exps_shuffled_table, 'block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed33d437",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_agreement(df_ref_exps_shuffled_table, 'tower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775beae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "\n",
    "agreement_baseline = {}\n",
    "agreement_baseline['block'] = []\n",
    "agreement_baseline['tower'] = []\n",
    "icc_baseline = []\n",
    "# icc_baseline['block'] = []\n",
    "# icc_baseline['tower'] = []\n",
    "\n",
    "for i in range(0,50):\n",
    "    \n",
    "    df_ref_exps_melt_shuffled = shuffle_counts(df_ref_exps_melt, within_exp_type=True, coupled=True)\n",
    "    \n",
    "    df_ref_exps_shuffled_table = df_ref_exps_melt_shuffled.pivot(index='message_id', columns=['exp_type', 'workerID'], values=['n_refs'])['n_refs']\n",
    "    \n",
    "    agreement_baseline['block'].append(prop_agreement(df_ref_exps_shuffled_table, 'block'))\n",
    "    agreement_baseline['tower'].append(prop_agreement(df_ref_exps_shuffled_table, 'tower'))\n",
    "    \n",
    "    icc_baseline.append(\\\n",
    "            pg.intraclass_corr(data = df_ref_exps_melt_shuffled, \n",
    "                               targets=\"message_id\", \n",
    "                               raters=\"workerID\", \n",
    "                               ratings=\"n_refs\").loc[0,\"ICC\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd8bbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_icc = pg.intraclass_corr(data = df_ref_exps_melt, targets=\"message_id\", raters=\"workerID\", ratings=\"n_refs\").loc[0,\"ICC\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd36f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10,4))\n",
    "sns.displot(icc_baseline, height=5, aspect=2)\n",
    "plt.axvline(overall_icc, color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e32612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10,4))\n",
    "sns.displot(agreement_baseline['block'], height=5, aspect=2)\n",
    "plt.axvline(prop_all_agree_block, color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f1d76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(agreement_baseline['tower'], height=5, aspect=2)\n",
    "plt.axvline(prop_all_agree_tower, color='r', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494336ad",
   "metadata": {},
   "source": [
    "# Chi-squared\n",
    "\n",
    "Compare word frequency distributions using chi-squared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb39e384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b653873",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ca_tut",
   "language": "python",
   "name": "ca_tut"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
