{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2x1 (left 4 (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) $0)))\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from towerPrimitives import primitives\n",
    "from makeTowerTasks import *\n",
    "from grammar import *\n",
    "from fragmentGrammar import *\n",
    "from gen_seq import *\n",
    "import utilities\n",
    "from enumeration import *\n",
    "from program import *\n",
    "import render\n",
    "import importlib\n",
    "\n",
    "\n",
    "_ = importlib.reload(utilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "\n",
    "ws = [1.5, 3.2, 3.3, 9.6] #subset of ws used when running model on all trial sequences\n",
    "w_locations = {w: i for i, w in enumerate(ws)}\n",
    "\n",
    "# ground-truth programs fed into library learning\n",
    "tower_strings = {\"CL\" :\"(h (l 1) v v (r 1) h (r 12) h (l 4) h (l 1) v v)\",\n",
    "                \"CPi\": \"(h (l 1) v v (r 1) h (r 6) v (r 6) v (l 5) h (r 4) h)\",\n",
    "                \"LPi\": \"(h (l 4) h (l 1) v v (r 9) v (r 6) v (l 5) h (r 4) h)\",\n",
    "                \"LC\": \"(h (l 4) h (l 1) v v (r 12) h (l 1) v v (r 1) h)\",\n",
    "                \"PiC\": \"(v (r 6) v (l 5) h (r 4) h (r 7) h (l 1) v v (r 1) h)\",\n",
    "                \"PiL\": \"(v (r 6) v (l 5) h (r 4) h (r 9) h (l 4) h (l 1) v v)\"}\n",
    "\n",
    "# webppl-readable ground-truth programs\n",
    "manual_tower_programs = {\"CL\" :\"h l_1 v v r_1 h r_12 h l_4 h l_1 v v\",\n",
    "                         \"CPi\": \"h l_1 v v r_1 h r_6 v r_6 v l_5 h r_4 h\",\n",
    "                         \"PiC\": \"v r_6 v l_5 h r_4 h r_7 h l_1 v v r_1 h\",\n",
    "                         \"LPi\": \"h l_4 h l_1 v v r_9 v r_6 v l_5 h r_4 h\",\n",
    "                         \"LC\": \"h l_4 h l_1 v v r_12 h l_1 v v r_1 h\",\n",
    "                         \"PiL\": \"v r_6 v l_5 h r_4 h r_9 h l_4 h l_1 v v\"}\n",
    "\n",
    "\n",
    "# base dsl for webppl-readable strings\n",
    "base_dsl = ['h', \n",
    " 'v', \n",
    " 'l_0',\n",
    " 'l_1',\n",
    " 'l_2',\n",
    " 'l_3',\n",
    " 'l_4',\n",
    " 'l_5',\n",
    " 'l_6',\n",
    " 'l_7',\n",
    " 'l_8',\n",
    " 'l_9',\n",
    " 'l_10',\n",
    " 'l_11',\n",
    " 'l_12',\n",
    " 'r_0',\n",
    " 'r_1',\n",
    " 'r_2',\n",
    " 'r_3',\n",
    " 'r_4',\n",
    " 'r_5',\n",
    " 'r_6',\n",
    " 'r_7',\n",
    " 'r_8',\n",
    " 'r_9',\n",
    " 'r_10',\n",
    " 'r_11',\n",
    " 'r_12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(s, base_dsl_only = False):\n",
    "    '''\n",
    "    Converts a program in lambda format (i.e. from Dreamcoder enumeration) into a sequence of commands, \n",
    "        possibly including learned chunks.\n",
    "        \n",
    "    base_dsl_only: output program in terms of base dsl commands only, \n",
    "                    rather than printing names of learned chunks e.g. 'chunk_8'\n",
    "\n",
    "    # demo string without chunks to check hs and vs\n",
    "    >>> s = '(lambda ((lambda (2x1 (left 4 ((lambda (2x1 (left 1 (1x2 (1x2 $0))))) $0)))) (right 9 (#(lambda (1x2 (right 6 (1x2 (left 5 (2x1 (right 4 (2x1 $0)))))))) (left 9 $0)))))'\n",
    "    >>> parse(s) \n",
    "    'h l_4 h l_1 v v r_9 chunk_Pi l_9'\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    s = utilities.parseSExpression(s)\n",
    "#     print(s)\n",
    "    def p(e):\n",
    "#         print(e)\n",
    "        if isinstance(e,list):\n",
    "            if e[0] == '#':\n",
    "                assert len(e) == 2\n",
    "                if base_dsl_only:\n",
    "                    return(p(e[1]))\n",
    "                else:\n",
    "                    return 'chunk_' + render.lookup[str(utilities.unparseSExpression(e[1]))][0].name + ' '\n",
    "#                 return 'search_for_chunk ' # in dsl- lookup and return\n",
    "            if e[0] == 'lambda':\n",
    "                assert len(e) == 2\n",
    "                return p(e[1]) # dig to see what else is in lambda \n",
    "            if e[0] == 'left':\n",
    "                if (e[1] == '$1') or (e[1] == '$0'):\n",
    "                    #return 'l_' + (p(e[2:]))\n",
    "                    return ''\n",
    "                else:\n",
    "                    return 'l_' + e[1] + ' ' + (p(e[2:]))\n",
    "            if e[0] == 'right': \n",
    "                if (e[1] == '$1') or (e[1] == '$0'):\n",
    "                    #return 'r_' + (p(e[2:]))\n",
    "                    return ''\n",
    "                else:\n",
    "                    return 'r_' + e[1] + ' ' + (p(e[2:]))\n",
    "            if e[0] == '1x2': return 'v ' + (p(e[1:]))\n",
    "            if e[0] == '2x1': return 'h ' + (p(e[1:]))\n",
    "            f = ''\n",
    "            for x in e:\n",
    "                f = f + p(x)\n",
    "            return f\n",
    "        assert isinstance(e,str)\n",
    "        if e[0] == '1x2': return 'v ' + (p(e[1:]))\n",
    "        if e[0] == '2x1': return 'h ' + (p(e[1:]))\n",
    "        if e == '$0': return ''\n",
    "        if e == '$1': return ''\n",
    "        raise ParseFailure((s,e))\n",
    "    return p(s)[:-1]\n",
    "\n",
    "\n",
    "def get_partially_chunked_programs(trial_datum):\n",
    "    chunk_lambdas = trial_datum['dsl_lambda'][16:]\n",
    "    chunk_names = trial_datum['chunks']\n",
    "    \n",
    "#     print('whole_lambdas', trial_datum['dsl_lambda'])\n",
    "#     print('lambdas', chunk_lambdas)\n",
    "#     print('names', chunk_names)\n",
    "    \n",
    "    progs = [trial_datum['min_program']]\n",
    "\n",
    "    for prog in progs:\n",
    "        for i, chunk_name in enumerate(chunk_names):\n",
    "            new_prog = prog.replace(chunk_name, parse(chunk_lambdas[i], base_dsl_only=True))\n",
    "            if not(new_prog in progs):\n",
    "                progs.append(new_prog)\n",
    "    \n",
    "    progs_with_length = {p: len(p.split(' ')) for p in progs}\n",
    "    return progs_with_length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DSLs for each trial sequence\n",
    "\n",
    "We are considering how abstractions are learned by individual participants across a sequence of trials.  \n",
    "We therefore track how each participant's Domain Specific Language (*DSL*) changes across the trial sequence.  \n",
    "DSLs include both the *base DSL* (specified above) as well as *program fragments* (abstractions) learned by Dreamcoder.  \n",
    "Dreamcoder is run on the sequence of tower programs seen up to the current trial.  \n",
    "\n",
    "`dsls[i]` is the dsl learned up to *and including* trial i.  \n",
    "Use `dsls[i-1]` for learning (as we are considering how the DSL, up to this point, is used to refactor the current program)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './results/revised/'\n",
    "\n",
    "dsls = {}\n",
    "trial_seqs = {}\n",
    "\n",
    "for ppt in range(1,50):\n",
    "    \n",
    "    dsls[ppt] = {}\n",
    "    \n",
    "    with open(data_path+f\"{ppt}/configs.p\", \"rb\") as config_file:\n",
    "            trial_seqs[ppt] = pickle.load(config_file)\n",
    "    \n",
    "    for trial in range(1, 13):\n",
    "        with open(data_path+f\"{ppt}/{trial}.p\", \"rb\") as input_file:\n",
    "                dsls[ppt][trial] = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enumerate programs\n",
    "\n",
    "We have the library of abstractions for each trial. Now we need to infer the actual programs used for the tower at that trial.  \n",
    "We assume that participants can find the shortest possible program using their library of abstractions.  \n",
    "We find these programs by:\n",
    "1. Enumerating programs until they meet the specification. (This works for programs with large abstractions, but timesout for those with a small DSL.)\n",
    "2. Manually refactoring programs written in the base DSL by searching for and replacing substrings with their corresponding chunk. (This is possible because in practice only a small handful of abstractions are learnt.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the trial grammars for a single participant's trial sequence\n",
    "\n",
    "# for a single value of w\n",
    "w = 3.3\n",
    "w_position = w_locations[w]\n",
    "\n",
    "trial_tasks = [SupervisedTower(tower_pair + str(i+1), tower_strings[tower_pair]) for i, tower_pair in enumerate(trial_seqs[ppt])]\n",
    "\n",
    "# get grammar for each trial\n",
    "trial_grammars = {trial_tasks[i]: Grammar.uniform(primitives + dsls[ppt][i][w_position]) for i in range (1,12)}\n",
    "trial_grammars[trial_tasks[0]] = Grammar.uniform(primitives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Run program enumeration (need to rerun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(python) Launching tower -> tower (3 tasks) w/ 1 CPUs. 0.000000 <= MDL < 1.500000. Timeout 20.000000.\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/will/opt/miniconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/will/opt/miniconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/will/compositional-abstractions/model_ms/lib_learning/utilities.py\", line 338, in _launchParallelProcess\n",
      "    [f, a, k] = PARALLELPROCESSDATA\n",
      "TypeError: cannot unpack non-iterable NoneType object\n"
     ]
    }
   ],
   "source": [
    "run = True\n",
    "\n",
    "if run:\n",
    "    for ppt in range(1,50):\n",
    "\n",
    "        # for a single value of w\n",
    "        w = 3.3\n",
    "        w_position = w_locations[w]\n",
    "\n",
    "\n",
    "        trial_tasks = [SupervisedTower(tower_pair + str(i+1), tower_strings[tower_pair]) for i, tower_pair in enumerate(trial_seqs[ppt])]\n",
    "\n",
    "        # get grammar for each trial\n",
    "        trial_grammars = {trial_tasks[i]: Grammar.uniform(primitives + dsls[ppt][i][w_position]) for i in range (1,12)}\n",
    "        trial_grammars[trial_tasks[0]] = Grammar.uniform(primitives)\n",
    "\n",
    "        filepath = './results/enumeration_ms/ppt_'+str(ppt)+'/'\n",
    "        Path(filepath).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        f_test = multicoreEnumeration(trial_grammars, \n",
    "                                 trial_tasks, \n",
    "                                 maximumFrontier=10.0, \n",
    "                                 enumerationTimeout=20, \n",
    "                                 solver='python',\n",
    "                                 filepath=filepath,\n",
    "                                 filename='enumeration_50_ppt'+str(ppt))\n",
    "\n",
    "        pickle.dump(f_test, open( './results/enumeration_ms/ppt_'+str(ppt)+'_complete.p', \"wb\" ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load programs from files\n",
    "\n",
    "frontiers = {}\n",
    "enumerated_programs = {}\n",
    "\n",
    "for ppt in range(1,50):\n",
    "\n",
    "    # for a single value of w\n",
    "    w = 3.3\n",
    "    w_position = w_locations[w]\n",
    "    \n",
    "    enumerated_programs[ppt] = {}\n",
    "\n",
    "    filepath = './results/enumeration_cogsci_revised/ppt_'+str(ppt)+'_complete.p'\n",
    "    \n",
    "    with open(filepath, \"rb\") as input_file:\n",
    "         frontiers[ppt] = pickle.load(input_file)\n",
    "            \n",
    "    \n",
    "    for trial_num in range(1,13):\n",
    "        enumerated_programs[ppt][trial_num] = [e.program for e in frontiers[ppt][0][trial_num-1].entries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['chunk_Pi r_9 chunk_L'],\n",
       " ['chunk_L r_12 chunk_C'],\n",
       " ['chunk_C r_6 chunk_Pi'],\n",
       " ['chunk_L r_9 chunk_Pi'],\n",
       " ['chunk_C r_12 chunk_L'],\n",
       " ['chunk_Pi r_7 chunk_C'],\n",
       " ['chunk_Pi r_9 chunk_L']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print programs from enumeration\n",
    "\n",
    "ppt_num = 1\n",
    "\n",
    "[list(map(lambda x: parse(str(x)), \n",
    "          enumerated_programs[ppt_num][trial_num])) \n",
    "    for trial_num in range(1,13)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactor missing programs by substituting in learned abstractions\n",
    "\n",
    "Programs involving fewers (or smaller) chunks are harder to reach through enumeration.\n",
    "Here we find the shortest programs analytically.\n",
    "- For the trials where no chunks have been learned, we use the ground-truth programs that were fed into Dreamcoder.\n",
    "- For trials where chunks were learned, we find start with the ground-truth programs and swap in chunks by searching for equivalent substrings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop \n",
    "\n",
    "verbose = False\n",
    "\n",
    "for ppt in range(1,50):\n",
    "    \n",
    "    trial_data = []\n",
    "\n",
    "    # towerpairs plus trial numbers\n",
    "    trial_tasks = [SupervisedTower(tower_pair + str(i+1), tower_strings[tower_pair]) for i, tower_pair in enumerate(trial_seqs[ppt])]\n",
    "\n",
    "    # get dsls for all trials\n",
    "    trial_grammars = {trial_tasks[i]: Grammar.uniform(primitives + dsls[ppt][i][w_position]) for i in range (1,12)}\n",
    "    trial_grammars[trial_tasks[0]] = Grammar.uniform(primitives)\n",
    "    \n",
    "    for trial_num in range(1,13):\n",
    "        \n",
    "        scene = trial_seqs[ppt][trial_num-1] # get trial scene\n",
    "        chunks = list(map(lambda x: parse(str(x)), trial_grammars[trial_tasks[trial_num-1]].primitives[16:]))\n",
    "        manual_program = manual_tower_programs[scene]\n",
    "        min_program = manual_program\n",
    "\n",
    "        if (len(enumerated_programs[ppt][trial_num]) > 0): # see if program found in enumeration\n",
    "\n",
    "            # parse program\n",
    "            parsed_programs = list(map(lambda x: parse(str(x)), enumerated_programs[ppt][trial_num]))\n",
    "\n",
    "            # trial_programs = []\n",
    "            # for entry in g[0][trial_num-1].entries:\n",
    "            #     trial_programs.append(parse(str(entry.program), base_dsl_only=False))\n",
    "\n",
    "            # Find shortest program if multiple found (in practice, only one program is found)\n",
    "            ps = {p: len(p.split(' ')) for p in parsed_programs}\n",
    "            trial_programs_sorted = {k: v for k, v in sorted(ps.items(), key=lambda item: item[1])}\n",
    "\n",
    "            min_program = list(trial_programs_sorted.keys())[0] # get first, shortest program\n",
    "\n",
    "            if verbose: print(min_program)\n",
    "\n",
    "        elif len(dsls[ppt][trial_num][w_position]) == 0: # if no chunks learned, take input program\n",
    "            \n",
    "            if verbose: print(min_program)\n",
    "\n",
    "        else: # if some chunks learned, swap in chunks into input program\n",
    "\n",
    "\n",
    "            # with trailing rights or lefts trimmed off\n",
    "            # WARNING- THIS ALLOWS CHUNKS WITH TRAILING RIGHT TO BE USED IN PLACES WHERE THERE ISN'T A RIGHT MOVE AT THE END\n",
    "            chunk_tranlations_trimmed = list(map(lambda x: parse(str(x), base_dsl_only=True), dsls[ppt][trial_num][w_position]))\n",
    "\n",
    "            chunked_program = manual_program\n",
    "\n",
    "            # WARNING: this goes through chunks in order. Different orders might yield different programs\n",
    "            # We should probably try all programs, then find the minimum\n",
    "            \n",
    "            for i, chunk in enumerate(chunks):\n",
    "                if chunk in ['chunk_Pi','chunk_L','chunk_C']:\n",
    "                    chunked_program = chunked_program.replace(chunk_tranlations_trimmed[i], chunk)\n",
    "                    \n",
    "            for i, chunk in enumerate(chunks):\n",
    "                if chunk in ['chunk_8','chunk_8b']:\n",
    "                    chunked_program = chunked_program.replace(chunk_tranlations_trimmed[i], chunk)\n",
    "\n",
    "            if verbose: print(chunked_program)\n",
    "            \n",
    "            min_program = chunked_program\n",
    "\n",
    "            \n",
    "#         ps = {p: len(p.split(' ')) for p in parsed_programs}\n",
    "#         trial_programs_sorted = {k: v for k, v in sorted(ps.items(), key=lambda item: item[1])}\n",
    "\n",
    "        trial_data.append(\n",
    "            {\n",
    "            'ppt' : ppt, # just added\n",
    "            'trial_num': trial_num,\n",
    "            'towers': scene,\n",
    "            'dsl_lambda': [str(p) for p in trial_grammars[trial_tasks[trial_num-1]].primitives],\n",
    "            'chunks': chunks,\n",
    "            'dsl': base_dsl + list(map(lambda s: parse(str(s)), trial_grammars[trial_tasks[trial_num-1]].primitives[16:])),\n",
    "            #         'trial_programs': trial_programs_sorted,\n",
    "            'min_program': min_program\n",
    "            })\n",
    "    \n",
    "    # find programs with abstractions replaced with base dsl only\n",
    "    for i, trial_datum in enumerate(trial_data):\n",
    "        trial_datum['programs_with_length'] = get_partially_chunked_programs(trial_datum)\n",
    "\n",
    "    # # This will save results within lib-learning directory. \n",
    "    with open(\"../lib_learning_output/synthesis_ms_output/ca_synthesis_ms_ppt_\" + str(ppt) + \".json\", \"w\") as write_file:\n",
    "         json.dump(trial_data, write_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now programs are stored in `lib_learning_output/synthesis_ms_output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h l_1 v v r_1 h r_6 v r_6 v l_5 h r_4 h',\n",
       " 'h l_4 h l_1 v v r_12 h l_1 v v r_1 h',\n",
       " 'h l_4 h l_1 v v r_9 v r_6 v l_5 h r_4 h',\n",
       " 'chunk_8b r_1 h r_12 h l_4 chunk_8b',\n",
       " 'v r_6 v l_5 h r_4 h r_9 h l_4 chunk_8',\n",
       " 'chunk_Pi r_7 chunk_C',\n",
       " 'chunk_Pi r_9 chunk_L',\n",
       " 'chunk_Pi r_9 chunk_L',\n",
       " 'chunk_Pi r_9 chunk_L',\n",
       " 'chunk_Pi r_9 chunk_L',\n",
       " 'chunk_Pi r_9 chunk_L',\n",
       " 'chunk_Pi r_9 chunk_L']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect programs\n",
    "\n",
    "# cogsci programs look wrong! Looks like they're all the same for the last 6 trials!\n",
    "\n",
    "ppt = 4\n",
    "\n",
    "with open(\"../lib_learning_output/synthesis_output_cogsci_revised/ca_synthesis_cogsci_21_ppt_\" + str(ppt) + \".json\", \"r\") as read_file:\n",
    "    cogsci_programs = json.load(read_file)\n",
    "\n",
    "with open(\"../lib_learning_output/synthesis_ms_output/ca_synthesis_ms_ppt_\" + str(ppt) + \".json\", \"r\") as read_file:\n",
    "    ms_programs = json.load(read_file)\n",
    "\n",
    "\n",
    "ms_progs = [trial_datum['min_program'] for trial_datum in ms_programs]\n",
    "cs_progs = [trial_datum['min_program'] for trial_datum in cogsci_programs]\n",
    "\n",
    "ms_progs\n",
    "# cs_progs\n",
    "\n",
    "# ms_progs == cs_progs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h l_1 v v r_1 h r_6 v r_6 v l_5 h r_4 h',\n",
       " 'h l_4 h l_1 v v r_12 h l_1 v v r_1 h',\n",
       " 'h l_4 h l_1 v v r_9 v r_6 v l_5 h r_4 h',\n",
       " 'chunk_8b r_1 h r_12 h l_4 chunk_8b',\n",
       " 'v r_6 v l_5 h r_4 h r_9 h l_4 chunk_8',\n",
       " 'chunk_Pi r_7 chunk_C',\n",
       " 'chunk_L r_9 chunk_Pi',\n",
       " 'chunk_C r_6 chunk_Pi',\n",
       " 'chunk_L r_12 chunk_C',\n",
       " 'chunk_Pi r_7 chunk_C',\n",
       " 'chunk_C r_12 chunk_L',\n",
       " 'chunk_Pi r_9 chunk_L']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show results for one participant\n",
    "ppt_programs = [trial_datum['min_program'] for trial_datum in ms_programs]\n",
    "ppt_programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h l_4 h l_1 v v r_9 v r_6 v l_5 h r_4 h',\n",
       " 'h l_1 v v r_1 h r_6 v r_6 v l_5 h r_4 h',\n",
       " 'h l_4 h l_1 v v r_12 h l_1 v v r_1 h',\n",
       " 'v r_6 v l_5 h r_4 h r_9 h l_4 chunk_8b',\n",
       " 'chunk_8 r_7 chunk_Pi r_1 h',\n",
       " 'chunk_Pi r_9 chunk_L',\n",
       " 'chunk_Pi r_9 chunk_L',\n",
       " 'chunk_Pi r_9 chunk_L',\n",
       " 'chunk_Pi r_9 chunk_L',\n",
       " 'chunk_Pi r_9 chunk_L',\n",
       " 'chunk_Pi r_9 chunk_L',\n",
       " 'chunk_Pi r_9 chunk_L']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppt_programs = [trial_datum['min_program'] for trial_datum in cogsci_programs]\n",
    "ppt_programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parse_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[26], line 41\u001b[0m\n",
      "\u001b[1;32m     34\u001b[0m     \u001b[39mif\u001b[39;00m verbose: \u001b[39mprint\u001b[39m(min_program)\n",
      "\u001b[1;32m     36\u001b[0m \u001b[39melse\u001b[39;00m: \u001b[39m# if some chunks learned, swap in chunks into input program\u001b[39;00m\n",
      "\u001b[1;32m     37\u001b[0m \n",
      "\u001b[1;32m     38\u001b[0m \n",
      "\u001b[1;32m     39\u001b[0m     \u001b[39m# with trailing rights or lefts trimmed off\u001b[39;00m\n",
      "\u001b[1;32m     40\u001b[0m     \u001b[39m# WARNING- THIS ALLOWS CHUNKS WITH TRAILING RIGHT TO BE USED IN PLACES WHERE THERE ISN'T A RIGHT MOVE AT THE END\u001b[39;00m\n",
      "\u001b[0;32m---> 41\u001b[0m     chunk_tranlations_trimmed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m(\u001b[39mlambda\u001b[39;49;00m x: parse_2(\u001b[39mstr\u001b[39;49m(x), base_dsl_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m), dsls[ppt][trial_num][w_position]))\n",
      "\u001b[1;32m     43\u001b[0m     chunked_program \u001b[39m=\u001b[39m manual_program\n",
      "\u001b[1;32m     45\u001b[0m     \u001b[39m# WARNING: this goes through chunks in order. Different orders might yield different programs\u001b[39;00m\n",
      "\u001b[1;32m     46\u001b[0m     \u001b[39m# We should probably try all programs, then find the minimum\u001b[39;00m\n",
      "\n",
      "Cell \u001b[0;32mIn[26], line 41\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n",
      "\u001b[1;32m     34\u001b[0m     \u001b[39mif\u001b[39;00m verbose: \u001b[39mprint\u001b[39m(min_program)\n",
      "\u001b[1;32m     36\u001b[0m \u001b[39melse\u001b[39;00m: \u001b[39m# if some chunks learned, swap in chunks into input program\u001b[39;00m\n",
      "\u001b[1;32m     37\u001b[0m \n",
      "\u001b[1;32m     38\u001b[0m \n",
      "\u001b[1;32m     39\u001b[0m     \u001b[39m# with trailing rights or lefts trimmed off\u001b[39;00m\n",
      "\u001b[1;32m     40\u001b[0m     \u001b[39m# WARNING- THIS ALLOWS CHUNKS WITH TRAILING RIGHT TO BE USED IN PLACES WHERE THERE ISN'T A RIGHT MOVE AT THE END\u001b[39;00m\n",
      "\u001b[0;32m---> 41\u001b[0m     chunk_tranlations_trimmed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m x: parse_2(\u001b[39mstr\u001b[39m(x), base_dsl_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), dsls[ppt][trial_num][w_position]))\n",
      "\u001b[1;32m     43\u001b[0m     chunked_program \u001b[39m=\u001b[39m manual_program\n",
      "\u001b[1;32m     45\u001b[0m     \u001b[39m# WARNING: this goes through chunks in order. Different orders might yield different programs\u001b[39;00m\n",
      "\u001b[1;32m     46\u001b[0m     \u001b[39m# We should probably try all programs, then find the minimum\u001b[39;00m\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parse_2' is not defined"
     ]
    }
   ],
   "source": [
    "# used for cogsci (I think)- doing something wrong (using variable that wasn't getting updated)\n",
    "# Create trial data by looping through participants and trials\n",
    "\n",
    "verbose = False\n",
    "\n",
    "for ppt in range(1,50):\n",
    "    \n",
    "    trial_data = []\n",
    "\n",
    "    # towerpairs plus trial numbers\n",
    "    trial_tasks = [SupervisedTower(tower_pair + str(i+1), tower_strings[tower_pair]) for i, tower_pair in enumerate(trial_seqs[ppt])]\n",
    "\n",
    "    # get dsls for all trials\n",
    "    trial_grammars = {trial_tasks[i]: Grammar.uniform(primitives + dsls[ppt][i][w_position]) for i in range (1,12)}\n",
    "    trial_grammars[trial_tasks[0]] = Grammar.uniform(primitives)\n",
    "    \n",
    "    for trial_num in range(1,13):\n",
    "        \n",
    "        scene = trial_seqs[ppt][trial_num-1] # get trial scene\n",
    "        chunks = list(map(lambda x: parse(str(x)), trial_grammars[trial_tasks[trial_num-1]].primitives[16:]))\n",
    "        manual_program = manual_tower_programs[scene]\n",
    "        min_program = manual_program\n",
    "\n",
    "        if (len(enumerated_programs[ppt][trial_num]) > 0): # see if program found in enumeration\n",
    "\n",
    "            # parse program\n",
    "            parsed_programs = list(map(lambda x: parse_2(str(x)), enumerated_programs[ppt][trial_num]))\n",
    "\n",
    "            min_program = list(trial_programs_sorted.keys())[0] # get first, shortest program\n",
    "\n",
    "            if verbose: print(min_program)\n",
    "\n",
    "        elif len(dsls[ppt][trial_num][w_position]) == 0: # if no chunks learned, take input program\n",
    "            \n",
    "            if verbose: print(min_program)\n",
    "\n",
    "        else: # if some chunks learned, swap in chunks into input program\n",
    "\n",
    "\n",
    "            # with trailing rights or lefts trimmed off\n",
    "            # WARNING- THIS ALLOWS CHUNKS WITH TRAILING RIGHT TO BE USED IN PLACES WHERE THERE ISN'T A RIGHT MOVE AT THE END\n",
    "            chunk_tranlations_trimmed = list(map(lambda x: parse_2(str(x), base_dsl_only=True), dsls[ppt][trial_num][w_position]))\n",
    "\n",
    "            chunked_program = manual_program\n",
    "\n",
    "            # WARNING: this goes through chunks in order. Different orders might yield different programs\n",
    "            # We should probably try all programs, then find the minimum\n",
    "            \n",
    "            for i, chunk in enumerate(chunks):\n",
    "                if chunk in ['chunk_Pi','chunk_L','chunk_C']:\n",
    "                    chunked_program = chunked_program.replace(chunk_tranlations_trimmed[i], chunk)\n",
    "                    \n",
    "            for i, chunk in enumerate(chunks):\n",
    "                if chunk in ['chunk_8','chunk_8b']:\n",
    "                    chunked_program = chunked_program.replace(chunk_tranlations_trimmed[i], chunk)\n",
    "\n",
    "            if verbose: print(chunked_program)\n",
    "            \n",
    "            min_program = chunked_program\n",
    "\n",
    "            \n",
    "#         ps = {p: len(p.split(' ')) for p in parsed_programs}\n",
    "#         trial_programs_sorted = {k: v for k, v in sorted(ps.items(), key=lambda item: item[1])}\n",
    "\n",
    "        trial_data.append(\n",
    "            {\n",
    "            'ppt' : ppt, # just added\n",
    "            'trial_num': trial_num,\n",
    "            'towers': scene,\n",
    "            'dsl_lambda': [str(p) for p in trial_grammars[trial_tasks[trial_num-1]].primitives],\n",
    "            'chunks': chunks,\n",
    "            'dsl': base_dsl + list(map(lambda s: parse(str(s)), trial_grammars[trial_tasks[trial_num-1]].primitives[16:])),\n",
    "            #         'trial_programs': trial_programs_sorted,\n",
    "            'min_program': min_program\n",
    "            })\n",
    "    \n",
    "    # find programs with abstractions replaced with base dsl only\n",
    "    for i, trial_datum in enumerate(trial_data):\n",
    "        trial_datum['programs_with_length'] = get_partially_chunked_programs(trial_datum)\n",
    "\n",
    "    # This will save results within lib-learning directory. \n",
    "#     with open(\"results/revised/synthesis_output/ca_synthesis_cogsci_21_ppt_\" + str(ppt) + \".json\", \"w\") as write_file:\n",
    "#          json.dump(trial_data, write_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Used in original cogsci submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually add trials 1-5\n",
    "\n",
    "trial_data = []\n",
    "\n",
    "for trial_num in range(1,6):\n",
    "    \n",
    "#     trial_programs = []\n",
    "#     for entry in g[0][trial_num-1].entries:\n",
    "#         trial_programs.append(parse(str(entry.program), base_dsl_only=False))\n",
    "\n",
    "    manual_program = manual_tower_programs[trial_seq[trial_num-1]]\n",
    "\n",
    "    ps = {manual_program: len(manual_program.split(' '))}\n",
    "    trial_programs_sorted = {k: v for k, v in sorted(ps.items(), key=lambda item: item[1])}\n",
    "    \n",
    "    trial_data.append(\n",
    "    {\n",
    "        'trial_num': trial_num,\n",
    "        'towers': trial_seq[trial_num-1],\n",
    "        'dsl_lambda': [str(p) for p in trial_grammars[trial_tasks[trial_num-1]].primitives],\n",
    "        'chunks': list(map(lambda s: parse(str(s)), trial_grammars[trial_tasks[trial_num-1]].primitives[16:])),\n",
    "        'dsl': base_dsl + list(map(lambda s: parse(str(s)), trial_grammars[trial_tasks[trial_num-1]].primitives[16:])),\n",
    "#         'trial_programs': trial_programs_sorted,\n",
    "        'min_program': manual_program\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually add min-length programs with chunks from trials four and five.\n",
    "\n",
    "# trial 4\n",
    "p_3 = 'chunk_8 r_1 h r_12 h l_4 h l_1 v v'\n",
    "trial_data[3]['min_program'] = p_3\n",
    "\n",
    "# trial 5\n",
    "p_4 = 'chunk_8 r_1 h r_6 chunk_9 h r_4 h'\n",
    "trial_data[4]['min_program'] = p_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find shortest program\n",
    "\n",
    "for trial_num in range(6,13):\n",
    "    \n",
    "    trial_programs = []\n",
    "    for entry in g[0][trial_num-1].entries:\n",
    "        trial_programs.append(parse(str(entry.program), base_dsl_only=False))\n",
    "\n",
    "    ps = {p: len(p.split(' ')) for p in trial_programs}\n",
    "    trial_programs_sorted = {k: v for k, v in sorted(ps.items(), key=lambda item: item[1])}\n",
    "    \n",
    "    trial_data.append(\n",
    "    {\n",
    "        'trial_num': trial_num,\n",
    "        'towers': trial_seq[trial_num-1],\n",
    "        'dsl_lambda': [str(p) for p in trial_grammars[trial_tasks[trial_num-1]].primitives],\n",
    "        'chunks': list(map(lambda s: parse(str(s)), trial_grammars[trial_tasks[trial_num-1]].primitives[16:])),\n",
    "        'dsl': base_dsl + list(map(lambda s: parse(str(s)), trial_grammars[trial_tasks[trial_num-1]].primitives[16:])),\n",
    "#         'trial_programs': trial_programs_sorted,\n",
    "        'min_program': list(trial_programs_sorted.keys())[0]\n",
    "    })\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partially_chunked_programs(trial_datum):\n",
    "#     chunks = trial_datum['chunks']\n",
    "#     min_prog = trial_datum['min_program']\n",
    "    chunk_lambdas = trial_datum['dsl_lambda'][16:]\n",
    "    chunk_names = trial_datum['dsl'][28:]\n",
    "    \n",
    "    progs = [trial_datum['min_program']]\n",
    "\n",
    "    for prog in progs:\n",
    "        for i, chunk_name in enumerate(chunk_names):\n",
    "            new_prog = prog.replace(chunk_name, parse(chunk_lambdas[i], base_dsl_only=True))\n",
    "            if not(new_prog in progs):\n",
    "                progs.append(new_prog)\n",
    "    \n",
    "    progs_with_length = {p: len(p.split(' ')) for p in progs}\n",
    "    return progs_with_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find programs with abstractions replaced with base dsl only\n",
    "\n",
    "for i, trial_datum in enumerate(trial_data):\n",
    "    trial_datum['programs_with_length'] = get_partially_chunked_programs(trial_datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'trial_num': 1,\n",
       "  'towers': 'PiC',\n",
       "  'dsl_lambda': ['2x1',\n",
       "   '1x2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '6',\n",
       "   '7',\n",
       "   '8',\n",
       "   '9',\n",
       "   '10',\n",
       "   '11',\n",
       "   '12',\n",
       "   'left',\n",
       "   'right'],\n",
       "  'chunks': [],\n",
       "  'dsl': ['h',\n",
       "   'v',\n",
       "   'l_0',\n",
       "   'l_1',\n",
       "   'l_2',\n",
       "   'l_3',\n",
       "   'l_4',\n",
       "   'l_5',\n",
       "   'l_6',\n",
       "   'l_7',\n",
       "   'l_8',\n",
       "   'l_9',\n",
       "   'l_10',\n",
       "   'l_11',\n",
       "   'l_12',\n",
       "   'r_0',\n",
       "   'r_1',\n",
       "   'r_2',\n",
       "   'r_3',\n",
       "   'r_4',\n",
       "   'r_5',\n",
       "   'r_6',\n",
       "   'r_7',\n",
       "   'r_8',\n",
       "   'r_9',\n",
       "   'r_10',\n",
       "   'r_11',\n",
       "   'r_12'],\n",
       "  'min_program': 'v r_6 v l_5 h r_4 h r_7 h l_1 v v r_1 h',\n",
       "  'programs_with_length': {'v r_6 v l_5 h r_4 h r_7 h l_1 v v r_1 h': 14}},\n",
       " {'trial_num': 2,\n",
       "  'towers': 'LC',\n",
       "  'dsl_lambda': ['2x1',\n",
       "   '1x2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '6',\n",
       "   '7',\n",
       "   '8',\n",
       "   '9',\n",
       "   '10',\n",
       "   '11',\n",
       "   '12',\n",
       "   'left',\n",
       "   'right'],\n",
       "  'chunks': [],\n",
       "  'dsl': ['h',\n",
       "   'v',\n",
       "   'l_0',\n",
       "   'l_1',\n",
       "   'l_2',\n",
       "   'l_3',\n",
       "   'l_4',\n",
       "   'l_5',\n",
       "   'l_6',\n",
       "   'l_7',\n",
       "   'l_8',\n",
       "   'l_9',\n",
       "   'l_10',\n",
       "   'l_11',\n",
       "   'l_12',\n",
       "   'r_0',\n",
       "   'r_1',\n",
       "   'r_2',\n",
       "   'r_3',\n",
       "   'r_4',\n",
       "   'r_5',\n",
       "   'r_6',\n",
       "   'r_7',\n",
       "   'r_8',\n",
       "   'r_9',\n",
       "   'r_10',\n",
       "   'r_11',\n",
       "   'r_12'],\n",
       "  'min_program': 'h l_4 h l_1 v v r_12 h l_1 v v r_1 h',\n",
       "  'programs_with_length': {'h l_4 h l_1 v v r_12 h l_1 v v r_1 h': 13}},\n",
       " {'trial_num': 3,\n",
       "  'towers': 'PiL',\n",
       "  'dsl_lambda': ['2x1',\n",
       "   '1x2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '6',\n",
       "   '7',\n",
       "   '8',\n",
       "   '9',\n",
       "   '10',\n",
       "   '11',\n",
       "   '12',\n",
       "   'left',\n",
       "   'right'],\n",
       "  'chunks': [],\n",
       "  'dsl': ['h',\n",
       "   'v',\n",
       "   'l_0',\n",
       "   'l_1',\n",
       "   'l_2',\n",
       "   'l_3',\n",
       "   'l_4',\n",
       "   'l_5',\n",
       "   'l_6',\n",
       "   'l_7',\n",
       "   'l_8',\n",
       "   'l_9',\n",
       "   'l_10',\n",
       "   'l_11',\n",
       "   'l_12',\n",
       "   'r_0',\n",
       "   'r_1',\n",
       "   'r_2',\n",
       "   'r_3',\n",
       "   'r_4',\n",
       "   'r_5',\n",
       "   'r_6',\n",
       "   'r_7',\n",
       "   'r_8',\n",
       "   'r_9',\n",
       "   'r_10',\n",
       "   'r_11',\n",
       "   'r_12'],\n",
       "  'min_program': 'v r_6 v l_5 h r_4 h r_9 h l_4 h l_1 v v',\n",
       "  'programs_with_length': {'v r_6 v l_5 h r_4 h r_9 h l_4 h l_1 v v': 14}},\n",
       " {'trial_num': 4,\n",
       "  'towers': 'CL',\n",
       "  'dsl_lambda': ['2x1',\n",
       "   '1x2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '6',\n",
       "   '7',\n",
       "   '8',\n",
       "   '9',\n",
       "   '10',\n",
       "   '11',\n",
       "   '12',\n",
       "   'left',\n",
       "   'right',\n",
       "   '#(lambda (2x1 (left 1 (1x2 (1x2 $0)))))'],\n",
       "  'chunks': ['chunk_8'],\n",
       "  'dsl': ['h',\n",
       "   'v',\n",
       "   'l_0',\n",
       "   'l_1',\n",
       "   'l_2',\n",
       "   'l_3',\n",
       "   'l_4',\n",
       "   'l_5',\n",
       "   'l_6',\n",
       "   'l_7',\n",
       "   'l_8',\n",
       "   'l_9',\n",
       "   'l_10',\n",
       "   'l_11',\n",
       "   'l_12',\n",
       "   'r_0',\n",
       "   'r_1',\n",
       "   'r_2',\n",
       "   'r_3',\n",
       "   'r_4',\n",
       "   'r_5',\n",
       "   'r_6',\n",
       "   'r_7',\n",
       "   'r_8',\n",
       "   'r_9',\n",
       "   'r_10',\n",
       "   'r_11',\n",
       "   'r_12',\n",
       "   'chunk_8'],\n",
       "  'min_program': 'chunk_8 r_1 h r_12 h l_4 h l_1 v v',\n",
       "  'programs_with_length': {'chunk_8 r_1 h r_12 h l_4 h l_1 v v': 10,\n",
       "   'h l_1 v v r_1 h r_12 h l_4 h l_1 v v': 13}},\n",
       " {'trial_num': 5,\n",
       "  'towers': 'CPi',\n",
       "  'dsl_lambda': ['2x1',\n",
       "   '1x2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '6',\n",
       "   '7',\n",
       "   '8',\n",
       "   '9',\n",
       "   '10',\n",
       "   '11',\n",
       "   '12',\n",
       "   'left',\n",
       "   'right',\n",
       "   '#(lambda (2x1 (left 1 (1x2 (1x2 $0)))))',\n",
       "   '#(lambda (1x2 (right 6 (1x2 (left 5 $0)))))'],\n",
       "  'chunks': ['chunk_8', 'chunk_9'],\n",
       "  'dsl': ['h',\n",
       "   'v',\n",
       "   'l_0',\n",
       "   'l_1',\n",
       "   'l_2',\n",
       "   'l_3',\n",
       "   'l_4',\n",
       "   'l_5',\n",
       "   'l_6',\n",
       "   'l_7',\n",
       "   'l_8',\n",
       "   'l_9',\n",
       "   'l_10',\n",
       "   'l_11',\n",
       "   'l_12',\n",
       "   'r_0',\n",
       "   'r_1',\n",
       "   'r_2',\n",
       "   'r_3',\n",
       "   'r_4',\n",
       "   'r_5',\n",
       "   'r_6',\n",
       "   'r_7',\n",
       "   'r_8',\n",
       "   'r_9',\n",
       "   'r_10',\n",
       "   'r_11',\n",
       "   'r_12',\n",
       "   'chunk_8',\n",
       "   'chunk_9'],\n",
       "  'min_program': 'chunk_8 r_1 h r_6 chunk_9 h r_4 h',\n",
       "  'programs_with_length': {'chunk_8 r_1 h r_6 chunk_9 h r_4 h': 8,\n",
       "   'h l_1 v v r_1 h r_6 chunk_9 h r_4 h': 11,\n",
       "   'chunk_8 r_1 h r_6 v r_6 v l_5 h r_4 h': 11,\n",
       "   'h l_1 v v r_1 h r_6 v r_6 v l_5 h r_4 h': 14}},\n",
       " {'trial_num': 6,\n",
       "  'towers': 'LPi',\n",
       "  'dsl_lambda': ['2x1',\n",
       "   '1x2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '6',\n",
       "   '7',\n",
       "   '8',\n",
       "   '9',\n",
       "   '10',\n",
       "   '11',\n",
       "   '12',\n",
       "   'left',\n",
       "   'right',\n",
       "   '#(lambda (2x1 (left 1 (1x2 (1x2 $0)))))',\n",
       "   '#(lambda (1x2 (right 6 (1x2 (left 5 (2x1 (right 4 (2x1 $0))))))))',\n",
       "   '#(lambda (2x1 (left 4 (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) $0))))',\n",
       "   '#(lambda (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) (right 1 (2x1 $0))))'],\n",
       "  'chunks': ['chunk_8', 'chunk_Pi', 'chunk_L', 'chunk_C'],\n",
       "  'dsl': ['h',\n",
       "   'v',\n",
       "   'l_0',\n",
       "   'l_1',\n",
       "   'l_2',\n",
       "   'l_3',\n",
       "   'l_4',\n",
       "   'l_5',\n",
       "   'l_6',\n",
       "   'l_7',\n",
       "   'l_8',\n",
       "   'l_9',\n",
       "   'l_10',\n",
       "   'l_11',\n",
       "   'l_12',\n",
       "   'r_0',\n",
       "   'r_1',\n",
       "   'r_2',\n",
       "   'r_3',\n",
       "   'r_4',\n",
       "   'r_5',\n",
       "   'r_6',\n",
       "   'r_7',\n",
       "   'r_8',\n",
       "   'r_9',\n",
       "   'r_10',\n",
       "   'r_11',\n",
       "   'r_12',\n",
       "   'chunk_8',\n",
       "   'chunk_Pi',\n",
       "   'chunk_L',\n",
       "   'chunk_C'],\n",
       "  'min_program': 'chunk_L r_9 chunk_Pi',\n",
       "  'programs_with_length': {'chunk_L r_9 chunk_Pi': 3,\n",
       "   'chunk_L r_9 v r_6 v l_5 h r_4 h': 9,\n",
       "   'h l_4 h l_1 v v r_9 chunk_Pi': 8,\n",
       "   'h l_4 h l_1 v v r_9 v r_6 v l_5 h r_4 h': 14}},\n",
       " {'trial_num': 7,\n",
       "  'towers': 'PiC',\n",
       "  'dsl_lambda': ['2x1',\n",
       "   '1x2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '6',\n",
       "   '7',\n",
       "   '8',\n",
       "   '9',\n",
       "   '10',\n",
       "   '11',\n",
       "   '12',\n",
       "   'left',\n",
       "   'right',\n",
       "   '#(lambda (2x1 (left 1 (1x2 (1x2 $0)))))',\n",
       "   '#(lambda (1x2 (right 6 (1x2 (left 5 (2x1 (right 4 (2x1 $0))))))))',\n",
       "   '#(lambda (2x1 (left 4 (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) $0))))',\n",
       "   '#(lambda (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) (right 1 (2x1 $0))))'],\n",
       "  'chunks': ['chunk_8', 'chunk_Pi', 'chunk_L', 'chunk_C'],\n",
       "  'dsl': ['h',\n",
       "   'v',\n",
       "   'l_0',\n",
       "   'l_1',\n",
       "   'l_2',\n",
       "   'l_3',\n",
       "   'l_4',\n",
       "   'l_5',\n",
       "   'l_6',\n",
       "   'l_7',\n",
       "   'l_8',\n",
       "   'l_9',\n",
       "   'l_10',\n",
       "   'l_11',\n",
       "   'l_12',\n",
       "   'r_0',\n",
       "   'r_1',\n",
       "   'r_2',\n",
       "   'r_3',\n",
       "   'r_4',\n",
       "   'r_5',\n",
       "   'r_6',\n",
       "   'r_7',\n",
       "   'r_8',\n",
       "   'r_9',\n",
       "   'r_10',\n",
       "   'r_11',\n",
       "   'r_12',\n",
       "   'chunk_8',\n",
       "   'chunk_Pi',\n",
       "   'chunk_L',\n",
       "   'chunk_C'],\n",
       "  'min_program': 'chunk_Pi r_7 chunk_C',\n",
       "  'programs_with_length': {'chunk_Pi r_7 chunk_C': 3,\n",
       "   'v r_6 v l_5 h r_4 h r_7 chunk_C': 9,\n",
       "   'chunk_Pi r_7 h l_1 v v r_1 h': 8,\n",
       "   'v r_6 v l_5 h r_4 h r_7 h l_1 v v r_1 h': 14}},\n",
       " {'trial_num': 8,\n",
       "  'towers': 'PiL',\n",
       "  'dsl_lambda': ['2x1',\n",
       "   '1x2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '6',\n",
       "   '7',\n",
       "   '8',\n",
       "   '9',\n",
       "   '10',\n",
       "   '11',\n",
       "   '12',\n",
       "   'left',\n",
       "   'right',\n",
       "   '#(lambda (1x2 (right 6 (1x2 (left 5 (2x1 (right 4 (2x1 $0))))))))',\n",
       "   '#(lambda (2x1 (left 1 (1x2 (1x2 $0)))))',\n",
       "   '#(lambda (2x1 (left 4 (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) $0))))',\n",
       "   '#(lambda (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) (right 1 (2x1 $0))))'],\n",
       "  'chunks': ['chunk_Pi', 'chunk_8', 'chunk_L', 'chunk_C'],\n",
       "  'dsl': ['h',\n",
       "   'v',\n",
       "   'l_0',\n",
       "   'l_1',\n",
       "   'l_2',\n",
       "   'l_3',\n",
       "   'l_4',\n",
       "   'l_5',\n",
       "   'l_6',\n",
       "   'l_7',\n",
       "   'l_8',\n",
       "   'l_9',\n",
       "   'l_10',\n",
       "   'l_11',\n",
       "   'l_12',\n",
       "   'r_0',\n",
       "   'r_1',\n",
       "   'r_2',\n",
       "   'r_3',\n",
       "   'r_4',\n",
       "   'r_5',\n",
       "   'r_6',\n",
       "   'r_7',\n",
       "   'r_8',\n",
       "   'r_9',\n",
       "   'r_10',\n",
       "   'r_11',\n",
       "   'r_12',\n",
       "   'chunk_Pi',\n",
       "   'chunk_8',\n",
       "   'chunk_L',\n",
       "   'chunk_C'],\n",
       "  'min_program': 'chunk_Pi r_9 chunk_L',\n",
       "  'programs_with_length': {'chunk_Pi r_9 chunk_L': 3,\n",
       "   'v r_6 v l_5 h r_4 h r_9 chunk_L': 9,\n",
       "   'chunk_Pi r_9 h l_4 h l_1 v v': 8,\n",
       "   'v r_6 v l_5 h r_4 h r_9 h l_4 h l_1 v v': 14}},\n",
       " {'trial_num': 9,\n",
       "  'towers': 'LC',\n",
       "  'dsl_lambda': ['2x1',\n",
       "   '1x2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '6',\n",
       "   '7',\n",
       "   '8',\n",
       "   '9',\n",
       "   '10',\n",
       "   '11',\n",
       "   '12',\n",
       "   'left',\n",
       "   'right',\n",
       "   '#(lambda (1x2 (right 6 (1x2 (left 5 (2x1 (right 4 (2x1 $0))))))))',\n",
       "   '#(lambda (2x1 (left 1 (1x2 (1x2 $0)))))',\n",
       "   '#(lambda (2x1 (left 4 (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) $0))))',\n",
       "   '#(lambda (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) (right 1 (2x1 $0))))'],\n",
       "  'chunks': ['chunk_Pi', 'chunk_8', 'chunk_L', 'chunk_C'],\n",
       "  'dsl': ['h',\n",
       "   'v',\n",
       "   'l_0',\n",
       "   'l_1',\n",
       "   'l_2',\n",
       "   'l_3',\n",
       "   'l_4',\n",
       "   'l_5',\n",
       "   'l_6',\n",
       "   'l_7',\n",
       "   'l_8',\n",
       "   'l_9',\n",
       "   'l_10',\n",
       "   'l_11',\n",
       "   'l_12',\n",
       "   'r_0',\n",
       "   'r_1',\n",
       "   'r_2',\n",
       "   'r_3',\n",
       "   'r_4',\n",
       "   'r_5',\n",
       "   'r_6',\n",
       "   'r_7',\n",
       "   'r_8',\n",
       "   'r_9',\n",
       "   'r_10',\n",
       "   'r_11',\n",
       "   'r_12',\n",
       "   'chunk_Pi',\n",
       "   'chunk_8',\n",
       "   'chunk_L',\n",
       "   'chunk_C'],\n",
       "  'min_program': 'chunk_L r_12 chunk_C',\n",
       "  'programs_with_length': {'chunk_L r_12 chunk_C': 3,\n",
       "   'h l_4 h l_1 v v r_12 chunk_C': 8,\n",
       "   'chunk_L r_12 h l_1 v v r_1 h': 8,\n",
       "   'h l_4 h l_1 v v r_12 h l_1 v v r_1 h': 13}},\n",
       " {'trial_num': 10,\n",
       "  'towers': 'CL',\n",
       "  'dsl_lambda': ['2x1',\n",
       "   '1x2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '6',\n",
       "   '7',\n",
       "   '8',\n",
       "   '9',\n",
       "   '10',\n",
       "   '11',\n",
       "   '12',\n",
       "   'left',\n",
       "   'right',\n",
       "   '#(lambda (1x2 (right 6 (1x2 (left 5 (2x1 (right 4 (2x1 $0))))))))',\n",
       "   '#(lambda (2x1 (left 1 (1x2 (1x2 $0)))))',\n",
       "   '#(lambda (2x1 (left 4 (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) $0))))',\n",
       "   '#(lambda (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) (right 1 (2x1 $0))))'],\n",
       "  'chunks': ['chunk_Pi', 'chunk_8', 'chunk_L', 'chunk_C'],\n",
       "  'dsl': ['h',\n",
       "   'v',\n",
       "   'l_0',\n",
       "   'l_1',\n",
       "   'l_2',\n",
       "   'l_3',\n",
       "   'l_4',\n",
       "   'l_5',\n",
       "   'l_6',\n",
       "   'l_7',\n",
       "   'l_8',\n",
       "   'l_9',\n",
       "   'l_10',\n",
       "   'l_11',\n",
       "   'l_12',\n",
       "   'r_0',\n",
       "   'r_1',\n",
       "   'r_2',\n",
       "   'r_3',\n",
       "   'r_4',\n",
       "   'r_5',\n",
       "   'r_6',\n",
       "   'r_7',\n",
       "   'r_8',\n",
       "   'r_9',\n",
       "   'r_10',\n",
       "   'r_11',\n",
       "   'r_12',\n",
       "   'chunk_Pi',\n",
       "   'chunk_8',\n",
       "   'chunk_L',\n",
       "   'chunk_C'],\n",
       "  'min_program': 'chunk_C r_12 chunk_L',\n",
       "  'programs_with_length': {'chunk_C r_12 chunk_L': 3,\n",
       "   'chunk_C r_12 h l_4 h l_1 v v': 8,\n",
       "   'h l_1 v v r_1 h r_12 chunk_L': 8,\n",
       "   'h l_1 v v r_1 h r_12 h l_4 h l_1 v v': 13}},\n",
       " {'trial_num': 11,\n",
       "  'towers': 'LPi',\n",
       "  'dsl_lambda': ['2x1',\n",
       "   '1x2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '6',\n",
       "   '7',\n",
       "   '8',\n",
       "   '9',\n",
       "   '10',\n",
       "   '11',\n",
       "   '12',\n",
       "   'left',\n",
       "   'right',\n",
       "   '#(lambda (1x2 (right 6 (1x2 (left 5 (2x1 (right 4 (2x1 $0))))))))',\n",
       "   '#(lambda (2x1 (left 1 (1x2 (1x2 $0)))))',\n",
       "   '#(lambda (2x1 (left 4 (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) $0))))',\n",
       "   '#(lambda (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) (right 1 (2x1 $0))))'],\n",
       "  'chunks': ['chunk_Pi', 'chunk_8', 'chunk_L', 'chunk_C'],\n",
       "  'dsl': ['h',\n",
       "   'v',\n",
       "   'l_0',\n",
       "   'l_1',\n",
       "   'l_2',\n",
       "   'l_3',\n",
       "   'l_4',\n",
       "   'l_5',\n",
       "   'l_6',\n",
       "   'l_7',\n",
       "   'l_8',\n",
       "   'l_9',\n",
       "   'l_10',\n",
       "   'l_11',\n",
       "   'l_12',\n",
       "   'r_0',\n",
       "   'r_1',\n",
       "   'r_2',\n",
       "   'r_3',\n",
       "   'r_4',\n",
       "   'r_5',\n",
       "   'r_6',\n",
       "   'r_7',\n",
       "   'r_8',\n",
       "   'r_9',\n",
       "   'r_10',\n",
       "   'r_11',\n",
       "   'r_12',\n",
       "   'chunk_Pi',\n",
       "   'chunk_8',\n",
       "   'chunk_L',\n",
       "   'chunk_C'],\n",
       "  'min_program': 'chunk_L r_9 chunk_Pi',\n",
       "  'programs_with_length': {'chunk_L r_9 chunk_Pi': 3,\n",
       "   'chunk_L r_9 v r_6 v l_5 h r_4 h': 9,\n",
       "   'h l_4 h l_1 v v r_9 chunk_Pi': 8,\n",
       "   'h l_4 h l_1 v v r_9 v r_6 v l_5 h r_4 h': 14}},\n",
       " {'trial_num': 12,\n",
       "  'towers': 'CPi',\n",
       "  'dsl_lambda': ['2x1',\n",
       "   '1x2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '6',\n",
       "   '7',\n",
       "   '8',\n",
       "   '9',\n",
       "   '10',\n",
       "   '11',\n",
       "   '12',\n",
       "   'left',\n",
       "   'right',\n",
       "   '#(lambda (1x2 (right 6 (1x2 (left 5 (2x1 (right 4 (2x1 $0))))))))',\n",
       "   '#(lambda (2x1 (left 1 (1x2 (1x2 $0)))))',\n",
       "   '#(lambda (2x1 (left 4 (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) $0))))',\n",
       "   '#(lambda (#(lambda (2x1 (left 1 (1x2 (1x2 $0))))) (right 1 (2x1 $0))))'],\n",
       "  'chunks': ['chunk_Pi', 'chunk_8', 'chunk_L', 'chunk_C'],\n",
       "  'dsl': ['h',\n",
       "   'v',\n",
       "   'l_0',\n",
       "   'l_1',\n",
       "   'l_2',\n",
       "   'l_3',\n",
       "   'l_4',\n",
       "   'l_5',\n",
       "   'l_6',\n",
       "   'l_7',\n",
       "   'l_8',\n",
       "   'l_9',\n",
       "   'l_10',\n",
       "   'l_11',\n",
       "   'l_12',\n",
       "   'r_0',\n",
       "   'r_1',\n",
       "   'r_2',\n",
       "   'r_3',\n",
       "   'r_4',\n",
       "   'r_5',\n",
       "   'r_6',\n",
       "   'r_7',\n",
       "   'r_8',\n",
       "   'r_9',\n",
       "   'r_10',\n",
       "   'r_11',\n",
       "   'r_12',\n",
       "   'chunk_Pi',\n",
       "   'chunk_8',\n",
       "   'chunk_L',\n",
       "   'chunk_C'],\n",
       "  'min_program': 'chunk_C r_6 chunk_Pi',\n",
       "  'programs_with_length': {'chunk_C r_6 chunk_Pi': 3,\n",
       "   'chunk_C r_6 v r_6 v l_5 h r_4 h': 9,\n",
       "   'h l_1 v v r_1 h r_6 chunk_Pi': 8,\n",
       "   'h l_1 v v r_1 h r_6 v r_6 v l_5 h r_4 h': 14}}]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open(\"ca_synthesis_output_manual_dechunked.json\", \"w\") as write_file:\n",
    "#     json.dump(trial_data, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./results/2/enumeration/enumeration_50000.p', \"rb\") as input_file:\n",
    "#     h = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
